"""
MD Shaving Solution V2 - Enhanced MD Shaving Analysis
=====================================================

This module provides next-generation Maximum Demand (MD) shaving analysis with:
- Monthly-based target calculation with dynamic user settings
- Battery database integration with vendor specifications
- Enhanced timeline visualization with peak events
- Interactive battery capacity selection interface

Author: Enhanced MD Shaving Team
Version: 2.0
Date: August 2025
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
import json
import io

# Import V1 components for reuse
from md_shaving_solution import (
    read_uploaded_file,
    _configure_data_inputs,
    _process_dataframe,
    _configure_tariff_selection,
    create_conditional_demand_line_with_peak_logic,
    _detect_peak_events,
    _detect_peak_events_tou_aware,
    _display_battery_simulation_chart,
    _simulate_battery_operation,
    _get_tariff_description
)
from tariffs.peak_logic import (
    is_peak_rp4, 
    get_period_classification,
    get_malaysia_holidays,
    detect_holidays_from_data
)


def debug_forecast_data_structure():
    """
    Debug function to examine forecast data structure in session state
    
    Returns:
        DataFrame or None: The forecast data if available
    """
    if 'roc_long_format' in st.session_state:
        forecast_df = st.session_state['roc_long_format']
        st.markdown("### ðŸ” **Forecast Data Structure Analysis**")
        
        # Basic info
        with st.expander("ðŸ“Š **Data Shape & Info**", expanded=True):
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Rows", f"{forecast_df.shape[0]:,}")
                st.metric("Columns", forecast_df.shape[1])
            with col2:
                if hasattr(forecast_df.index, 'name'):
                    st.write(f"**Index**: {forecast_df.index.name}")
                st.write(f"**Index Type**: {type(forecast_df.index).__name__}")
        
        # Column analysis
        with st.expander("ðŸ·ï¸ **Column Details**"):
            st.write("**Available Columns:**")
            for col in forecast_df.columns:
                col_type = forecast_df[col].dtype
                non_null = forecast_df[col].count()
                st.write(f"- `{col}` ({col_type}) - {non_null:,} non-null values")
        
        # Sample data
        with st.expander("ðŸ“‹ **Sample Data (First 5 rows)**"):
            st.dataframe(forecast_df.head())
            
        # Data range info
        if 't' in forecast_df.columns:
            with st.expander("ðŸ“… **Time Range**"):
                time_col = pd.to_datetime(forecast_df['t'])
                st.write(f"**Start**: {time_col.min()}")
                st.write(f"**End**: {time_col.max()}")
                st.write(f"**Duration**: {time_col.max() - time_col.min()}")
        
        return forecast_df
    else:
        st.warning("âš ï¸ No forecast data found in session state")
        return None


def _infer_interval_hours(datetime_index, fallback=0.25):
    """
    Infer sampling interval from datetime index using mode of timestamp differences.
    
    Args:
        datetime_index: pandas DatetimeIndex
        fallback: fallback interval in hours (default: 0.25 = 15 minutes)
        
    Returns:
        float: Interval in hours
    """
    try:
        if len(datetime_index) > 1:
            diffs = datetime_index.to_series().diff().dropna()
            if len(diffs) > 0 and not diffs.mode().empty:
                interval_hours = diffs.mode()[0].total_seconds() / 3600
                return interval_hours
    except Exception:
        pass
    return fallback


def _get_dynamic_interval_hours(df_or_index):
    """
    Centralized function to get dynamic interval hours with consistent fallback logic.
    
    This ensures all energy conversion calculations use the same detected interval
    throughout V2, preventing inconsistencies between hardcoded and dynamic intervals.
    
    Args:
        df_or_index: DataFrame or DatetimeIndex to detect interval from
        
    Returns:
        float: Detected interval in hours
    """
    # First try to get from session state (already detected and stored)
    try:
        import streamlit as st
        if hasattr(st.session_state, 'data_interval_hours'):
            return st.session_state.data_interval_hours
    except (ImportError, AttributeError):
        pass
    
    # Fallback to detection from provided data
    if hasattr(df_or_index, 'index'):
        return _infer_interval_hours(df_or_index.index, fallback=0.25)
    else:
        return _infer_interval_hours(df_or_index, fallback=0.25)


def infer_base_interval(series):
    """
    Infer the base interval of the input series using native timestamp frequency.
    
    Args:
        series: pd.Series or pd.DataFrame with datetime index
        
    Returns:
        pd.Timedelta: Base interval of the series
        
    Raises:
        ValueError: If interval is irregular or outside valid range (1-60 minutes)
    """
    import numpy as np
    
    # Get the datetime index
    if hasattr(series, 'index'):
        dt_index = series.index
    else:
        dt_index = series
        
    if len(dt_index) < 2:
        raise ValueError("Need at least 2 timestamps to infer interval")
    
    try:
        # Try pandas infer_freq first
        inferred_freq = pd.infer_freq(dt_index)
        if inferred_freq and inferred_freq != 'T':  # 'T' is sometimes problematic
            try:
                base_interval = pd.Timedelta(inferred_freq)
            except (ValueError, TypeError):
                inferred_freq = None
        else:
            inferred_freq = None
            
        if not inferred_freq:
            # Fallback: median of timestamp differences
            diffs = np.diff(dt_index.values).astype('timedelta64[s]')
            median_seconds = np.median(diffs.astype(float))
            base_interval = pd.Timedelta(seconds=median_seconds)
        
        # Validate interval is between 1 minute and 60 minutes
        min_interval = pd.Timedelta(minutes=1)
        max_interval = pd.Timedelta(minutes=60)
        
        if base_interval < min_interval or base_interval > max_interval:
            raise ValueError(
                f"Base interval {base_interval} is outside valid range (1-60 minutes). "
                f"Please ensure your data has regular intervals between 1 minute and 1 hour."
            )
            
        return base_interval
        
    except Exception as e:
        # Check for irregular intervals
        if len(dt_index) > 2:
            diffs = np.diff(dt_index.values).astype('timedelta64[s]')
            diff_std = np.std(diffs.astype(float))
            diff_mean = np.mean(diffs.astype(float))
            
            if diff_std > diff_mean * 0.1:  # More than 10% variation
                raise ValueError(
                    f"Irregular time intervals detected (std/mean ratio: {diff_std/diff_mean:.2f}). "
                    f"ROC forecasting requires regular time intervals. "
                    f"Consider resampling your data to a fixed frequency."
                )
        
        raise ValueError(f"Could not infer base interval: {str(e)}")


def generate_forecast_horizons(base_interval):
    """
    Generate forecast horizons based on the base interval of the input series.
    
    Rules:
    - If base â‰¤ 5min, use multipliers [1, 10, 30]  
    - If base > 5min, use multipliers [1, 2, 3, 4]
    
    Args:
        base_interval: pd.Timedelta representing the base interval
        
    Returns:
        list: List of pd.Timedelta objects representing forecast horizons
    """
    # Convert to minutes for comparison
    base_minutes = base_interval.total_seconds() / 60
    
    if base_minutes <= 5:
        multipliers = [1, 10, 30]
    else:
        multipliers = [1, 2, 3, 4]
    
    # Generate horizons as Timedelta objects
    horizons = [base_interval * multiplier for multiplier in multipliers]
    
    return horizons


def get_adaptive_forecast_horizons(series):
    """
    Convenience function to infer base interval and generate appropriate horizons.
    
    Args:
        series: pd.Series or pd.DataFrame with datetime index
        
    Returns:
        tuple: (base_interval, horizons_list, horizons_minutes_list)
    """
    base_interval = infer_base_interval(series)
    horizons = generate_forecast_horizons(base_interval)
    
    # Also return horizon values in minutes for backwards compatibility
    horizons_minutes = [int(h.total_seconds() / 60) for h in horizons]
    
    return base_interval, horizons, horizons_minutes


def _calculate_tariff_specific_monthly_peaks(df, power_col, selected_tariff, holidays):
    """
    Calculate monthly peak demands based on tariff type:
    - General Tariff: Uses 24/7 peak demand (highest demand anytime)
    - TOU Tariff: Uses peak period demand only (2PM-10PM weekdays)
    
    Args:
        df: DataFrame with power data
        power_col: Column name containing power values
        selected_tariff: Selected tariff configuration
        holidays: Set of holiday dates
    
    Returns:
        tuple: (monthly_general_peaks, monthly_tou_peaks, tariff_type)
    """
    # Determine tariff type
    tariff_type = 'General'  # Default
    if selected_tariff:
        tariff_name = selected_tariff.get('Tariff', '').lower()
        tariff_type_field = selected_tariff.get('Type', '').lower()
        
        # Check if it's a TOU tariff
        if 'tou' in tariff_name or 'tou' in tariff_type_field or tariff_type_field == 'tou':
            tariff_type = 'TOU'
    
    # Calculate monthly peaks
    df_monthly = df.copy()
    df_monthly['Month'] = df_monthly.index.to_period('M')
    
    # General peaks (24/7 maximum demand)
    monthly_general_peaks = df_monthly.groupby('Month')[power_col].max()
    
    # TOU peaks (peak period maximum demand only - 2PM-10PM weekdays)
    monthly_tou_peaks = {}
    
    for month_period in monthly_general_peaks.index:
        month_start = month_period.start_time
        month_end = month_period.end_time
        month_mask = (df_monthly.index >= month_start) & (df_monthly.index <= month_end)
        month_data = df_monthly[month_mask]
        
        if not month_data.empty:
            # Filter for TOU peak periods only
            tou_peak_data = []
            
            for timestamp in month_data.index:
                power_value = month_data.loc[timestamp, power_col]
                if is_peak_rp4(timestamp, holidays if holidays else set()):
                    tou_peak_data.append(power_value)
            
            if tou_peak_data:
                monthly_tou_peaks[month_period] = max(tou_peak_data)
            else:
                monthly_tou_peaks[month_period] = monthly_general_peaks[month_period]
        else:
            monthly_tou_peaks[month_period] = 0
    
    monthly_tou_peaks = pd.Series(monthly_tou_peaks)
    
    return monthly_general_peaks, monthly_tou_peaks, tariff_type


def _calculate_monthly_targets_v2(df, power_col, selected_tariff, holidays, target_method, shave_percent, target_percent, target_manual_kw):
    """
    Calculate monthly targets based on tariff-specific peak demands.
    
    Returns:
        tuple: (monthly_targets, reference_peaks, tariff_type, target_description)
    """
    # Get tariff-specific monthly peaks
    monthly_general_peaks, monthly_tou_peaks, tariff_type = _calculate_tariff_specific_monthly_peaks(
        df, power_col, selected_tariff, holidays
    )
    
    # Select appropriate reference peaks based on tariff type
    if tariff_type == 'TOU':
        reference_peaks = monthly_tou_peaks
        peak_description = "TOU Peak Period (2PM-10PM weekdays)"
    else:
        reference_peaks = monthly_general_peaks
        peak_description = "General (24/7)"
    
    # Calculate targets based on reference peaks
    if target_method == "Manual Target (kW)":
        # For manual target, use the same value for all months
        monthly_targets = pd.Series(index=reference_peaks.index, data=target_manual_kw)
        target_description = f"{target_manual_kw:.0f} kW manual target ({peak_description})"
    elif target_method == "Percentage to Shave":
        # Calculate target as percentage reduction from each month's reference peak
        target_multiplier = 1 - (shave_percent / 100)
        monthly_targets = reference_peaks * target_multiplier
        target_description = f"{shave_percent}% shaving from {peak_description}"
    else:  # Percentage of Current Max
        # Calculate target as percentage of each month's reference peak
        target_multiplier = target_percent / 100
        monthly_targets = reference_peaks * target_multiplier
        target_description = f"{target_percent}% of {peak_description}"
    
    return monthly_targets, reference_peaks, tariff_type, target_description


def _generate_clustering_summary_table(all_monthly_events, selected_tariff, holidays):
    """
    Generate date-based clustering summary table for Section B2.
    
    Args:
        all_monthly_events: List of peak events from peak events detection
        selected_tariff: Selected tariff configuration
        holidays: Set of holiday dates
        
    Returns:
        pd.DataFrame: Summary table with columns: Date, Total Peak Events, General/TOU MD Excess, 
                     General/TOU Total Energy Required, Cost Impact
    """
    if not all_monthly_events or len(all_monthly_events) == 0:
        return pd.DataFrame()
    
    # Group events by date
    daily_events = {}
    for event in all_monthly_events:
        event_date = event.get('Start Date')
        if event_date not in daily_events:
            daily_events[event_date] = []
        daily_events[event_date].append(event)
    
    # Determine tariff type for MD cost calculation
    tariff_type = 'General'  # Default
    if selected_tariff:
        tariff_name = selected_tariff.get('Tariff', '').lower()
        tariff_type_field = selected_tariff.get('Type', '').lower()
        
        # Check if it's a TOU tariff
        if 'tou' in tariff_name or 'tou' in tariff_type_field or tariff_type_field == 'tou':
            tariff_type = 'TOU'
    
    # Get MD rate from tariff for cost calculation
    md_rate_rm_per_kw = 0
    if selected_tariff and isinstance(selected_tariff, dict):
        rates = selected_tariff.get('Rates', {})
        md_rate_rm_per_kw = rates.get('Capacity Rate', 0) + rates.get('Network Rate', 0)
    
    # Create summary data
    summary_data = []
    for date, events in daily_events.items():
        # Count total events for this date
        total_events = len(events)
        
        # Calculate MD excess values based on tariff type
        if tariff_type == 'TOU':
            # For TOU: Use TOU-specific values
            md_excess_values = [event.get('TOU Excess (kW)', 0) or 0 for event in events]
            energy_required_values = [event.get('TOU Required Energy (kWh)', 0) or 0 for event in events]
            max_md_excess = max(md_excess_values) if md_excess_values else 0
        else:
            # For General: Use General values (24/7 MD impact)
            md_excess_values = [event.get('General Excess (kW)', 0) or 0 for event in events]
            energy_required_values = [event.get('General Required Energy (kWh)', 0) or 0 for event in events]
            max_md_excess = max(md_excess_values) if md_excess_values else 0
        
        # Sum total energy required for the date
        total_energy_required = sum(energy_required_values)
        
        # Calculate cost impact using the maximum MD excess for the date
        # This follows the MD charging methodology where only the highest peak matters
        cost_impact_rm = max_md_excess * md_rate_rm_per_kw if max_md_excess > 0 and md_rate_rm_per_kw > 0 else 0
        
        summary_data.append({
            'Date': date,
            'Total Peak Events (count)': total_events,
            f'{tariff_type} MD Excess (Max kW)': round(max_md_excess, 2),
            f'{tariff_type} Total Energy Required (sum kWh)': round(total_energy_required, 2),
            'Cost Impact (RM/month)': round(cost_impact_rm, 2)
        })
    
    # Create DataFrame and sort by date
    df_summary = pd.DataFrame(summary_data)
    if not df_summary.empty:
        df_summary = df_summary.sort_values('Date')
    
    return df_summary


def _generate_monthly_summary_table(all_monthly_events, selected_tariff, holidays):
    """
    Generate monthly summary table for Section B2.
    
    CORRECTED METHODOLOGY: Uses daily clustering as intermediary step to match reference calculations.
    
    Args:
        all_monthly_events: List of peak events from peak events detection
        selected_tariff: Selected tariff configuration
        holidays: Set of holiday dates
        
    Returns:
        pd.DataFrame: Summary table with columns: Month, General/TOU MD Excess (Max kW), 
                     General/TOU Required Energy (Max kWh)
    """
    if not all_monthly_events or len(all_monthly_events) == 0:
        return pd.DataFrame()
    
    # STEP 1: Generate daily clustering summary first (intermediary calculation)
    daily_clustering_df = _generate_clustering_summary_table(all_monthly_events, selected_tariff, holidays)
    
    if daily_clustering_df.empty:
        return pd.DataFrame()
    
    # Determine tariff type for column naming
    tariff_type = 'General'  # Default
    if selected_tariff:
        tariff_name = selected_tariff.get('Tariff', '').lower()
        tariff_type_field = selected_tariff.get('Type', '').lower()
        
        # Check if it's a TOU tariff
        if 'tou' in tariff_name or 'tou' in tariff_type_field or tariff_type_field == 'tou':
            tariff_type = 'TOU'
    
    # STEP 2: Group daily results by month and take maximums
    # Add month column to daily clustering data
    daily_clustering_df['Month'] = pd.to_datetime(daily_clustering_df['Date']).dt.strftime('%Y-%m')
    
    # Define column names based on tariff type
    md_excess_col = f'{tariff_type} MD Excess (Max kW)'
    energy_required_col = f'{tariff_type} Total Energy Required (sum kWh)'
    
    # Group by month and calculate maximums from daily values
    monthly_summary = daily_clustering_df.groupby('Month').agg({
        md_excess_col: 'max',  # Maximum daily MD excess becomes monthly MD excess
        energy_required_col: 'max'  # Maximum daily energy required becomes monthly energy required
    }).reset_index()
    
    # Rename energy column to match expected format
    monthly_summary = monthly_summary.rename(columns={
        energy_required_col: f'{tariff_type} Required Energy (Max kWh)'
    })
    
    # Round values for display
    monthly_summary[md_excess_col] = monthly_summary[md_excess_col].round(2)
    monthly_summary[f'{tariff_type} Required Energy (Max kWh)'] = monthly_summary[f'{tariff_type} Required Energy (Max kWh)'].round(2)
    
    # Sort by month
    monthly_summary = monthly_summary.sort_values('Month')
    
    return monthly_summary


def build_daily_simulator_structure(df, threshold_kw, clusters_df, selected_tariff=None):
    """
    Build day-level structure for battery dispatch simulation.
    
    Args:
        df: Cleaned DataFrame with DateTimeIndex and 'kW' column
        threshold_kw: Power threshold for shaving analysis
        clusters_df: DataFrame from cluster_peak_events() function
        selected_tariff: Tariff configuration dict (optional)
    
    Returns:
        dict: days_struct[date] = {timeline, kW, above_threshold_kW, clusters, recharge_windows, dt_hours}
    """
    if df.empty or clusters_df.empty:
        return {}
        
    # Infer sampling interval from DataFrame index
    dt_hours = (df.index[1] - df.index[0]).total_seconds() / 3600 if len(df) > 1 else 0.5
    
    # Get TOU configuration from selected tariff
    md_hours = (14, 22)  # Default 2PM-10PM
    working_days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']
    tou_windows = {'off_peak': [(0, 8), (22, 24)], 'peak': [(14, 22)]}  # Default TOU
    charge_allowed_windows = [(0, 8), (22, 24)]  # Default: off-peak charging only
    max_site_charge_kw = None  # No default grid limit
    
    if selected_tariff:
        # Extract TOU configuration from tariff if available
        tariff_config = selected_tariff.get('config', {})
        if 'md_hours' in tariff_config:
            md_hours = tariff_config['md_hours']
        if 'working_days' in tariff_config:
            working_days = tariff_config['working_days']
        if 'tou_windows' in tariff_config:
            tou_windows = tariff_config['tou_windows']
        if 'charge_windows' in tariff_config:
            charge_allowed_windows = tariff_config['charge_windows']
        if 'max_site_charge_kw' in tariff_config:
            max_site_charge_kw = tariff_config['max_site_charge_kw']
    
    # Get unique dates from clusters and DataFrame
    cluster_dates = set()
    for _, cluster in clusters_df.iterrows():
        cluster_dates.add(cluster['cluster_start'].date())
        cluster_dates.add(cluster['cluster_end'].date())
    
    # Also include dates from DataFrame to ensure complete coverage
    df_dates = set(df.index.date)
    all_dates = cluster_dates.union(df_dates)
    
    days_struct = {}
    
    for date in sorted(all_dates):
        # Define day timeline (handle overnight MD window if needed)
        day_start = pd.Timestamp.combine(date, pd.Timestamp.min.time())
        day_end = day_start + pd.Timedelta(days=1)
        
        # Extract day's timeline from DataFrame
        day_mask = (df.index >= day_start) & (df.index < day_end)
        day_df = df[day_mask].copy()
        
        if day_df.empty:
            continue
            
        timeline = day_df.index
        kW_series = day_df['kW']
        above_threshold_kW = pd.Series(
            data=np.maximum(kW_series.values - threshold_kw, 0),
            index=timeline,
            name='above_threshold_kW'
        )
        
        # Find clusters intersecting this day
        day_clusters = []
        for _, cluster in clusters_df.iterrows():
            cluster_start = cluster['cluster_start']
            cluster_end = cluster['cluster_end']
            
            # Check if cluster intersects with this day
            if (cluster_start.date() == date or cluster_end.date() == date or
                (cluster_start.date() < date < cluster_end.date())):
                
                # Find timeline slice for this cluster
                cluster_mask = (timeline >= cluster_start) & (timeline <= cluster_end)
                if cluster_mask.any():
                    start_idx = np.where(cluster_mask)[0][0] if cluster_mask.any() else None
                    end_idx = np.where(cluster_mask)[0][-1] + 1 if cluster_mask.any() else None
                    
                    day_clusters.append({
                        'cluster_id': int(cluster['cluster_id']),
                        'start': cluster_start,
                        'end': cluster_end,
                        'duration_hr': float(cluster['cluster_duration_hr']),
                        'num_events': int(cluster['num_events_in_cluster']),
                        'peak_abs_kw_in_cluster': float(cluster['peak_abs_kw_in_cluster']),
                        'total_energy_above_threshold_kwh': float(cluster['total_energy_above_threshold_kwh']),
                        'slice': (start_idx, end_idx) if start_idx is not None else None
                    })
        
        # Sort clusters by start time
        day_clusters.sort(key=lambda x: x['start'])
        
        # Generate recharge windows between clusters
        recharge_windows = []
        
        if len(day_clusters) > 1:
            for i in range(len(day_clusters) - 1):
                current_cluster = day_clusters[i]
                next_cluster = day_clusters[i + 1]
                
                gap_start = current_cluster['end']
                gap_end = next_cluster['start']
                gap_duration = (gap_end - gap_start).total_seconds() / 3600
                
                if gap_duration > 0:
                    # Determine TOU label for this time period
                    gap_hour = gap_start.hour
                    gap_day = gap_start.strftime('%A')
                    
                    tou_label = 'off_peak'  # Default
                    for label, windows in tou_windows.items():
                        for window_start, window_end in windows:
                            if window_start <= gap_hour < window_end:
                                tou_label = label
                                break
                    
                    # Check if charging is allowed during this window
                    is_charging_allowed = False
                    for charge_start, charge_end in charge_allowed_windows:
                        if charge_start <= gap_hour < charge_end:
                            is_charging_allowed = True
                            break
                    
                    # Additional check: only allow charging on working days if specified
                    if gap_day not in working_days and 'working_days_only_charge' in (selected_tariff or {}):
                        is_charging_allowed = False
                    
                    recharge_windows.append({
                        'start': gap_start,
                        'end': gap_end,
                        'duration_hr': gap_duration,
                        'tou_label': tou_label,
                        'is_charging_allowed': is_charging_allowed,
                        'max_site_charge_kw': max_site_charge_kw
                    })
        
        # Add recharge windows at beginning and end of day if needed
        if day_clusters:
            # Before first cluster
            first_cluster = day_clusters[0]
            if first_cluster['start'] > timeline[0]:
                gap_start = timeline[0]
                gap_end = first_cluster['start']
                gap_duration = (gap_end - gap_start).total_seconds() / 3600
                
                gap_hour = gap_start.hour
                tou_label = 'off_peak'
                for label, windows in tou_windows.items():
                    for window_start, window_end in windows:
                        if window_start <= gap_hour < window_end:
                            tou_label = label
                            break
                
                is_charging_allowed = any(
                    charge_start <= gap_hour < charge_end 
                    for charge_start, charge_end in charge_allowed_windows
                )
                
                recharge_windows.insert(0, {
                    'start': gap_start,
                    'end': gap_end,
                    'duration_hr': gap_duration,
                    'tou_label': tou_label,
                    'is_charging_allowed': is_charging_allowed,
                    'max_site_charge_kw': max_site_charge_kw
                })
            
            # After last cluster
            last_cluster = day_clusters[-1]
            if last_cluster['end'] < timeline[-1]:
                gap_start = last_cluster['end']
                gap_end = timeline[-1]
                gap_duration = (gap_end - gap_start).total_seconds() / 3600
                
                gap_hour = gap_start.hour
                tou_label = 'off_peak'
                for label, windows in tou_windows.items():
                    for window_start, window_end in windows:
                        if window_start <= gap_hour < window_end:
                            tou_label = label
                            break
                
                is_charging_allowed = any(
                    charge_start <= gap_hour < charge_end 
                    for charge_start, charge_end in charge_allowed_windows
                )
                
                recharge_windows.append({
                    'start': gap_start,
                    'end': gap_end,
                    'duration_hr': gap_duration,
                    'tou_label': tou_label,
                    'is_charging_allowed': is_charging_allowed,
                    'max_site_charge_kw': max_site_charge_kw
                })
        
        # Store day structure
        days_struct[date] = {
            'timeline': timeline,
            'kW': kW_series,
            'above_threshold_kW': above_threshold_kW,
            'clusters': day_clusters,
            'recharge_windows': recharge_windows,
            'dt_hours': dt_hours
            }
        
        
        def _calculate_c_rate_limited_power_simple(current_soc_percent, max_power_rating_kw, battery_capacity_kwh, c_rate=1.0):
            """
            Simple C-rate power limitation for charging/discharging.
            
            Args:
                current_soc_percent: Current state of charge percentage
                max_power_rating_kw: Battery's rated power
                battery_capacity_kwh: Battery's energy capacity
                c_rate: Battery's C-rate (default 1.0C)
                
            Returns:
                Dictionary with power limits
            """
            # Calculate C-rate based power limits
            c_rate_power_limit = battery_capacity_kwh * c_rate
            
            # SOC-based derating (power reduces at extreme SOC levels)
            if current_soc_percent > 95:
                soc_factor = 0.8  # Reduce power at high SOC
            elif current_soc_percent < 5:
                soc_factor = 0.7  # Reduce power at low SOC (5% minimum safety limit)
            else:
                soc_factor = 1.0  # Full power in normal SOC range
            
            # Final power limit is minimum of C-rate limit and rated power
            effective_max_discharge_kw = min(c_rate_power_limit, max_power_rating_kw) * soc_factor
            effective_max_charge_kw = min(c_rate_power_limit, max_power_rating_kw) * soc_factor * 0.8  # Charging typically slower
            
            return {
                'max_discharge_power_kw': effective_max_discharge_kw,
                'max_charge_power_kw': effective_max_charge_kw,
                'c_rate_power_limit_kw': c_rate_power_limit,
                'soc_derating_factor': soc_factor,
                'limiting_factor': 'C-rate' if c_rate_power_limit < max_power_rating_kw else 'Power Rating'
            }
    
    return days_struct


def validate_and_clean_data(series, power_col=None, fill_method='drop'):
    """
    Validate and clean input data by handling NaN values and "null" strings.
    
    Args:
        series: pandas Series or DataFrame with datetime index and power values
        power_col: column name if series is a DataFrame (optional if Series)
        fill_method: method to handle NaN values ('drop', 'interpolate', 'forward', 'backward', 'raise')
        
    Returns:
        tuple: (cleaned_data, validation_report)
        
    Raises:
        ValueError: If data quality is insufficient or fill_method='raise' and NaNs found
    """
    # Handle both Series and DataFrame inputs
    if isinstance(series, pd.Series):
        data = series.copy()
        col_name = power_col or 'Power'
    else:
        if power_col is None:
            # Use first numeric column if power_col not specified
            numeric_cols = series.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) == 0:
                raise ValueError("No numeric columns found in DataFrame")
            power_col = numeric_cols[0]
        data = series[power_col].copy()
        col_name = power_col
    
    # Convert string "null" values to actual NaN
    if data.dtype == 'object':
        data = data.replace(['null', 'NULL', 'Null', 'nan', 'NaN', 'NAN', ''], np.nan)
        # Try to convert to numeric
        data = pd.to_numeric(data, errors='coerce')
    
    # Validation report
    total_points = len(data)
    nan_count = data.isna().sum()
    nan_percentage = (nan_count / total_points) * 100 if total_points > 0 else 0
    
    validation_report = {
        'total_points': total_points,
        'nan_count': nan_count,
        'nan_percentage': nan_percentage,
        'fill_method_used': fill_method,
        'data_quality': 'good' if nan_percentage < 5 else 'fair' if nan_percentage < 15 else 'poor'
    }
    
    # Check data quality
    if total_points < 2:
        raise ValueError("Need at least 2 data points for analysis")
    
    if nan_percentage > 50:
        raise ValueError(f"Too many missing values ({nan_percentage:.1f}%). Data quality insufficient for analysis.")
    
    # Handle NaN values based on fill_method - Default to 'drop' for peak/target calculations
    if nan_count > 0:
        if fill_method == 'raise':
            raise ValueError(f"Found {nan_count} NaN values in {col_name} column. Clean data required.")
        
        elif fill_method == 'drop':
            # Drop NaN rows completely (preserving datetime index alignment)
            data_filled = data.dropna()
            validation_report['points_after_drop'] = len(data_filled)
            validation_report['fill_method_used'] = 'drop'
            if len(data_filled) < 2:
                raise ValueError("Insufficient data points remaining after dropping NaNs")
        
        elif fill_method == 'interpolate':
            # Use linear interpolation with limit to avoid excessive extrapolation
            data_filled = data.interpolate(method='linear', limit=5)
            # Fill any remaining NaNs at edges with forward/backward fill
            data_filled = data_filled.fillna(method='ffill').fillna(method='bfill')
            validation_report['fill_method_used'] = 'interpolate + edge_fill'
            
        elif fill_method == 'forward':
            data_filled = data.fillna(method='ffill')
            
        elif fill_method == 'backward':
            data_filled = data.fillna(method='bfill')
            
        else:
            raise ValueError(f"Unknown fill_method: {fill_method}")
        
        # Check if fill was successful
        remaining_nans = data_filled.isna().sum()
        if remaining_nans > 0 and fill_method != 'drop':
            validation_report['remaining_nans'] = remaining_nans
            validation_report['data_quality'] = 'poor'
    else:
        data_filled = data
        validation_report['fill_method_used'] = 'none_needed'
    
    return data_filled, validation_report


def _calculate_roc_from_series(series, power_col=None):
    """
    Calculate Rate of Change (ROC) in kW per minute from a pandas Series or DataFrame.
    Reuses logic from load_forecasting.py _calculate_roc function.
    Now includes comprehensive NaN handling and data validation.
    
    Args:
        series: pandas Series with datetime index and power values, or DataFrame with power column
        power_col: column name if series is a DataFrame (optional if Series)
    
    Returns:
        pandas DataFrame with Timestamp, Power (kW), and ROC (kW/min) columns
    """
    # Validate and clean input data using DROP method for data integrity
    try:
        cleaned_data, validation_report = validate_and_clean_data(series, power_col, fill_method='drop')
    except Exception as e:
        raise ValueError(f"Data validation failed: {str(e)}")
    
    # Handle both Series and DataFrame inputs with cleaned data
    if isinstance(series, pd.Series):
        df_processed = pd.DataFrame({power_col or 'Power': cleaned_data})
        power_col = power_col or 'Power'
    else:
        # Use only the valid timestamps from cleaned data
        df_processed = series.loc[cleaned_data.index].copy()
        df_processed[power_col] = cleaned_data  # Use cleaned data
        if power_col is None:
            numeric_cols = df_processed.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) == 0:
                raise ValueError("No numeric columns found in DataFrame")
            power_col = numeric_cols[0]
    
    # Ensure datetime index
    if not isinstance(df_processed.index, pd.DatetimeIndex):
        raise ValueError("Series/DataFrame must have datetime index")
    
    df_roc = df_processed.copy()
    
    # Calculate time differences in minutes (reusing load_forecasting.py logic)
    df_roc['time_diff_min'] = df_roc.index.to_series().diff().dt.total_seconds() / 60
    
    # Calculate power differences
    df_roc['power_diff_kw'] = df_roc[power_col].diff()
    
    # Calculate ROC (kW per minute)
    df_roc['roc_kw_per_min'] = df_roc['power_diff_kw'] / df_roc['time_diff_min']
    
    # Create clean output dataframe (matching load_forecasting.py format)
    roc_df = pd.DataFrame({
        'Timestamp': df_roc.index,
        'Power (kW)': df_roc[power_col],
        'ROC (kW/min)': df_roc['roc_kw_per_min']
    })
    
    # Add validation report as metadata
    roc_df._validation_report = validation_report
    
    return roc_df


def roc_forecast(series, horizon=1, power_col=None):
    """
    Generate horizon-minute ahead forecasts for all data points using Rate of Change (ROC) method.
    Reuses existing ROC calculation logic from load_forecasting.py.
    
    This function generates forecasts for ALL points in the series, not rolling forecasts.
    For each point t, it forecasts the value at t+horizon using the ROC at time t.
    
    Args:
        series: pandas Series with datetime index and power values, or DataFrame with power column
        horizon: forecast horizon in minutes (default: 1)
        power_col: column name if series is a DataFrame (optional if Series)
    
    Returns:
        pandas DataFrame with columns:
        - Timestamp: original timestamp
        - Power_Actual (kW): actual power at timestamp
        - ROC (kW/min): rate of change at timestamp
        - Forecast_Timestamp: timestamp + horizon
        - Power_Forecast (kW): forecasted power value
        - Forecast_Available: boolean indicating if forecast could be made
    
    Examples:
        # Using Series
        forecast_df = roc_forecast(power_series, horizon=5)
        
        # Using DataFrame
        forecast_df = roc_forecast(df, horizon=1, power_col='Power_kW')
    """
    
    # Validate inputs
    if not isinstance(series, (pd.Series, pd.DataFrame)):
        raise ValueError("Input must be a pandas Series or DataFrame")
    
    if horizon <= 0:
        raise ValueError("Horizon must be positive")
    
    # Calculate ROC using existing logic
    try:
        roc_df = _calculate_roc_from_series(series, power_col)
    except Exception as e:
        raise ValueError(f"Error calculating ROC: {str(e)}")
    
    # Generate forecasts for all points
    forecasts = []
    
    for idx, row in roc_df.iterrows():
        timestamp = row['Timestamp']
        power_actual = row['Power (kW)']
        roc_value = row['ROC (kW/min)']
        
        # Calculate forecast timestamp
        forecast_timestamp = timestamp + pd.Timedelta(minutes=horizon)
        
        # Generate forecast using ROC method (reusing load_forecasting.py logic)
        # P_hat = P_now + ROC_now * h
        if pd.isna(roc_value):
            # Cannot make forecast without ROC (typically first data point)
            power_forecast = np.nan
            forecast_available = False
        else:
            power_forecast = power_actual + roc_value * horizon
            forecast_available = True
        
        forecasts.append({
            'Timestamp': timestamp,
            'Power_Actual (kW)': power_actual,
            'ROC (kW/min)': roc_value,
            'Forecast_Timestamp': forecast_timestamp,
            'Power_Forecast (kW)': power_forecast,
            'Forecast_Available': forecast_available
        })
    
    forecast_df = pd.DataFrame(forecasts)
    
    return forecast_df


def roc_forecast_with_validation(series, horizon=1, power_col=None, return_metrics=False):
    """
    Generate ROC forecasts and validate against actual future values where available.
    Extended version of roc_forecast that includes validation metrics.
    
    Args:
        series: pandas Series with datetime index and power values, or DataFrame with power column
        horizon: forecast horizon in minutes (default: 1)
        power_col: column name if series is a DataFrame (optional if Series)
        return_metrics: if True, return summary metrics along with forecast DataFrame
    
    Returns:
        pandas DataFrame with forecast + validation columns, optionally metrics dict
    """
    
    # Generate basic forecasts
    forecast_df = roc_forecast(series, horizon, power_col)
    
    # Prepare original data for validation
    if isinstance(series, pd.Series):
        original_data = pd.DataFrame({'Power': series})
        power_col = power_col or 'Power'
    else:
        original_data = series.copy()
        if power_col is None:
            numeric_cols = original_data.select_dtypes(include=[np.number]).columns
            power_col = numeric_cols[0]
    
    # Add validation columns
    validation_results = []
    
    for idx, row in forecast_df.iterrows():
        result = row.to_dict()
        
        if row['Forecast_Available']:
            forecast_timestamp = row['Forecast_Timestamp']
            
            # Find actual value at forecast timestamp
            try:
                # Try exact match first
                if forecast_timestamp in original_data.index:
                    actual_future = original_data.loc[forecast_timestamp, power_col]
                    validation_available = True
                else:
                    # Try nearest time match
                    time_diffs = (original_data.index - forecast_timestamp).abs()
                    nearest_idx = time_diffs.idxmin()
                    
                    # Only use if within reasonable tolerance (e.g., half the horizon)
                    tolerance = pd.Timedelta(minutes=horizon/2)
                    if time_diffs.min() <= tolerance:
                        actual_future = original_data.loc[nearest_idx, power_col]
                        validation_available = True
                    else:
                        actual_future = np.nan
                        validation_available = False
            except:
                actual_future = np.nan
                validation_available = False
            
            # Calculate validation metrics
            if validation_available and not pd.isna(actual_future):
                forecast_error = row['Power_Forecast (kW)'] - actual_future
                abs_error = abs(forecast_error)
                if actual_future != 0:
                    pct_error = (abs_error / abs(actual_future)) * 100
                else:
                    pct_error = np.nan
            else:
                actual_future = np.nan
                forecast_error = np.nan
                abs_error = np.nan
                pct_error = np.nan
                validation_available = False
        else:
            # No forecast available
            actual_future = np.nan
            forecast_error = np.nan
            abs_error = np.nan
            pct_error = np.nan
            validation_available = False
        
        # Add validation columns
        result.update({
            'Power_Actual_Future (kW)': actual_future,
            'Forecast_Error (kW)': forecast_error,
            'Absolute_Error (kW)': abs_error,
            'Percentage_Error (%)': pct_error,
            'Validation_Available': validation_available
        })
        
        validation_results.append(result)
    
    validated_forecast_df = pd.DataFrame(validation_results)
    
    # Calculate summary metrics if requested
    if return_metrics:
        valid_forecasts = validated_forecast_df[
            (validated_forecast_df['Forecast_Available']) & 
            (validated_forecast_df['Validation_Available'])
        ].copy()
        
        if len(valid_forecasts) > 0:
            metrics = {
                'total_points': len(forecast_df),
                'forecasts_made': len(validated_forecast_df[validated_forecast_df['Forecast_Available']]),
                'validations_available': len(valid_forecasts),
                'validation_rate': len(valid_forecasts) / len(validated_forecast_df[validated_forecast_df['Forecast_Available']]) * 100,
                'mae_kw': valid_forecasts['Absolute_Error (kW)'].mean(),
                'rmse_kw': np.sqrt((valid_forecasts['Forecast_Error (kW)'] ** 2).mean()),
                'mean_pct_error': valid_forecasts['Percentage_Error (%)'].mean(),
                'median_pct_error': valid_forecasts['Percentage_Error (%)'].median(),
                'bias_kw': valid_forecasts['Forecast_Error (kW)'].mean()
            }
        else:
            metrics = {
                'total_points': len(forecast_df),
                'forecasts_made': 0,
                'validations_available': 0,
                'validation_rate': 0,
                'mae_kw': np.nan,
                'rmse_kw': np.nan,
                'mean_pct_error': np.nan,
                'median_pct_error': np.nan,
                'bias_kw': np.nan
            }
        
        return validated_forecast_df, metrics
    
    return validated_forecast_df


def convert_roc_backtest_to_long_format(forecast_series_dict, actual_series_dict, horizons):
    """
    Convert ROC backtest results to long format table with columns: t, horizon_min, actual, forecast_p50
    
    Args:
        forecast_series_dict: Dictionary of {horizon: forecast_series}
        actual_series_dict: Dictionary of {horizon: actual_series} 
        horizons: List of forecast horizons in minutes
        
    Returns:
        pd.DataFrame: Long format table with columns [t, horizon_min, actual, forecast_p50]
    """
    try:
        long_data = []
        
        for horizon in horizons:
            if horizon in forecast_series_dict and horizon in actual_series_dict:
                forecast_series = forecast_series_dict[horizon]
                actual_series = actual_series_dict[horizon]
                
                # Align series by index (timestamp)
                aligned_forecast, aligned_actual = forecast_series.align(actual_series, join='inner')
                
                for timestamp in aligned_forecast.index:
                    if pd.notna(aligned_forecast.loc[timestamp]) and pd.notna(aligned_actual.loc[timestamp]):
                        long_data.append({
                            't': timestamp,
                            'horizon_min': horizon,
                            'actual': aligned_actual.loc[timestamp],
                            'forecast_p50': aligned_forecast.loc[timestamp]
                        })
        
        if long_data:
            df_long = pd.DataFrame(long_data)
            df_long = df_long.sort_values(['t', 'horizon_min']).reset_index(drop=True)
            return df_long
        else:
            return pd.DataFrame(columns=['t', 'horizon_min', 'actual', 'forecast_p50'])
    
    except Exception as e:
        print(f"Error converting ROC backtest to long format: {e}")
        return pd.DataFrame(columns=['t', 'horizon_min', 'actual', 'forecast_p50'])


def compute_residual_quantiles_by_horizon(df_long, quantiles=[0.1, 0.5, 0.9]):
    """
    Compute residual quantiles by horizon from long format backtest results
    
    Args:
        df_long: DataFrame with columns [t, horizon_min, actual, forecast_p50]
        quantiles: List of quantiles to compute (default: [0.1, 0.5, 0.9] for P10, P50, P90)
        
    Returns:
        pd.DataFrame: Quantiles by horizon with columns [horizon_min, residual_p10, residual_p50, residual_p90]
    """
    try:
        if df_long.empty or 'actual' not in df_long.columns or 'forecast_p50' not in df_long.columns:
            return pd.DataFrame(columns=['horizon_min', 'residual_p10', 'residual_p50', 'residual_p90'])
        
        # Calculate residuals (forecast - actual)
        df_long = df_long.copy()
        df_long['residual'] = df_long['forecast_p50'] - df_long['actual']
        
        # Group by horizon and compute quantiles
        quantile_results = []
        for horizon in sorted(df_long['horizon_min'].unique()):
            horizon_data = df_long[df_long['horizon_min'] == horizon]
            residuals = horizon_data['residual'].dropna()
            
            if len(residuals) > 0:
                quantile_values = residuals.quantile(quantiles).values
                result = {'horizon_min': horizon}
                
                # Map quantiles to column names
                for i, q in enumerate(quantiles):
                    if q == 0.1:
                        result['residual_p10'] = quantile_values[i]
                    elif q == 0.5:
                        result['residual_p50'] = quantile_values[i]
                    elif q == 0.9:
                        result['residual_p90'] = quantile_values[i]
                
                quantile_results.append(result)
        
        if quantile_results:
            return pd.DataFrame(quantile_results)
        else:
            return pd.DataFrame(columns=['horizon_min', 'residual_p10', 'residual_p50', 'residual_p90'])
    
    except Exception as e:
        print(f"Error computing residual quantiles: {e}")
        return pd.DataFrame(columns=['horizon_min', 'residual_p10', 'residual_p50', 'residual_p90'])


def generate_p90_forecast_bands(df_long, residual_quantiles):
    """
    Generate P90 forecast bands by adding residual quantiles to P50 forecasts
    
    Args:
        df_long: DataFrame with columns [t, horizon_min, actual, forecast_p50]
        residual_quantiles: DataFrame with quantiles by horizon
        
    Returns:
        pd.DataFrame: Long format with added columns [forecast_p10, forecast_p90]
    """
    try:
        if df_long.empty or residual_quantiles.empty:
            return df_long.copy()
        
        df_result = df_long.copy()
        
        # Initialize new columns
        df_result['forecast_p10'] = np.nan
        df_result['forecast_p90'] = np.nan
        
        # Add quantiles by horizon
        for _, row in residual_quantiles.iterrows():
            horizon = row['horizon_min']
            horizon_mask = df_result['horizon_min'] == horizon
            
            if 'residual_p10' in row and pd.notna(row['residual_p10']):
                df_result.loc[horizon_mask, 'forecast_p10'] = (
                    df_result.loc[horizon_mask, 'forecast_p50'] + row['residual_p10']
                )
            
            if 'residual_p90' in row and pd.notna(row['residual_p90']):
                df_result.loc[horizon_mask, 'forecast_p90'] = (
                    df_result.loc[horizon_mask, 'forecast_p50'] + row['residual_p90']
                )
        
        return df_result
    
    except Exception as e:
        print(f"Error generating P90 forecast bands: {e}")
        return df_long.copy()


def load_vendor_battery_database():
    """Load vendor battery database from JSON file."""
    try:
        with open('vendor_battery_database.json', 'r') as f:
            battery_db = json.load(f)
        return battery_db
    except FileNotFoundError:
        st.error("âŒ Battery database file 'vendor_battery_database.json' not found")
        return None
    except json.JSONDecodeError:
        st.error("âŒ Error parsing battery database JSON file")
        return None
    except Exception as e:
        st.error(f"âŒ Error loading battery database: {str(e)}")
        return None


def get_battery_capacity_range(battery_db):
    """Get the capacity range from battery database."""
    if not battery_db:
        return 200, 250, 225  # Default fallback values (all int)
    
    capacities = []
    for battery_id, spec in battery_db.items():
        capacity = spec.get('energy_kWh', 0)
        if capacity > 0:
            capacities.append(int(capacity))  # Ensure int type
    
    if capacities:
        min_cap = min(capacities)
        max_cap = max(capacities)
        default_cap = int(np.mean(capacities))
        return min_cap, max_cap, default_cap
    else:
        return 200, 250, 225  # Default fallback (all int)


def _render_battery_selection_dropdown():
    """
    Render independent battery selection dropdown that's always visible when data is available.
    This function should be called when a file is uploaded and data is available.
    """
    with st.container():
        st.markdown("#### 7. ðŸ“‹ Tabled Analysis")
        
        # Battery selection dropdown
        battery_db = load_vendor_battery_database()
        
        if battery_db:
            # Create battery options for dropdown
            battery_options = {}
            battery_list = []
            
            for battery_id, spec in battery_db.items():
                company = spec.get('company', 'Unknown')
                model = spec.get('model', battery_id)
                capacity = spec.get('energy_kWh', 0)
                power = spec.get('power_kW', 0)
                
                label = f"{company} {model} ({capacity}kWh, {power}kW)"
                battery_options[label] = {
                    'id': battery_id,
                    'spec': spec,
                    'capacity_kwh': capacity,
                    'power_kw': power
                }
                battery_list.append(label)
            
            # Sort battery list for better UX
            battery_list.sort()
            battery_list.insert(0, "-- Select a Battery --")
            
            # Battery selection dropdown
            selected_battery_label = st.selectbox(
                "ðŸ”‹ Select Battery for Analysis:",
                options=battery_list,
                index=0,
                key="independent_battery_selection",
                help="Choose a battery from the vendor database to view specifications and analysis"
            )
            
            # Display selected battery information
            if selected_battery_label != "-- Select a Battery --":
                selected_battery_data = battery_options[selected_battery_label]
                battery_spec = selected_battery_data['spec']
                
                # Display battery specifications in a table format
                st.markdown("**ðŸ“Š Battery Specifications:**")
                spec_data = {
                    'Parameter': ['Company', 'Model', 'Energy Capacity', 'Power Rating', 'C-Rate', 'Voltage', 'Lifespan', 'Cooling'],
                    'Value': [
                        battery_spec.get('company', 'N/A'),
                        battery_spec.get('model', 'N/A'),
                        f"{battery_spec.get('energy_kWh', 0)} kWh",
                        f"{battery_spec.get('power_kW', 0)} kW",
                        f"{battery_spec.get('c_rate', 0)}C",
                        f"{battery_spec.get('voltage_V', 0)} V",
                        f"{battery_spec.get('lifespan_years', 0)} years",
                        battery_spec.get('cooling', 'N/A')
                    ]
                }
                df_specs = pd.DataFrame(spec_data)
                st.dataframe(df_specs, use_container_width=True, hide_index=True)
                
                # Store selected battery in session state for use in other parts of the analysis
                st.session_state.tabled_analysis_selected_battery = {
                    'id': selected_battery_data['id'],
                    'spec': battery_spec,
                    'capacity_kwh': selected_battery_data['capacity_kwh'],
                    'power_kw': selected_battery_data['power_kw'],
                    'label': selected_battery_label
                }
                
                return selected_battery_data
            else:
                st.info("ðŸ’¡ Select a battery from the dropdown above to view detailed specifications and analysis.")
                return None
        else:
            st.error("âŒ Battery database not available")
            return None


def _render_battery_quantity_recommendation(max_power_shaving_required, recommended_energy_capacity):
    """
    Render battery quantity recommendation section between Tabled Analysis and Battery Sizing Analysis.
    
    Args:
        max_power_shaving_required: Maximum power shaving required (kW)
        recommended_energy_capacity: Maximum required energy (kWh)
    """
    st.markdown("#### 7.1 ðŸ”¢ Battery Quantity Recommendation")
    
    # Check if user has selected a battery from the tabled analysis dropdown
    if hasattr(st.session_state, 'tabled_analysis_selected_battery') and st.session_state.tabled_analysis_selected_battery:
        selected_battery = st.session_state.tabled_analysis_selected_battery
        battery_spec = selected_battery['spec']
        battery_name = selected_battery['label']
        
        # Extract battery specifications
        battery_power_kw = battery_spec.get('power_kW', 0)
        battery_energy_kwh = battery_spec.get('energy_kWh', 0)
        
        if battery_power_kw > 0 and battery_energy_kwh > 0:
            # Calculate recommended quantities
            # Power Rating based quantity: roundup(Max Power Shaving Required / Battery Power Rating)
            qty_for_power = max_power_shaving_required / battery_power_kw if battery_power_kw > 0 else 0
            qty_for_power_rounded = int(np.ceil(qty_for_power))
            
            # Energy Capacity based quantity: roundup(Max Required Energy / Battery Energy Capacity / DOD / Efficiency) 
            qty_for_energy = recommended_energy_capacity / battery_energy_kwh / 0.9 / 0.93 if battery_energy_kwh > 0 else 0
            qty_for_energy_rounded = int(np.ceil(qty_for_energy))
            
            # Recommended quantity: maximum of the two
            recommended_qty = max(qty_for_power_rounded, qty_for_energy_rounded)
            
            # Display metrics showing the calculation
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric(
                    "Power-Based Qty", 
                    f"{qty_for_power_rounded} units",
                    help=f"Based on {max_power_shaving_required:.1f} kW Ã· {battery_power_kw} kW"
                )
                st.caption(f"Calculation: âŒˆ{max_power_shaving_required:.1f} Ã· {battery_power_kw}âŒ‰")
            
            with col2:
                st.metric(
                    "Energy-Based Qty", 
                    f"{qty_for_energy_rounded} units",
                    help=f"Based on {recommended_energy_capacity:.1f} kWh Ã· {battery_energy_kwh} kWh Ã· 0.9 Ã· 0.93"
                )
                st.caption(f"Calculation: âŒˆ{recommended_energy_capacity:.1f} Ã· {battery_energy_kwh} Ã· 0.9 Ã· 0.93âŒ‰")
            
            with col3:
                st.metric(
                    "Recommended Qty", 
                    f"{recommended_qty} units",
                    delta=f"{recommended_qty} units",
                    help="Maximum of power-based and energy-based quantities"
                )
                st.caption("Auto-recommended based on max requirement")
            
            # Allow user to override the recommended quantity
            st.markdown("**ðŸŽ›ï¸ Battery Quantity Configuration:**")
            
            # User input for quantity with recommended as default
            user_selected_qty = st.number_input(
                "Select Battery Quantity:",
                min_value=1,
                max_value=200,
                value=recommended_qty,
                step=1,
                key="v2_battery_quantity_selection",
                help=f"Auto-recommended: {recommended_qty} units. You can adjust this value if needed."
            )
            
            # Show impact of user selection
            total_power_capacity = user_selected_qty * battery_power_kw
            total_energy_capacity = user_selected_qty * battery_energy_kwh
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric(
                    "Total Power Capacity",
                    f"{total_power_capacity:.1f} kW",
                    f"{user_selected_qty} Ã— {battery_power_kw} kW"
                )
            
            with col2:
                st.metric(
                    "Total Energy Capacity", 
                    f"{total_energy_capacity:.1f} kWh",
                    f"{user_selected_qty} Ã— {battery_energy_kwh} kWh"
                )
            
            with col3:
                # Calculate coverage percentages
                power_coverage = (total_power_capacity / max_power_shaving_required * 100) if max_power_shaving_required > 0 else 100
                energy_coverage = (total_energy_capacity / recommended_energy_capacity * 100) if recommended_energy_capacity > 0 else 100
                
                overall_coverage = min(power_coverage, energy_coverage)
                
                coverage_color = "normal" if overall_coverage >= 100 else "inverse"
                st.metric(
                    "Coverage",
                    f"{overall_coverage:.1f}%",
                    delta_color=coverage_color,
                    help="Minimum of power and energy coverage percentages"
                )
            
            # Store the selected quantity in session state for use in sizing analysis
            st.session_state.tabled_analysis_battery_quantity = user_selected_qty
            
            # Provide guidance on the selection and integration information
            if user_selected_qty == recommended_qty:
                st.success(f"âœ… **Optimal Configuration**: Using auto-recommended quantity of {recommended_qty} units based on your requirements.")
            elif user_selected_qty > recommended_qty:
                st.info(f"â„¹ï¸ **Oversized Configuration**: You've selected {user_selected_qty} units, which is {user_selected_qty - recommended_qty} units more than the recommended {recommended_qty} units. This provides extra capacity margin.")
            else:
                st.warning(f"âš ï¸ **Undersized Configuration**: You've selected {user_selected_qty} units, which is {recommended_qty - user_selected_qty} units less than the recommended {recommended_qty} units. This may not fully meet your requirements.")
            
            # Integration feedback
            st.info(f"ðŸ”„ **Integration Active**: The selected quantity ({user_selected_qty} units) will be automatically used in the 'ðŸ“Š Battery Operation Simulation' section below, replacing any auto-calculated values.")
            
        else:
            st.error("âŒ Selected battery has invalid power or energy specifications")
    
    else:
        st.warning("âš ï¸ **No Battery Selected**: Please select a battery from the 'ðŸ“‹ Tabled Analysis' dropdown above to see quantity recommendations.")
        st.info("ðŸ’¡ Battery quantity will be automatically calculated based on your requirements once a battery is selected.")


def _render_battery_sizing_analysis(max_power_shaving_required, recommended_energy_capacity, total_md_cost):
    """
    Render comprehensive battery sizing and financial analysis table.
    
    Args:
        max_power_shaving_required: Maximum power shaving required (kW)
        recommended_energy_capacity: Maximum TOU excess power requirement (kW)  
        total_md_cost: Total MD cost impact (RM)
    """
    st.markdown("#### 7.2 ðŸ”‹ Battery Sizing & Financial Analysis")
    
    # Check if user has selected a battery from the tabled analysis dropdown
    if hasattr(st.session_state, 'tabled_analysis_selected_battery') and st.session_state.tabled_analysis_selected_battery:
        selected_battery = st.session_state.tabled_analysis_selected_battery
        battery_spec = selected_battery['spec']
        battery_name = selected_battery['label']
        
        st.info(f"ðŸ”‹ **Analysis based on selected battery:** {battery_name}")
        
        # Extract battery specifications
        battery_power_kw = battery_spec.get('power_kW', 0)
        battery_energy_kwh = battery_spec.get('energy_kWh', 0)
        battery_lifespan_years = battery_spec.get('lifespan_years', 15)
        
        if battery_power_kw > 0 and battery_energy_kwh > 0:
            # Use the user-selected quantity from the quantity recommendation section
            bess_quantity = getattr(st.session_state, 'tabled_analysis_battery_quantity', 1)
            
            # Calculate quantities that would be needed (for reference only)
            qty_for_power = max_power_shaving_required / battery_power_kw if battery_power_kw > 0 else 0
            qty_for_power_rounded = int(np.ceil(qty_for_power))
            qty_for_excess = recommended_energy_capacity / battery_energy_kwh if battery_energy_kwh > 0 else 0
            qty_for_excess_rounded = int(np.ceil(qty_for_excess))
            
            # Calculate total system specifications based on user-selected quantity
            total_power_kw = bess_quantity * battery_power_kw
            total_energy_kwh = bess_quantity * battery_energy_kwh
            
            # Column 4: MD shaved (actual impact with this battery configuration)
            # Use the total power capacity from the larger battery quantity (BESS quantity)
            md_shaved_kw = total_power_kw  # Total power from the BESS system
            md_shaving_percentage = (md_shaved_kw / max_power_shaving_required * 100) if max_power_shaving_required > 0 else 0

            # Column 5: Cost of batteries
            estimated_cost_per_kwh = 1400  # RM per kWh (consistent with main app)
            total_battery_cost = total_energy_kwh * estimated_cost_per_kwh
            
            # Create analysis table
            analysis_data = {
                'Analysis Parameter': [
                    'Units for Selected Power Requirement',
                    'Units for Selected Energy Capacity',
                    'Total BESS Quantity Required',
                    'Total System Power Capacity',
                    'Total System Energy Capacity',
                    'Actual MD Shaved',
                    'MD Shaving Coverage',
                    'Total Battery Investment'
                ],
                'Value': [
                    f"{qty_for_power_rounded} units (for {max_power_shaving_required:.1f} kW)",
                    f"{qty_for_excess_rounded} units (for {recommended_energy_capacity:.1f} kWh)", 
                    f"{bess_quantity} units",
                    f"{total_power_kw:.1f} kW",
                    f"{total_energy_kwh:.1f} kWh",
                    f"{md_shaved_kw:.1f} kW",
                    f"{md_shaving_percentage:.1f}%",
                    f"RM {total_battery_cost:,.0f}"
                ],
                'Calculation Basis': [
                    f"Selected Power Requirement: {max_power_shaving_required:.1f} kW Ã· {battery_power_kw} kW/unit",
                    f"Selected Energy Capacity: {recommended_energy_capacity:.1f} kWh Ã· {battery_energy_kwh} kWh/unit",
                    "Higher of power or energy requirement",
                    f"{bess_quantity} units Ã— {battery_power_kw} kW/unit",
                    f"{bess_quantity} units Ã— {battery_energy_kwh} kWh/unit", 
                    f"{bess_quantity} units Ã— {battery_power_kw} kW/unit = {total_power_kw:.1f} kW",
                    f"MD Shaved Ã· Selected Power Requirement Ã— 100%",
                    f"{total_energy_kwh:.1f} kWh Ã— RM {estimated_cost_per_kwh}/kWh"
                ]
            }
            
            df_analysis = pd.DataFrame(analysis_data)
            
            # Display the dataframe without styling for consistent formatting
            st.dataframe(df_analysis, use_container_width=True, hide_index=True)
            
            # Key insights - only showing total investment
            col1, col2, col3 = st.columns(3)
            
            with col2:  # Center the single metric
                st.metric(
                    "ðŸ’° Total Investment", 
                    f"RM {total_battery_cost:,.0f}",
                    help="Total cost for complete BESS installation"
                )
            
            # Analysis insights
            if bess_quantity > 0:
                st.success(f"""
                **ðŸ“Š Analysis Summary:**
                - **Battery Selection**: {battery_name}
                - **System Configuration**: {bess_quantity} units providing {total_power_kw:.1f} kW / {total_energy_kwh:.1f} kWh
                - **MD Shaving Capability**: {md_shaving_percentage:.1f}% coverage of maximum demand events
                - **Investment Required**: RM {total_battery_cost:,.0f} for complete BESS installation
                """)
                
                if md_shaving_percentage < 100:
                    st.warning(f"""
                    âš ï¸ **Partial Coverage Notice**: 
                    This battery configuration covers {md_shaving_percentage:.1f}% of maximum power shaving requirements.
                    Additional {max_power_shaving_required - md_shaved_kw:.1f} kW capacity may be needed for complete coverage.
                    """)
            else:
                st.error("âŒ Invalid battery configuration - no units required")
                
        else:
            st.error("âŒ Selected battery has invalid power or energy specifications")
            
    else:
        st.warning("âš ï¸ **No Battery Selected**: Please select a battery from the 'ðŸ“‹ Tabled Analysis' dropdown above to perform sizing analysis.")
        st.info("ðŸ’¡ Navigate to the top of this page and select a battery from the dropdown to see detailed sizing and financial analysis.")


def get_battery_options_for_capacity(battery_db, target_capacity, tolerance=5):
    """Get batteries that match the target capacity within tolerance."""
    if not battery_db:
        return []
    
    matching_batteries = []
    for battery_id, spec in battery_db.items():
        battery_capacity = spec.get('energy_kWh', 0)
        if abs(battery_capacity - target_capacity) <= tolerance:
            matching_batteries.append({
                'id': battery_id,
                'spec': spec,
                'capacity_kwh': battery_capacity,
                'power_kw': spec.get('power_kW', 0),
                'c_rate': spec.get('c_rate', 0)
            })
    
    # Sort by closest match to target capacity
    matching_batteries.sort(key=lambda x: abs(x['capacity_kwh'] - target_capacity))
    return matching_batteries


def _render_v2_battery_controls(max_power_shaving_required=None, max_required_energy=None):
    """
    Render battery capacity controls in the main content area (right side).
    
    Args:
        max_power_shaving_required: Maximum power shaving required from analysis (kW)
        max_required_energy: Maximum required energy from analysis (kWh)
    """
    
    st.markdown("### ðŸ”‹ Battery Configuration")
    st.markdown("**Configure battery specifications for MD shaving analysis.**")
    
    # Load battery database
    battery_db = load_vendor_battery_database()
    
    if not battery_db:
        st.error("âŒ Battery database not available")
        return None
    
    # Get capacity range
    min_cap, max_cap, default_cap = get_battery_capacity_range(battery_db)
    
    # Selection method
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("**Battery Selection Method:** By Specific Model")
        st.caption("Choose specific battery model from database")
    
    with col2:
        st.metric("Available Range", f"{min_cap}-{max_cap} kWh")
    
    # Battery selection by specific model only
    # Create battery options
    battery_options = {}
    for battery_id, spec in battery_db.items():
        label = f"{spec.get('company', 'Unknown')} {spec.get('model', 'Unknown')} ({spec.get('energy_kWh', 0)}kWh)"
        battery_options[label] = {
            'id': battery_id,
            'spec': spec,
            'capacity': spec.get('energy_kWh', 0)
        }
    
    selected_battery_label = st.selectbox(
        "Select Battery Model:",
        options=list(battery_options.keys()),
        key="v2_main_battery_model",
        help="Choose specific battery model from database"
    )
    
    if selected_battery_label:
        selected_battery_data = battery_options[selected_battery_label]
        active_battery_spec = selected_battery_data['spec']
        selected_capacity = selected_battery_data['capacity']
        
        # Display selected battery specs
        st.markdown("#### ðŸ“Š Battery Specifications:")
        
        # Create specifications table
        specs_data = [
            ["Company", active_battery_spec.get('company', 'Unknown')],
            ["Model", active_battery_spec.get('model', 'Unknown')],
            ["Energy Capacity", f"{active_battery_spec.get('energy_kWh', 0)} kWh"],
            ["Power Rating", f"{active_battery_spec.get('power_kW', 0)} kW"],
            ["C Rate", f"{active_battery_spec.get('c_rate', 0)}C"],
            ["Voltage", f"{active_battery_spec.get('voltage_V', 0)} V"],
            ["Lifespan", f"{active_battery_spec.get('lifespan_years', 0)} years"],
            ["Cooling", active_battery_spec.get('cooling', 'N/A')]
        ]
        
        specs_df = pd.DataFrame(specs_data, columns=["Parameter", "Value"])
        st.table(specs_df)
        
        # Battery Quantity Recommendation section
        st.markdown("#### 7.1 ðŸ”¢ Battery Quantity Recommendation")
        
        # Use actual calculated values from analysis, fallback to default if not provided
        max_power_required = max_power_shaving_required if max_power_shaving_required is not None else 1734.4  # kW
        max_energy_required = max_required_energy if max_required_energy is not None else 7884.8  # kWh
        
        # Display source of values
        if max_power_shaving_required is not None and max_required_energy is not None:
            st.info("ðŸ“Š **Values sourced from Section 6.5 Battery Sizing Analysis**")
        else:
            st.warning("âš ï¸ **Using default values** - Run analysis in Section 6 to get accurate calculations")
        
        # Extract battery specifications for calculations
        battery_power_kw = active_battery_spec.get('power_kW', 0)
        battery_energy_kwh = active_battery_spec.get('energy_kWh', 0)
        
        # Initialize variables that will be needed later
        total_power_capacity = 0
        total_energy_capacity = 0
        overall_coverage = 0
        
        if battery_power_kw > 0 and battery_energy_kwh > 0:
            # Calculate recommended quantities
            # Power-based quantity: ceiling(Max Power Required / Battery Power Rating)
            qty_power = np.ceil(max_power_required / battery_power_kw) if battery_power_kw > 0 else 0
            
            # Energy-based quantity: ceiling(Max Energy Required / Battery Energy / DOD / Efficiency)
            dod = 0.9  # Depth of Discharge
            efficiency = 0.93  # Battery efficiency
            qty_energy = np.ceil(max_energy_required / battery_energy_kwh / dod / efficiency) if battery_energy_kwh > 0 else 0
            
            # Recommended quantity: maximum of the two
            recommended_qty = max(int(qty_power), int(qty_energy))
            
            # Display quantity recommendations
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Power-Based Qty â„¹ï¸", f"{int(qty_power)} units")
                st.caption(f"Calculation: âŒˆ{max_power_required} Ã· {battery_power_kw}âŒ‰")
            
            with col2:
                st.metric("Energy-Based Qty â„¹ï¸", f"{int(qty_energy)} units") 
                st.caption(f"Calculation: âŒˆ{max_energy_required} Ã· {battery_energy_kwh} Ã· {dod} Ã· {efficiency}âŒ‰")
            
            with col3:
                st.metric("Recommended Qty â„¹ï¸", f"{recommended_qty} units", delta=f"â†‘ {recommended_qty} units")
                st.caption("Auto-recommended based on max requirement")
        else:
            st.warning("âš ï¸ Battery specifications incomplete for quantity calculation")
    else:
        active_battery_spec = None
        selected_capacity = default_cap
    
    # Battery Quantity Configuration
    st.markdown("#### ðŸ”¢ Battery Quantity Configuration:")
    
    # Get the recommended quantity from the previous calculation (if available)
    if active_battery_spec and battery_power_kw > 0 and battery_energy_kwh > 0:
        default_qty = recommended_qty
    else:
        default_qty = 37  # Fallback default
    
    # Battery quantity selector with +/- controls
    st.markdown("**Select Battery Quantity:**")
    
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col1:
        if st.button("âž–", key="decrease_qty", help="Decrease quantity by 1"):
            if "battery_quantity" not in st.session_state:
                st.session_state.battery_quantity = default_qty
            if st.session_state.battery_quantity > 1:
                st.session_state.battery_quantity -= 1
    
    with col2:
        # Initialize session state if not exists
        if "battery_quantity" not in st.session_state:
            st.session_state.battery_quantity = default_qty
            
        # Display current quantity
        selected_quantity = st.number_input(
            "",
            min_value=1,
            max_value=1000,
            value=st.session_state.battery_quantity,
            key="qty_input",
            label_visibility="collapsed"
        )
        st.session_state.battery_quantity = selected_quantity
    
    with col3:
        if st.button("âž•", key="increase_qty", help="Increase quantity by 1"):
            if "battery_quantity" not in st.session_state:
                st.session_state.battery_quantity = default_qty
            if st.session_state.battery_quantity < 1000:
                st.session_state.battery_quantity += 1
    
    # Calculate total capacities and coverage based on selected quantity
    if active_battery_spec and battery_power_kw > 0 and battery_energy_kwh > 0:
        total_power_capacity = st.session_state.battery_quantity * battery_power_kw
        total_energy_capacity = st.session_state.battery_quantity * battery_energy_kwh
        
        # Calculate coverage percentage (based on max requirements)
        power_coverage = (total_power_capacity / max_power_required) * 100 if max_power_required > 0 else 0
        energy_coverage = (total_energy_capacity / max_energy_required) * 100 if max_energy_required > 0 else 0
        overall_coverage = min(power_coverage, energy_coverage)  # Limiting factor
        
        # Display capacity metrics
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                "Total Power Capacity",
                f"{total_power_capacity:.1f} kW",
                delta=f"â†‘ {st.session_state.battery_quantity} Ã— {battery_power_kw} kW"
            )
        
        with col2:
            st.metric(
                "Total Energy Capacity", 
                f"{total_energy_capacity:.1f} kWh",
                delta=f"â†‘ {st.session_state.battery_quantity} Ã— {battery_energy_kwh} kWh"
            )
        
        with col3:
            coverage_color = "normal"
            if overall_coverage >= 100:
                coverage_color = "normal"
            elif overall_coverage >= 80:
                coverage_color = "normal" 
            else:
                coverage_color = "inverse"
                
            st.metric(
                "Coverage",
                f"{overall_coverage:.1f}%",
                delta=None
            )
        
        # Configuration status messages
        if st.session_state.battery_quantity == default_qty:
            st.success("âœ… **Optimal Configuration:** Using auto-recommended quantity of {} units based on your requirements.".format(default_qty))
        else:
            st.info(f"ðŸ”§ **Custom Configuration:** Using {st.session_state.battery_quantity} units (recommended: {default_qty} units)")
        
        # Integration notice
        st.info("ðŸ“Š **Integration Active:** The selected quantity ({} units) will be automatically used in the 'ðŸ“Š Battery Operation Simulation' section below, replacing any auto-calculated values.".format(st.session_state.battery_quantity))
        
        # Battery Sizing & Financial Analysis Section
        st.markdown("#### 7.2 ðŸ’° Battery Sizing & Financial Analysis")
        
        # Analysis header with battery info
        battery_model = active_battery_spec.get('model', 'Unknown')
        battery_company = active_battery_spec.get('company', 'Unknown')
        st.info(f"ðŸ”‹ **Analysis based on selected battery:** {battery_company} {battery_model} ({battery_energy_kwh}kWh, {battery_power_kw}kW)")
        
        # Analysis calculations
        max_power_required = 1734.4  # kW - from requirements analysis
        max_energy_required = 7884.8  # kWh - from energy analysis
        selected_qty = st.session_state.battery_quantity
        
        # Calculate units needed based on power and energy
        units_for_power = int(np.ceil(max_power_required / battery_power_kw)) if battery_power_kw > 0 else 0
        units_for_energy = int(np.ceil(max_energy_required / battery_energy_kwh)) if battery_energy_kwh > 0 else 0
        
        # System capacities based on selected quantity
        total_system_power = selected_qty * battery_power_kw
        total_system_energy = selected_qty * battery_energy_kwh
        
        # MD shaving calculations
        actual_md_shaved = total_system_power  # Assuming full power utilization
        md_shaving_coverage = (actual_md_shaved / max_power_required) * 100 if max_power_required > 0 else 0
        
        # Financial calculations (using RM 1400/kWh as per screenshot)
        cost_per_kwh = 1400  # RM per kWh
        total_battery_investment = total_system_energy * cost_per_kwh
        
        # Create analysis table
        analysis_data = [
            ["Units for Selected Power Requirement", f"{units_for_power} units (for {max_power_required} kW)", f"Selected Power Requirement: {max_power_required} kW Ã· {battery_power_kw} kW/unit"],
            ["Units for Selected Energy Capacity", f"{units_for_energy} units (for {max_energy_required} kWh)", f"Selected Energy Capacity: {max_energy_required} kWh Ã· {battery_energy_kwh} kWh/unit"],
            ["Total BESS Quantity Required", f"{selected_qty} units", "Higher of power or energy requirement"],
            ["Total System Power Capacity", f"{total_system_power:.1f} kW", f"{selected_qty} units Ã— {battery_power_kw} kW/unit"],
            ["Total System Energy Capacity", f"{total_system_energy:.1f} kWh", f"{selected_qty} units Ã— {battery_energy_kwh} kWh/unit"],
            ["Actual MD Shaved", f"{actual_md_shaved:.1f} kW", f"{selected_qty} units Ã— {battery_power_kw} kW/unit = {actual_md_shaved:.1f} kW"],
            ["MD Shaving Coverage", f"{md_shaving_coverage:.1f}%", f"MD Shaved Ã· Selected Power Requirement Ã— 100%"],
            ["Total Battery Investment", f"RM {total_battery_investment:,.0f}", f"{total_system_energy:.1f} kWh Ã— RM {cost_per_kwh}/kWh"]
        ]
        
        analysis_df = pd.DataFrame(analysis_data, columns=["Analysis Parameter", "Value", "Calculation Basis"])
        st.table(analysis_df)
        
        # Total Investment Display
        st.markdown("### ðŸ’° Total Investment â„¹ï¸")
        st.markdown(f"<h1 style='text-align: center; color: #2E8B57; font-size: 3em; margin: 0.5em 0;'>RM {total_battery_investment:,}</h1>", unsafe_allow_html=True)
        
        run_analysis = True  # Always enable analysis when battery is properly configured
    else:
        st.warning("âš ï¸ Battery specifications incomplete for quantity configuration")
        run_analysis = False
    
    # Return the selected battery configuration with consistent key names
    battery_config = {
        'selection_method': 'By Specific Model',
        'selected_capacity': selected_capacity if 'selected_capacity' in locals() else default_cap,
        'active_battery_spec': active_battery_spec if 'active_battery_spec' in locals() else {},
        'selected_quantity': st.session_state.get('battery_quantity', default_qty),
        'total_power_capacity': total_power_capacity if 'total_power_capacity' in locals() else 0,
        'total_energy_capacity': total_energy_capacity if 'total_energy_capacity' in locals() else 0,
        'coverage_percentage': overall_coverage if 'overall_coverage' in locals() else 0,
        'run_analysis': run_analysis
    }
    
    return battery_config


def _get_soc_aware_discharge_strategy(current_soc_percent, demand_excess_kw, battery_power_kw):
    """
    SOC-aware conservative discharge strategy for battery management.
    
    Args:
        current_soc_percent (float): Current state of charge as percentage
        demand_excess_kw (float): Excess demand above target that needs shaving
        battery_power_kw (float): Maximum battery discharge power
        
    Returns:
        dict: Discharge strategy with power_kw and reasoning
    """
    # SOC-Aware Strategy Parameters (Conservative)
    MIN_SOC_THRESHOLD = 20.0  # Keep 20% minimum charge for safety
    EXCESS_DISCHARGE_RATE = 0.6  # Use 60% of excess for conservative approach
    
    # Safety check: Don't discharge below minimum SOC
    if current_soc_percent <= MIN_SOC_THRESHOLD:
        return {
            'power_kw': 0,
            'reasoning': f"SOC too low ({current_soc_percent:.1f}%) - maintaining {MIN_SOC_THRESHOLD}% minimum reserve"
        }
    
    # Conservative discharge: Only use 60% of demand excess
    conservative_demand = demand_excess_kw * EXCESS_DISCHARGE_RATE
    
    # Limit to battery capacity
    discharge_power = min(conservative_demand, battery_power_kw)
    
    # Additional SOC-based power limiting for very low SOC
    if current_soc_percent < 30.0:
        # Further reduce power when approaching minimum SOC
        soc_limiter = (current_soc_percent - MIN_SOC_THRESHOLD) / (30.0 - MIN_SOC_THRESHOLD)
        discharge_power *= soc_limiter
    
    return {
        'power_kw': discharge_power,
        'reasoning': f"SOC-Aware: {discharge_power:.1f}kW (60% of {demand_excess_kw:.1f}kW excess, SOC: {current_soc_percent:.1f}%)"
    }


def _get_tariff_aware_discharge_strategy(current_soc_percent, demand_excess_kw, battery_power_kw):
    """
    Default tariff-aware aggressive discharge strategy for battery management.
    
    Args:
        current_soc_percent (float): Current state of charge as percentage
        demand_excess_kw (float): Excess demand above target that needs shaving
        battery_power_kw (float): Maximum battery discharge power
        
    Returns:
        dict: Discharge strategy with power_kw and reasoning
    """
    # Default Strategy Parameters (Aggressive)
    MIN_SOC_THRESHOLD = 5.0   # Allow discharge to 5% for maximum shaving
    EXCESS_DISCHARGE_RATE = 0.8  # Use 80% of excess for aggressive approach
    
    # Safety check: Don't discharge below minimum SOC
    if current_soc_percent <= MIN_SOC_THRESHOLD:
        return {
            'power_kw': 0,
            'reasoning': f"SOC critical ({current_soc_percent:.1f}%) - maintaining {MIN_SOC_THRESHOLD}% emergency reserve"
        }
    
    # Aggressive discharge: Use 80% of demand excess
    aggressive_demand = demand_excess_kw * EXCESS_DISCHARGE_RATE
    
    # Limit to battery capacity
    discharge_power = min(aggressive_demand, battery_power_kw)
    
    return {
        'power_kw': discharge_power,
        'reasoning': f"Default: {discharge_power:.1f}kW (80% of {demand_excess_kw:.1f}kW excess, SOC: {current_soc_percent:.1f}%)"
    }


def _get_strategy_aware_discharge(strategy_mode, current_soc_percent, demand_excess_kw, battery_power_kw):
    """
    Router function to select appropriate discharge strategy based on user selection.
    
    Args:
        strategy_mode (str): Either "Default Shaving" or "SOC-Aware"
        current_soc_percent (float): Current state of charge as percentage
        demand_excess_kw (float): Excess demand above target that needs shaving
        battery_power_kw (float): Maximum battery discharge power
        
    Returns:
        dict: Discharge strategy with power_kw, reasoning, and strategy_type
    """
    if strategy_mode == "SOC-Aware":
        result = _get_soc_aware_discharge_strategy(current_soc_percent, demand_excess_kw, battery_power_kw)
        result['strategy_type'] = 'SOC-Aware (Conservative)'
    else:  # Default Shaving
        result = _get_tariff_aware_discharge_strategy(current_soc_percent, demand_excess_kw, battery_power_kw)
        result['strategy_type'] = 'Default (Aggressive)'
    
    return result


def render_md_shaving_v2():
    """
    Main function to display the MD Shaving Solution V2 interface.
    Enhanced implementation with file upload functionality.
    """
    st.title("ðŸ”‹ MD Shaving Solution V2")
    st.markdown("""
    **Next-generation Maximum Demand (MD) shaving analysis** with enhanced features and advanced optimization algorithms.
    
    ðŸ†• **V2 Enhancements:**
    - ðŸ”§ **Advanced Battery Sizing**: Multi-parameter optimization algorithms
    - ðŸ“Š **Multi-Scenario Analysis**: Compare different battery configurations
    - ðŸ’° **Enhanced Cost Analysis**: ROI calculations and payback period analysis
    - ðŸ“ˆ **Improved Visualizations**: Interactive charts and detailed reporting
    - ðŸŽ¯ **Smart Recommendations**: AI-powered optimization suggestions
    """)
    
    # File upload section
    st.subheader("ðŸ“ Data Upload")
    st.markdown("*Upload your energy data file to begin MD shaving analysis*")
    
    uploaded_file = st.file_uploader(
        "Upload your energy data file", 
        type=["csv", "xls", "xlsx"], 
        key="md_shaving_v2_file_uploader",
        help="Upload your load profile data (CSV, Excel formats supported)"
    )
    
    if uploaded_file:
        try:
            # Read the uploaded file
            with st.spinner("Reading uploaded file..."):
                df = read_uploaded_file(uploaded_file)
            
            if df is None or df.empty:
                st.error("âŒ The uploaded file appears to be empty or invalid.")
                return
            
            if len(df.columns) < 2:
                st.error("âŒ The uploaded file doesn't have enough columns. Need at least timestamp and power columns.")
                return
            
            st.success(f"âœ… File uploaded successfully! Shape: {df.shape[0]} rows Ã— {df.shape[1]} columns")
            
            # Configure data inputs (reusing V1 logic)
            try:
                timestamp_col, power_col, holidays = _configure_data_inputs(df)
                
                if timestamp_col and power_col:
                    # Process the dataframe
                    with st.spinner("Processing data..."):
                        df_processed = _process_dataframe(df, timestamp_col)
                        # Store processed dataframe and column names in session state for later use
                        st.session_state['df_processed'] = df_processed
                        st.session_state['v2_power_col'] = power_col
                        st.session_state['v2_timestamp_col'] = timestamp_col
                    
                    st.success(f"âœ… Data processed successfully! Final shape: {df_processed.shape[0]} rows")
                    
                    # Display basic statistics
                    st.subheader("ðŸ“Š Data Summary")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("Total Records", f"{len(df_processed):,}")
                        
                    with col2:
                        date_range = df_processed.index.max() - df_processed.index.min()
                        st.metric("Date Range", f"{date_range.days} days")
                        
                    with col3:
                        avg_power = df_processed[power_col].mean()
                        st.metric("Average Power", f"{avg_power:.2f} kW")
                    
                    # Data preview
                    st.subheader("ðŸ“‹ Data Preview")
                    st.dataframe(df_processed[[power_col]].head(10), use_container_width=True)
                    
                    # V2 Tariff Selection
                    st.subheader("âš¡ V2 Tariff Configuration")
                    try:
                        selected_tariff = _configure_tariff_selection()
                        
                        if selected_tariff:
                            st.success("âœ… Tariff configuration completed!")
                            
                            # V2 Monthly Peak Analysis
                            st.subheader("ðŸ“Š V2 Monthly Peak Analysis")
                            try:
                                with st.spinner("Calculating tariff-specific monthly peaks..."):
                                    monthly_general_peaks, monthly_tou_peaks, tariff_type = _calculate_tariff_specific_monthly_peaks(
                                        df_processed, power_col, selected_tariff, holidays
                                    )
                                
                                st.success(f"âœ… Monthly peaks calculated for {tariff_type} tariff")
                                
                                # Display peak analysis results
                                col1, col2 = st.columns(2)
                                
                                with col1:
                                    st.subheader("ðŸ“ˆ General Peaks (24/7)")
                                    if not monthly_general_peaks.empty:
                                        st.dataframe(monthly_general_peaks, use_container_width=True)
                                    else:
                                        st.info("No general peaks calculated")
                                
                                with col2:
                                    st.subheader("ðŸ• TOU Peaks (2PM-10PM Weekdays)")
                                    if not monthly_tou_peaks.empty:
                                        st.dataframe(monthly_tou_peaks, use_container_width=True)
                                    else:
                                        st.info("No TOU peaks calculated")
                                
                                # V2 Monthly Targets Calculation
                                st.subheader("ðŸŽ¯ V2 Monthly Targets Calculation")
                                
                                # Target method selection for V2
                                target_method = st.selectbox(
                                    "Select target calculation method:",
                                    ["Percentage to Shave", "Percentage of Current Max", "Manual Target (kW)"],
                                    help="Choose how to calculate monthly demand targets"
                                )
                                
                                # Method-specific parameters
                                shave_percent = None
                                target_percent = None
                                target_manual_kw = None
                                
                                if target_method == "Percentage to Shave":
                                    shave_percent = st.slider("Shave Percentage (%)", 1, 50, 10)
                                elif target_method == "Percentage of Current Max":
                                    target_percent = st.slider("Target Percentage of Peak (%)", 50, 95, 85)
                                elif target_method == "Manual Target (kW)":
                                    target_manual_kw = st.number_input("Manual Target (kW)", min_value=0.0, value=1000.0, step=10.0)
                                
                                # Calculate monthly targets (Automatic)
                                try:
                                    # Validate inputs before calculation
                                    if target_method == "Percentage to Shave" and shave_percent is None:
                                        st.error("âŒ Please set the shave percentage")
                                    elif target_method == "Percentage of Current Max" and target_percent is None:
                                        st.error("âŒ Please set the target percentage")
                                    elif target_method == "Manual Target (kW)" and target_manual_kw is None:
                                        st.error("âŒ Please set the manual target value")
                                    else:
                                        with st.spinner("Calculating V2 monthly targets..."):
                                            monthly_targets, reference_peaks, calc_tariff_type, target_description = _calculate_monthly_targets_v2(
                                                df_processed, power_col, selected_tariff, holidays,
                                                target_method, shave_percent, target_percent, target_manual_kw
                                            )
                                        
                                        st.success("âœ… V2 Monthly targets calculated successfully!")
                                        
                                        # Store in session state for use in other functions
                                        st.session_state['v2_monthly_targets'] = monthly_targets
                                        st.session_state['v2_reference_peaks'] = reference_peaks
                                        st.session_state['v2_tariff_type'] = calc_tariff_type
                                        st.session_state['v2_target_description'] = target_description
                                        
                                        # Generate Monthly Target Calculation Summary Table
                                        if not reference_peaks.empty and not monthly_targets.empty:
                                            # Get the general and TOU peaks for comparison
                                            monthly_general_peaks, monthly_tou_peaks, _ = _calculate_tariff_specific_monthly_peaks(
                                                df_processed, power_col, selected_tariff, holidays
                                            )
                                            
                                            comparison_data = []
                                            
                                            for month_period in reference_peaks.index:
                                                general_peak = monthly_general_peaks[month_period] if month_period in monthly_general_peaks.index else 0
                                                tou_peak = monthly_tou_peaks[month_period] if month_period in monthly_tou_peaks.index else 0
                                                reference_peak = reference_peaks[month_period]
                                                target = monthly_targets[month_period]
                                                shaving_amount = reference_peak - target
                                                
                                                comparison_data.append({
                                                    'Month': str(month_period),
                                                    'General Peak (24/7)': f"{general_peak:.1f} kW",
                                                    'TOU Peak (2PM-10PM)': f"{tou_peak:.1f} kW",
                                                    'Reference Peak': f"{reference_peak:.1f} kW",
                                                    'Target MD': f"{target:.1f} kW",
                                                    'Shaving Amount': f"{shaving_amount:.1f} kW",
                                                    'Tariff Type': calc_tariff_type
                                                })
                                            
                                            df_comparison = pd.DataFrame(comparison_data)
                                            
                                            st.markdown("#### 6.1 ðŸ“‹ Monthly Target Calculation Summary")
                                            
                                            # Highlight the reference column based on tariff type
                                            def highlight_reference_peak(row):
                                                colors = []
                                                for col in row.index:
                                                    if col == 'Reference Peak':
                                                        colors.append('background-color: rgba(0, 255, 0, 0.3)')  # Green highlight
                                                    elif col == 'TOU Peak (2PM-10PM)' and calc_tariff_type == 'TOU':
                                                        colors.append('background-color: rgba(255, 255, 0, 0.2)')  # Yellow highlight
                                                    elif col == 'General Peak (24/7)' and calc_tariff_type == 'General':
                                                        colors.append('background-color: rgba(255, 255, 0, 0.2)')  # Yellow highlight
                                                    else:
                                                        colors.append('')
                                                return colors
                                            
                                            styled_comparison = df_comparison.style.apply(highlight_reference_peak, axis=1)
                                            st.dataframe(styled_comparison, use_container_width=True, hide_index=True)
                                            
                                            st.info(f"""
                                            **ðŸ“Š Target Calculation Explanation:**
                                            - **General Peak**: Highest demand anytime (24/7) 
                                            - **TOU Peak**: Highest demand during peak period (2PM-10PM weekdays only)
                                            - **Reference Peak**: Used for target calculation based on {calc_tariff_type} tariff
                                            - **Target MD**: {target_description}
                                            - ðŸŸ¢ **Green**: Reference peak used for calculations
                                            - ðŸŸ¡ **Yellow**: Peak type matching selected tariff
                                            """)
                                    
                                except Exception as e:
                                    st.error(f"âŒ Error calculating V2 monthly targets: {str(e)}")
                                    # Add debug information
                                    st.error(f"Debug info - target_method: {target_method}, shave_percent: {shave_percent}, target_percent: {target_percent}, target_manual_kw: {target_manual_kw}")
                                
                            except Exception as e:
                                st.error(f"âŒ Error calculating monthly peaks: {str(e)}")
                        
                        else:
                            st.warning("âš ï¸ Please configure tariff settings to proceed with V2 analysis")
                            
                    except Exception as e:
                        st.error(f"âŒ Error configuring tariff: {str(e)}")
                    
                    # V2 Peak Events Analysis
                    st.subheader("ðŸ“Š V2 Peak Events Analysis")
                    try:
                        # Detect data interval using V2 function
                        detected_interval_hours = _infer_interval_hours(df_processed.index)
                        st.success(f"âœ… Detected sampling interval: {int(round(detected_interval_hours * 60))} minutes")
                        
                        # Peak Events Detection (Automatic)
                        peak_events = []
                        try:
                            with st.spinner("Detecting peak events..."):
                                # Use the monthly targets from session state - MONTH BY MONTH APPROACH
                                if 'v2_monthly_targets' in st.session_state:
                                    monthly_targets = st.session_state['v2_monthly_targets']
                                    all_monthly_events = []
                                    
                                    # Debug information
                                    st.info(f"ðŸ” **Debug Info:**")
                                    st.write(f"- Monthly targets shape: {monthly_targets.shape}")
                                    st.write(f"- Data shape: {df_processed.shape}")
                                    st.write(f"- Power column: {power_col}")
                                    st.write(f"- Detected interval: {detected_interval_hours:.4f} hours")
                                    
                                    # Get MD rate from selected tariff
                                    total_md_rate = 0
                                    if selected_tariff and isinstance(selected_tariff, dict):
                                        rates = selected_tariff.get('Rates', {})
                                        total_md_rate = rates.get('Capacity Rate', 0) + rates.get('Network Rate', 0)
                                    
                                    st.write(f"- Total MD rate: {total_md_rate} RM/kW")
                                    
                                    # Process each month separately (like copy file)
                                    for month_period, target_value in monthly_targets.items():
                                        month_start = month_period.start_time
                                        month_end = month_period.end_time
                                        month_mask = (df_processed.index >= month_start) & (df_processed.index <= month_end)
                                        month_data = df_processed[month_mask]
                                        
                                        if not month_data.empty:
                                            # Find peak events for this month using TOU-aware detection
                                            month_peak_events = _detect_peak_events_tou_aware(
                                                month_data, power_col, target_value, total_md_rate, detected_interval_hours, selected_tariff, holidays
                                            )
                                            
                                            # Add month info to each event
                                            for event in month_peak_events:
                                                event['Month'] = str(month_period)
                                                event['Monthly_Target'] = target_value
                                                all_monthly_events.append(event)
                                    
                                    peak_events = all_monthly_events
                                    st.write(f"- Peak events found: {len(peak_events) if peak_events else 0}")
                                else:
                                    st.error("âŒ Monthly targets not calculated. Please calculate targets first.")
                                    peak_events = []
                        
                            if peak_events and len(peak_events) > 0:
                                st.success(f"âœ… Detected {len(peak_events)} peak events")
                                
                                # Display peak events summary with original detailed columns
                                events_summary = []
                                for i, event in enumerate(peak_events):
                                    events_summary.append({
                                        "Start Date": event.get('Start Date', 'N/A'),
                                        "Start Time": event.get('Start Time', 'N/A'),
                                        "End Date": event.get('End Date', 'N/A'),
                                        "End Time": event.get('End Time', 'N/A'),
                                        "General Peak Load (kW)": f"{event.get('General Peak Load (kW)', 0):.2f}",
                                        "General Excess (kW)": f"{event.get('General Excess (kW)', 0):.2f}",
                                        "TOU Peak Load (kW)": f"{event.get('TOU Peak Load (kW)', 0):.2f}",
                                        "TOU Excess (kW)": f"{event.get('TOU Excess (kW)', 0):.2f}",
                                        "TOU Peak Time": event.get('TOU Peak Time', 'N/A'),
                                        "Duration (min)": f"{event.get('Duration (min)', 0):.1f}",
                                        "General Required Energy (kWh)": f"{event.get('General Required Energy (kWh)', 0):.2f}",
                                        "TOU Required Energy (kWh)": f"{event.get('TOU Required Energy (kWh)', 0):.2f}",
                                        "MD Cost Impact (RM)": f"{event.get('MD Cost Impact (RM)', 0):.2f}",
                                        "Tariff Type": event.get('Tariff Type', 'N/A')
                                    })
                                
                                st.dataframe(pd.DataFrame(events_summary), use_container_width=True)
                            else:
                                st.info("â„¹ï¸ No peak events detected above the targets")
                                
                        except Exception as e:
                            st.error(f"âŒ Error detecting peak events: {str(e)}")
                        
                        # V2 Peak Events Timeline Visualization (Automatic)
                        try:
                            with st.spinner("Generating peak events timeline..."):
                                # Create visualization using V2 timeline function
                                fig = _render_v2_peak_events_timeline(
                                    df_processed, 
                                    power_col, 
                                    selected_tariff, 
                                    holidays,
                                    target_method, 
                                    shave_percent, 
                                    target_percent, 
                                    target_manual_kw, 
                                    target_description
                                )
                                
                                if fig:
                                    st.plotly_chart(fig, use_container_width=True)
                                    st.success("âœ… Peak events timeline generated successfully!")
                                else:
                                    st.warning("âš ï¸ Timeline visualization not available")
                                    
                        except Exception as e:
                            st.error(f"âŒ Error generating timeline: {str(e)}")
                            # Fallback: Use conditional demand line function
                            try:
                                st.info("ðŸ”„ Using alternative visualization...")
                                fig = px.line()
                                # Get targets from session state for fallback
                                avg_target = 1000  # Default value
                                if 'v2_monthly_targets' in st.session_state:
                                    monthly_targets = st.session_state['v2_monthly_targets']
                                    avg_target = monthly_targets.mean() if not monthly_targets.empty else 1000
                                
                                fig = create_conditional_demand_line_with_peak_logic(
                                    fig, 
                                    df_processed, 
                                    power_col, 
                                    avg_target,
                                    selected_tariff, 
                                    holidays, 
                                    "Demand with Peak Logic"
                                )
                                st.plotly_chart(fig, use_container_width=True)
                                st.success("âœ… Alternative demand visualization generated!")
                            except Exception as fallback_e:
                                st.error(f"âŒ Fallback visualization failed: {str(fallback_e)}")
                        
                    except Exception as e:
                        st.error(f"âŒ Error in peak events analysis: {str(e)}")
                    
                    # Daily Clustering Summary Table (after peak events detection)
                    try:
                        if 'peak_events' in locals() and peak_events:
                            # Generate daily clustering summary table
                            clustering_summary_df = _generate_clustering_summary_table(
                                peak_events, selected_tariff, holidays
                            )
                            
                            if not clustering_summary_df.empty:
                                st.markdown("#### 6.3.1 ðŸ“Š Daily Clustering Summary")
                                st.caption("Summary of peak events grouped by date with MD cost impact analysis")
                                
                                # Display the daily clustering summary table
                                st.dataframe(clustering_summary_df, use_container_width=True, hide_index=True)
                    
                    except Exception as e:
                        st.error(f"âŒ Error generating daily clustering summary: {str(e)}")
                    
                    # Monthly Summary Table (after peak events detection)
                    try:
                        if 'peak_events' in locals() and peak_events:
                            # Generate monthly summary table (uses daily clustering as intermediary)
                            monthly_summary_df = _generate_monthly_summary_table(
                                peak_events, selected_tariff, holidays
                            )
                            
                            if not monthly_summary_df.empty:
                                st.markdown("#### 6.3.2 ðŸ“… Monthly Summary")
                                st.caption("Maximum MD excess and energy requirements aggregated by month")
                                
                                # Display the monthly summary table
                                st.dataframe(monthly_summary_df, use_container_width=True, hide_index=True)
                                
                                # Add summary metrics below the monthly summary table
                                col1, col2, col3 = st.columns(3)
                                
                                # Calculate totals from the monthly summary
                                total_months = len(monthly_summary_df)
                                
                                # Find the column names dynamically (could be "TOU" or "General")
                                md_excess_col = [col for col in monthly_summary_df.columns if 'MD Excess' in col]
                                energy_col = [col for col in monthly_summary_df.columns if 'Required Energy' in col]
                                
                                if md_excess_col and energy_col:
                                    max_monthly_md_excess = monthly_summary_df[md_excess_col[0]].max()
                                    max_monthly_energy = monthly_summary_df[energy_col[0]].max()
                                    
                                    col1.metric("Total Months", total_months)
                                    col2.metric("Max Monthly MD Excess", f"{max_monthly_md_excess:.2f} kW")
                                    col3.metric("Max Monthly Required Energy", f"{max_monthly_energy:.2f} kWh")
                                else:
                                    st.warning("Could not extract summary metrics from monthly data")
                                    
                            else:
                                st.info("No monthly summary data available.")
                                
                    except Exception as e:
                        st.error(f"âŒ Error generating monthly summary table: {str(e)}")
                    
                    # Battery Sizing Analysis (using Monthly Summary data)
                    try:
                        if 'peak_events' in locals() and peak_events and 'monthly_summary_df' in locals() and not monthly_summary_df.empty:
                            # Use values from Monthly Summary table for accurate battery sizing
                            md_excess_col = [col for col in monthly_summary_df.columns if 'MD Excess' in col]
                            energy_col = [col for col in monthly_summary_df.columns if 'Required Energy' in col]
                            
                            if md_excess_col and energy_col:
                                max_power_shaving_required = monthly_summary_df[md_excess_col[0]].max()
                                max_required_energy = monthly_summary_df[energy_col[0]].max()
                                total_months = len(monthly_summary_df)
                                total_md_cost = sum([event.get('MD Cost Impact (RM)', 0) for event in peak_events]) if peak_events else 0
                                
                                if max_power_shaving_required > 0:
                                    st.markdown("### 6.5 ðŸ”‹ Battery Sizing Analysis")
                                    
                                    # Display key metrics using Monthly Summary data
                                    col1, col2, col3 = st.columns(3)
                                    with col1:
                                        st.metric("Total Months", total_months)
                                    with col2:
                                        st.metric("Max Monthly MD Excess", f"{max_power_shaving_required:.2f} kW")
                                    with col3:
                                        st.metric("Max Monthly Required Energy", f"{max_required_energy:.2f} kWh")
                                
                                    # Call the battery sizing analysis function
                                    _render_battery_sizing_analysis(max_power_shaving_required, max_required_energy, total_md_cost)
                            else:
                                st.warning("Could not extract MD excess and energy columns from Monthly Summary data")
                        elif 'peak_events' in locals() and peak_events:
                            # Fallback to individual peak events calculation if Monthly Summary is not available
                            max_power_shaving_required = max([event.get('General Excess (kW)', 0) for event in peak_events]) if peak_events else 0
                            max_required_energy = max([event.get('General Required Energy (kWh)', 0) for event in peak_events]) if peak_events else 0
                            total_md_cost = sum([event.get('MD Cost Impact (RM)', 0) for event in peak_events]) if peak_events else 0
                            
                            if max_power_shaving_required > 0:
                                st.markdown("### 6.5 ðŸ”‹ Battery Sizing Analysis")
                                st.warning("âš ï¸ Using individual peak events data (Monthly Summary not available)")
                                
                                # Display key metrics using fallback calculation
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("Total Months", len(set([event.get('Start Date', '') for event in peak_events])))
                                with col2:
                                    st.metric("Max Monthly MD Excess", f"{max_power_shaving_required:.2f} kW")
                                with col3:
                                    st.metric("Max Monthly Required Energy", f"{max_required_energy:.2f} kWh")
                                
                                # Call the battery sizing analysis function
                                _render_battery_sizing_analysis(max_power_shaving_required, max_required_energy, total_md_cost)
                                
                    except Exception as e:
                        st.error(f"âŒ Error in battery sizing analysis: {str(e)}")
                    
                    # V2 Battery Configuration
                    st.subheader("ðŸ”‹ V2 Battery Configuration")
                    try:
                        # Pass calculated values if available, otherwise use None for default behavior
                        power_shaving_val = max_power_shaving_required if 'max_power_shaving_required' in locals() else None
                        energy_requirement_val = max_required_energy if 'max_required_energy' in locals() else None
                        
                        battery_config = _render_v2_battery_controls(power_shaving_val, energy_requirement_val)
                        
                        if battery_config:
                            st.success("âœ… Battery configuration completed!")
                            
                            # Display configuration summary
                            with st.expander("ðŸ“‹ Battery Configuration Summary"):
                                st.json(battery_config)
                            
                            # Additional V2 Analysis Features
                            st.info("ðŸ”„ **Additional V2 analysis features integrated and ready for testing.**")
                            
                            # Forecasting Section
                            st.markdown("---")  # Separator line
                            st.subheader("ðŸ“ˆ Forecasting")
                            
                            # Forecasting enable/disable checkbox
                            enable_forecasting = st.checkbox(
                                "Enable Forecasting",
                                value=False,
                                key="v2_enable_forecasting",
                                help="Enable advanced forecasting capabilities for demand prediction and optimization"
                            )
                            
                            if enable_forecasting:
                                st.success("ðŸ”® **Forecasting Mode:** Advanced prediction capabilities activated")
                                
                                # Forecasting Method Selection
                                st.markdown("#### ðŸ”§ Forecasting Method Selection")
                                
                                # Define available forecasting methods
                                forecasting_methods = {
                                    "Rate of Change (ROC)": {
                                        "description": "Analyzes demand patterns based on historical rate of change trends",
                                        "status": "Available",
                                        "complexity": "Medium",
                                        "accuracy": "Good for short-term predictions"
                                    },
                                    "Linear Regression": {
                                        "description": "Statistical method using linear relationships in historical data",
                                        "status": "Coming Soon",
                                        "complexity": "Low",
                                        "accuracy": "Moderate for trend-based data"
                                    },
                                    "ARIMA (AutoRegressive Integrated Moving Average)": {
                                        "description": "Time series forecasting using autoregressive and moving average components",
                                        "status": "Planned",
                                        "complexity": "High",
                                        "accuracy": "High for seasonal data"
                                    },
                                    "Prophet": {
                                        "description": "Facebook's forecasting tool designed for business time series data",
                                        "status": "Planned",
                                        "complexity": "Medium",
                                        "accuracy": "Excellent for seasonal patterns"
                                    },
                                    "LSTM Neural Networks": {
                                        "description": "Deep learning approach for complex pattern recognition in time series",
                                        "status": "Future Release",
                                        "complexity": "Very High",
                                        "accuracy": "Excellent for complex patterns"
                                    }
                                }
                                
                                # Method selection dropdown
                                method_names = list(forecasting_methods.keys())
                                selected_method = st.selectbox(
                                    "Select Forecasting Method:",
                                    options=method_names,
                                    index=0,  # Default to ROC
                                    key="forecasting_method_selection",
                                    help="Choose the forecasting algorithm for demand prediction"
                                )
                                
                                # Display method details in a table
                                if selected_method:
                                    method_details = forecasting_methods[selected_method]
                                    
                                    st.markdown("##### ï¿½ Method Details")
                                    
                                    # Create method details table
                                    method_info = [
                                        ["Method", selected_method],
                                        ["Description", method_details["description"]],
                                        ["Status", method_details["status"]],
                                        ["Complexity", method_details["complexity"]],
                                        ["Accuracy", method_details["accuracy"]]
                                    ]
                                    
                                    method_df = pd.DataFrame(method_info, columns=["Parameter", "Details"])
                                    st.table(method_df)
                                    
                                    # Status-based messaging
                                    if method_details["status"] == "Available":
                                        st.success(f"âœ… **{selected_method}** is ready for use")
                                        
                                        # ROC Method Implementation
                                        if selected_method == "Rate of Change (ROC)":
                                            st.markdown("#### ðŸ”§ ROC Forecasting Configuration")
                                            
                                            # Validate data quality first
                                            try:
                                                # Check for NaN values in the power data
                                                nan_count = df_processed[power_col].isna().sum()
                                                total_points = len(df_processed)
                                                nan_percentage = (nan_count / total_points) * 100 if total_points > 0 else 0
                                                
                                                if nan_count > 0:
                                                    st.warning(f"""
                                                    âš ï¸ **Data Quality Notice:** 
                                                    Found {nan_count} missing values ({nan_percentage:.1f}% of data).
                                                    Data will be automatically cleaned using interpolation before forecasting.
                                                    """)
                                                    
                                                    if nan_percentage > 20:
                                                        st.error(f"""
                                                        ðŸš¨ **High Missing Data Warning:** 
                                                        {nan_percentage:.1f}% missing values may impact forecast accuracy.
                                                        Consider reviewing your data source for quality issues.
                                                        """)
                                                
                                            except Exception as e:
                                                st.warning(f"Could not validate data quality: {str(e)}")
                                            
                                            # Infer adaptive horizons based on data interval
                                            try:
                                                base_interval, adaptive_horizons, horizons_minutes = get_adaptive_forecast_horizons(df_processed)
                                                
                                                st.info(f"""
                                                ðŸ“Š **Auto-detected Data Characteristics:**
                                                - Base Interval: {base_interval} 
                                                - Recommended Horizons: {[f'{h}' for h in adaptive_horizons]}
                                                - Available Horizons (minutes): {horizons_minutes}
                                                """)
                                                
                                            except Exception as e:
                                                st.error(f"âŒ Error detecting data interval: {str(e)}")
                                                # Fallback to default horizons
                                                horizons_minutes = [1, 5, 10]
                                                st.warning("Using fallback horizons: [1, 5, 10] minutes")
                                            
                                            # Configuration controls
                                            col1, col2 = st.columns(2)
                                            
                                            with col1:
                                                # Use adaptive horizons or fallback
                                                available_options = horizons_minutes if 'horizons_minutes' in locals() else [1, 5, 10, 15, 20, 30]
                                                default_selection = horizons_minutes[:2] if 'horizons_minutes' in locals() else [1, 10]
                                                
                                                horizons = st.multiselect(
                                                    "Forecast Horizons (minutes)",
                                                    options=available_options,
                                                    default=default_selection,
                                                    help="Horizons auto-generated based on your data's native interval"
                                                )
                                            
                                            with col2:
                                                enable_backtesting = st.checkbox(
                                                    "Enable Historical Backtesting",
                                                    value=True,
                                                    help="Generate forecasts for all historical data points"
                                                )
                                            
                                            if enable_backtesting and horizons:
                                                with st.spinner("ðŸ”„ Generating ROC forecasts for historical backtesting..."):
                                                    try:
                                                        # Generate time series forecasts for each horizon
                                                        forecast_series = {}
                                                        validation_metrics = {}
                                                        
                                                        for horizon in horizons:
                                                            # Use our ROC forecast function with validation
                                                            validated_df, metrics = roc_forecast_with_validation(
                                                                df_processed[power_col], 
                                                                horizon=horizon, 
                                                                return_metrics=True
                                                            )
                                                            
                                                            # Create clean time series aligned to actual timestamps
                                                            # Each forecast[t] predicts the value at t+horizon
                                                            forecast_ts = pd.Series(
                                                                validated_df['Power_Forecast (kW)'].values,
                                                                index=validated_df['Forecast_Timestamp'],
                                                                name=f'Forecast_{horizon}min'
                                                            )
                                                            
                                                            # Store aligned forecast series and metrics
                                                            forecast_series[f'forecast_{horizon}min'] = forecast_ts
                                                            validation_metrics[horizon] = metrics
                                                        
                                                        # Store in session state for future use
                                                        st.session_state['roc_forecast_series'] = forecast_series
                                                        st.session_state['roc_validation_metrics'] = validation_metrics
                                                        st.session_state['roc_actual_series'] = df_processed[power_col]
                                                        
                                                        # Display summary
                                                        st.success("âœ… ROC forecasting completed successfully!")
                                                        
                                                        # Data Quality Report
                                                        try:
                                                            # Get validation report from the first horizon (they all use same data)
                                                            first_horizon = list(validation_metrics.keys())[0] if validation_metrics else None
                                                            if first_horizon:
                                                                # Try to get validation report from ROC calculation
                                                                roc_df_sample = _calculate_roc_from_series(df_processed[power_col])
                                                                if hasattr(roc_df_sample, '_validation_report'):
                                                                    validation_report = roc_df_sample._validation_report
                                                                    
                                                                    with st.expander("ðŸ“Š Data Quality Report", expanded=False):
                                                                        st.markdown("**Original Data Analysis:**")
                                                                        
                                                                        qual_col1, qual_col2, qual_col3 = st.columns(3)
                                                                        
                                                                        with qual_col1:
                                                                            st.metric("Total Data Points", validation_report['total_points'])
                                                                            
                                                                        with qual_col2:
                                                                            st.metric("Missing Values", validation_report['nan_count'])
                                                                            
                                                                        with qual_col3:
                                                                            quality_color = {
                                                                                'good': 'ðŸŸ¢',
                                                                                'fair': 'ðŸŸ¡', 
                                                                                'poor': 'ðŸ”´'
                                                                            }.get(validation_report['data_quality'], 'âšª')
                                                                            st.metric("Data Quality", f"{quality_color} {validation_report['data_quality'].title()}")
                                                                        
                                                                        # Additional details
                                                                        if validation_report['nan_count'] > 0:
                                                                            st.markdown(f"""
                                                                            **ðŸ”§ Data Cleaning Applied:**
                                                                            - Missing Values: {validation_report['nan_count']} ({validation_report['nan_percentage']:.1f}%)
                                                                            - Fill Method: {validation_report['fill_method_used']}
                                                                            - Remaining Issues: {validation_report.get('remaining_nans', 0)} NaNs
                                                                            """)
                                                                        else:
                                                                            st.info("âœ… No missing values detected - data is clean and ready for analysis")
                                                        except Exception as e:
                                                            st.warning(f"Could not generate data quality report: {str(e)}")
                                                        
                                                        # Summary metrics
                                                        col1, col2, col3 = st.columns(3)
                                                        
                                                        with col1:
                                                            st.metric("Horizons Generated", len(horizons))
                                                        
                                                        with col2:
                                                            total_forecasts = sum(
                                                                metrics['forecasts_made'] 
                                                                for metrics in validation_metrics.values()
                                                            )
                                                            st.metric("Total Forecasts", total_forecasts)
                                                        
                                                        with col3:
                                                            avg_validation_rate = np.mean([
                                                                metrics['validation_rate'] 
                                                                for metrics in validation_metrics.values()
                                                            ])
                                                            st.metric("Avg Validation Rate", f"{avg_validation_rate:.1f}%")
                                                        
                                                        # Performance summary table
                                                        st.markdown("#### ðŸ“Š Forecast Performance Summary")
                                                        
                                                        perf_data = []
                                                        for horizon in sorted(horizons):
                                                            metrics = validation_metrics[horizon]
                                                            perf_data.append({
                                                                'Horizon (min)': horizon,
                                                                'Forecasts Made': metrics['forecasts_made'],
                                                                'Validations Available': metrics['validations_available'],
                                                                'Validation Rate (%)': f"{metrics['validation_rate']:.1f}",
                                                                'MAE (kW)': f"{metrics['mae_kw']:.2f}" if not pd.isna(metrics['mae_kw']) else "N/A",
                                                                'RMSE (kW)': f"{metrics['rmse_kw']:.2f}" if not pd.isna(metrics['rmse_kw']) else "N/A",
                                                                'Mean % Error': f"{metrics['mean_pct_error']:.2f}%" if not pd.isna(metrics['mean_pct_error']) else "N/A",
                                                                'Bias (kW)': f"{metrics['bias_kw']:.2f}" if not pd.isna(metrics['bias_kw']) else "N/A"
                                                            })
                                                        
                                                        perf_df = pd.DataFrame(perf_data)
                                                        st.dataframe(perf_df, use_container_width=True)
                                                        
                                                        # Data structure info
                                                        with st.expander("ðŸ“‹ Generated Time Series Info"):
                                                            st.markdown("**Time Series Structure:**")
                                                            for horizon in horizons:
                                                                series_name = f'forecast_{horizon}min'
                                                                series = forecast_series[series_name]
                                                                st.write(f"- `{series_name}[t]`: {len(series)} points, forecasts value at t+{horizon} minutes")
                                                                st.write(f"  - Time range: {series.index.min()} to {series.index.max()}")
                                                                st.write(f"  - Available forecasts: {series.notna().sum()}")
                                                            
                                                            st.markdown("**Actual Series:**")
                                                            actual = df_processed[power_col]
                                                            st.write(f"- `actual[t]`: {len(actual)} points")
                                                            st.write(f"  - Time range: {actual.index.min()} to {actual.index.max()}")
                                                            
                                                            st.markdown("**Direct Comparison Ready:**")
                                                            st.write("Each forecast series is aligned to target timestamps for direct comparison:")
                                                            st.code("""
# Example comparison at any timestamp t:
actual_value = actual[t]
forecast_1min = forecast_1min[t]  # Predicted 1 minute ago  
forecast_10min = forecast_10min[t]  # Predicted 10 minutes ago

# Error calculation:
error_1min = forecast_1min - actual_value
error_10min = forecast_10min - actual_value
                                                            """)
                                                        
                                                        # P90 Forecasting Section
                                                        st.markdown("#### ðŸŽ¯ P90 Forecast Generation")
                                                        
                                                        with st.spinner("ðŸ”„ Generating P90 forecast bands from historical residuals..."):
                                                            try:
                                                                # Convert ROC backtest results to long format
                                                                forecast_dict = {}
                                                                actual_dict = {}
                                                                
                                                                for horizon in horizons:
                                                                    series_name = f'forecast_{horizon}min'
                                                                    forecast_dict[horizon] = forecast_series[series_name]
                                                                    actual_dict[horizon] = df_processed[power_col]
                                                                
                                                                # Convert to long format
                                                                df_long = convert_roc_backtest_to_long_format(
                                                                    forecast_dict, actual_dict, horizons
                                                                )
                                                                
                                                                if not df_long.empty:
                                                                    # Compute residual quantiles by horizon
                                                                    residual_quantiles = compute_residual_quantiles_by_horizon(df_long)
                                                                    
                                                                    if not residual_quantiles.empty:
                                                                        # Generate P90 forecast bands
                                                                        df_long_with_bands = generate_p90_forecast_bands(df_long, residual_quantiles)
                                                                        
                                                                        # Store results in session state
                                                                        st.session_state['roc_long_format'] = df_long_with_bands
                                                                        st.session_state['residual_quantiles'] = residual_quantiles
                                                                        
                                                                        # Display results
                                                                        col1, col2 = st.columns(2)
                                                                        
                                                                        with col1:
                                                                            st.success("âœ… P90 bands generated successfully!")
                                                                            st.metric("Long Format Records", len(df_long_with_bands))
                                                                            st.metric("Horizons with Quantiles", len(residual_quantiles))
                                                                        
                                                                        with col2:
                                                                            # Show residual quantiles summary
                                                                            st.markdown("**Residual Quantiles by Horizon:**")
                                                                            for _, row in residual_quantiles.iterrows():
                                                                                horizon = row['horizon_min']
                                                                                p10 = row.get('residual_p10', np.nan)
                                                                                p90 = row.get('residual_p90', np.nan)
                                                                                st.write(f"â€¢ {horizon}min: P10={p10:.1f}kW, P90={p90:.1f}kW")
                                                                        
                                                                        # Interactive P90 Forecast Visualization
                                                                        st.markdown("#### ðŸŽ¯ Interactive P90 Forecast Analysis")
                                                                        
                                                                        # Interactive controls
                                                                        col_controls1, col_controls2 = st.columns(2)
                                                                        
                                                                        with col_controls1:
                                                                            # Horizon selection
                                                                            available_horizons = sorted(df_long_with_bands['horizon_min'].unique())
                                                                            default_horizon = 5 if 5 in available_horizons else available_horizons[0]
                                                                            selected_horizon = st.radio(
                                                                                "ðŸ•’ Select Forecast Horizon",
                                                                                options=available_horizons,
                                                                                index=available_horizons.index(default_horizon),
                                                                                format_func=lambda x: f"{int(x)} minutes",
                                                                                help="Choose a single horizon for detailed analysis"
                                                                            )
                                                                        
                                                                        with col_controls2:
                                                                            # Date range selection
                                                                            if not df_long_with_bands.empty:
                                                                                min_date = df_long_with_bands['t'].min().date()
                                                                                max_date = df_long_with_bands['t'].max().date()
                                                                                
                                                                                st.markdown("ðŸ“… **Date Range Selection**")
                                                                                date_range = st.date_input(
                                                                                    "Select date range",
                                                                                    value=(min_date, min_date),
                                                                                    min_value=min_date,
                                                                                    max_value=max_date,
                                                                                    help="Select start and end dates for analysis (defaults to single day)"
                                                                                )
                                                                        
                                                                        # Filter data based on selections
                                                                        if not df_long_with_bands.empty and date_range:
                                                                            # Handle single date or date range
                                                                            if isinstance(date_range, tuple) and len(date_range) == 2:
                                                                                start_date, end_date = date_range
                                                                            else:
                                                                                start_date = end_date = date_range
                                                                            
                                                                            # Filter by horizon and date range
                                                                            filtered_df = df_long_with_bands[
                                                                                (df_long_with_bands['horizon_min'] == selected_horizon) &
                                                                                (df_long_with_bands['t'].dt.date >= start_date) &
                                                                                (df_long_with_bands['t'].dt.date <= end_date)
                                                                            ].copy().sort_values('t')
                                                                            
                                                                            if not filtered_df.empty:
                                                                                # Create focused forecast table
                                                                                st.markdown(f"##### ðŸ“Š {int(selected_horizon)}-Minute Forecast Table")
                                                                                
                                                                                # Prepare display DataFrame
                                                                                display_cols = ['t', 'actual', 'forecast_p10', 'forecast_p50', 'forecast_p90']
                                                                                available_cols = [col for col in display_cols if col in filtered_df.columns]
                                                                                
                                                                                display_df = filtered_df[available_cols].copy()
                                                                                if 't' in display_df.columns:
                                                                                    display_df['Time'] = display_df['t'].dt.strftime('%Y-%m-%d %H:%M:%S')
                                                                                    display_df = display_df[['Time'] + [col for col in available_cols if col != 't']]
                                                                                
                                                                                # Show filtered table
                                                                                st.dataframe(display_df.head(20), use_container_width=True, height=300)
                                                                                st.caption(f"Showing first 20 of {len(filtered_df)} records for {int(selected_horizon)}-minute horizon")
                                                                                
                                                                                # ROC Calculation Validation Table
                                                                                with st.expander("ðŸ” ROC Calculation Validation (10 sample entries)", expanded=False):
                                                                                    st.markdown(f"**Validate ROC calculations for {int(selected_horizon)}-minute horizon**")
                                                                                    
                                                                                    # Create ROC validation table with step-by-step calculations
                                                                                    if len(filtered_df) > 0:
                                                                                        validation_df = filtered_df.head(10).copy()
                                                                                        
                                                                                        # Calculate ROC step by step for validation display
                                                                                        if 't' in validation_df.columns and 'actual' in validation_df.columns:
                                                                                            validation_display = []
                                                                                            
                                                                                            # Sort by timestamp to ensure proper order for ROC calculation
                                                                                            validation_df = validation_df.sort_values('t')
                                                                                            
                                                                                            for i, (idx, row) in enumerate(validation_df.iterrows()):
                                                                                                timestamp = row['t']
                                                                                                power = row.get('actual', 0)
                                                                                                forecast = row.get('forecast_p50', 0)
                                                                                                
                                                                                                # Calculate Power Diff and ROC for current row
                                                                                                if i == 0:
                                                                                                    # First row - no previous data for diff calculation
                                                                                                    power_diff = 0  # or NaN
                                                                                                    roc_value = 0   # or NaN
                                                                                                else:
                                                                                                    # Calculate difference from previous row
                                                                                                    prev_row = validation_df.iloc[i-1]
                                                                                                    prev_power = prev_row.get('actual', 0)
                                                                                                    prev_time = prev_row['t']
                                                                                                    
                                                                                                    # Power difference
                                                                                                    power_diff = power - prev_power
                                                                                                    
                                                                                                    # Time difference in minutes
                                                                                                    time_diff_min = (timestamp - prev_time).total_seconds() / 60
                                                                                                    
                                                                                                    # ROC calculation
                                                                                                    roc_value = power_diff / time_diff_min if time_diff_min > 0 else 0
                                                                                                
                                                                                                validation_display.append({
                                                                                                    'Timestamp': timestamp.strftime('%H:%M:%S'),
                                                                                                    'Power (kW)': f"{power:.2f}",
                                                                                                    'Power Diff (kW)': f"{power_diff:.2f}" if i > 0 else "N/A",
                                                                                                    'ROC (kW/min)': f"{roc_value:.4f}" if i > 0 else "N/A",
                                                                                                    'Forecast (kW)': f"{forecast:.2f}"
                                                                                                })
                                                                                            
                                                                                            validation_table = pd.DataFrame(validation_display)
                                                                                            st.dataframe(validation_table, use_container_width=True, height=350)
                                                                                            
                                                                                            # Add calculation methodology
                                                                                            st.markdown("**ðŸ“Š ROC Calculation Formula:**")
                                                                                            st.markdown(f"""
                                                                                            - **Power Diff**: Current Power - Previous Power
                                                                                            - **ROC**: Power Diff Ã· Time Interval (minutes)
                                                                                            - **Forecast**: Current Power + (ROC Ã— {int(selected_horizon)} minutes)
                                                                                            - **Formula**: P_forecast = P_current + ROC Ã— horizon
                                                                                            """)
                                                                                            
                                                                                        else:
                                                                                            st.info("Validation data not available for selected time period")
                                                                                    else:
                                                                                        st.info("No data available for ROC validation")
                                                                                
                                                                                # Generate P90 visualization for selected horizon
                                                                                st.markdown(f"##### ðŸ“ˆ {int(selected_horizon)}-Minute Forecast Visualization with P10-P90 Bands")
                                                                                
                                                                                # Create the plot
                                                                                fig_p90 = go.Figure()
                                                                                
                                                                                # Add P10-P90 shaded band
                                                                                if 'forecast_p10' in filtered_df.columns and 'forecast_p90' in filtered_df.columns:
                                                                                    fig_p90.add_trace(go.Scatter(
                                                                                        x=filtered_df['t'],
                                                                                        y=filtered_df['forecast_p90'],
                                                                                        mode='lines',
                                                                                        line=dict(color='rgba(0,0,0,0)'),
                                                                                        showlegend=False,
                                                                                        hoverinfo='skip'
                                                                                    ))
                                                                                    
                                                                                    fig_p90.add_trace(go.Scatter(
                                                                                        x=filtered_df['t'],
                                                                                        y=filtered_df['forecast_p10'],
                                                                                        mode='lines',
                                                                                        line=dict(color='rgba(0,0,0,0)'),
                                                                                        fill='tonexty',
                                                                                        fillcolor='rgba(128, 128, 128, 0.3)',
                                                                                        name='P10-P90 Uncertainty Band',
                                                                                        hovertemplate='P10-P90 Band<br>Time: %{x}<br>P10: %{y:.2f} kW<extra></extra>'
                                                                                    ))
                                                                                
                                                                                # Add actual values
                                                                                if 'actual' in filtered_df.columns:
                                                                                    fig_p90.add_trace(go.Scatter(
                                                                                        x=filtered_df['t'],
                                                                                        y=filtered_df['actual'],
                                                                                        mode='lines',
                                                                                        line=dict(color='blue', width=2),
                                                                                        name='Actual Load',
                                                                                        hovertemplate='Actual: %{y:.2f} kW<br>Time: %{x}<extra></extra>'
                                                                                    ))
                                                                                
                                                                                # Add P50 forecast
                                                                                if 'forecast_p50' in filtered_df.columns:
                                                                                    fig_p90.add_trace(go.Scatter(
                                                                                        x=filtered_df['t'],
                                                                                        y=filtered_df['forecast_p50'],
                                                                                        mode='lines',
                                                                                        line=dict(color='red', width=2, dash='dash'),
                                                                                        name='P50 Forecast',
                                                                                        hovertemplate='P50 Forecast: %{y:.2f} kW<br>Time: %{x}<extra></extra>'
                                                                                    ))
                                                                                
                                                                                # Update layout
                                                                                fig_p90.update_layout(
                                                                                    title=f"{int(selected_horizon)}-Minute Forecast with P10-P90 Uncertainty Bands",
                                                                                    xaxis_title="Time",
                                                                                    yaxis_title="Power (kW)",
                                                                                    height=500,
                                                                                    showlegend=True,
                                                                                    hovermode='x unified',
                                                                                    legend=dict(
                                                                                        orientation="h",
                                                                                        yanchor="bottom",
                                                                                        y=1.02,
                                                                                        xanchor="right",
                                                                                        x=1
                                                                                    )
                                                                                )
                                                                                
                                                                                # Display the plot
                                                                                st.plotly_chart(fig_p90, use_container_width=True)
                                                                                
                                                                                # Show filtered metrics
                                                                                col_metrics1, col_metrics2, col_metrics3 = st.columns(3)
                                                                                
                                                                                with col_metrics1:
                                                                                    st.metric("Data Points", len(filtered_df))
                                                                                    
                                                                                with col_metrics2:
                                                                                    if 'forecast_p10' in filtered_df.columns and 'forecast_p90' in filtered_df.columns:
                                                                                        band_width = (filtered_df['forecast_p90'] - filtered_df['forecast_p10']).mean()
                                                                                        st.metric("Avg Uncertainty Band", f"{band_width:.1f} kW")
                                                                                    else:
                                                                                        st.metric("Avg Uncertainty Band", "N/A")
                                                                                
                                                                                with col_metrics3:
                                                                                    if 'actual' in filtered_df.columns and 'forecast_p50' in filtered_df.columns:
                                                                                        mae = abs(filtered_df['forecast_p50'] - filtered_df['actual']).mean()
                                                                                        st.metric("MAE", f"{mae:.1f} kW")
                                                                                    else:
                                                                                        st.metric("MAE", "N/A")
                                                                            
                                                                            else:
                                                                                st.warning(f"âš ï¸ No data available for {int(selected_horizon)}-minute horizon in the selected date range.")
                                                                        
                                                                        # Export options for filtered data
                                                                        with st.expander("ï¿½ Export Filtered Forecast Data"):
                                                                            if 'filtered_df' in locals() and not filtered_df.empty:
                                                                                export_df = filtered_df[available_cols].copy()
                                                                                if 't' in export_df.columns:
                                                                                    export_df['timestamp'] = export_df['t'].dt.strftime('%Y-%m-%d %H:%M:%S')
                                                                                    export_df = export_df.drop('t', axis=1)
                                                                                
                                                                                st.download_button(
                                                                                    label=f"ðŸ“¥ Download {int(selected_horizon)}-Min Filtered Forecast",
                                                                                    data=export_df.to_csv(index=False),
                                                                                    file_name=f"p90_forecast_{int(selected_horizon)}min_{start_date}_to_{end_date}_{datetime.now().strftime('%H%M')}.csv",
                                                                                    mime="text/csv",
                                                                                    help=f"Export {int(selected_horizon)}-minute P90 forecast data for selected date range"
                                                                                )
                                                                                
                                                                                # Summary of exported data
                                                                                st.info(f"ðŸ“Š Export contains {len(export_df)} records for {int(selected_horizon)}-minute horizon from {start_date} to {end_date}")
                                                                            else:
                                                                                st.warning("No filtered data available for export")
                                                                        
                                                                        # Overall horizon comparison  
                                                                        if len(df_long_with_bands['horizon_min'].unique()) > 1:
                                                                            st.markdown("#### ðŸ“ˆ All Horizons Overview")
                                                                            
                                                                            metrics_col1, metrics_col2, metrics_col3 = st.columns(3)
                                                                            
                                                                            with metrics_col1:
                                                                                # Count data points for each horizon
                                                                                horizon_counts = df_long_with_bands.groupby('horizon_min').size()
                                                                                st.markdown("**ðŸ“Š Total Data Points**")
                                                                                for horizon, count in horizon_counts.items():
                                                                                    st.write(f"â€¢ {int(horizon)} min: {count:,} points")
                                                                            
                                                                            with metrics_col2:
                                                                                # Calculate uncertainty band widths
                                                                                if 'forecast_p10' in df_long_with_bands.columns and 'forecast_p90' in df_long_with_bands.columns:
                                                                                    st.markdown("**ðŸŽ¯ Avg Uncertainty Band**")
                                                                                    band_widths = df_long_with_bands.groupby('horizon_min').apply(
                                                                                        lambda x: (x['forecast_p90'] - x['forecast_p10']).mean()
                                                                                    )
                                                                                    for horizon, width in band_widths.items():
                                                                                        st.write(f"â€¢ {int(horizon)} min: {width:.1f} kW")
                                                                            
                                                                            with metrics_col3:
                                                                                # Calculate forecast accuracy (MAE) if actual values available
                                                                                if 'actual' in df_long_with_bands.columns and 'forecast_p50' in df_long_with_bands.columns:
                                                                                    st.markdown("**ðŸ” Overall MAE**")
                                                                                    mae_by_horizon = df_long_with_bands.groupby('horizon_min').apply(
                                                                                        lambda x: abs(x['forecast_p50'] - x['actual']).mean()
                                                                                    )
                                                                                    for horizon, mae in mae_by_horizon.items():
                                                                                        st.write(f"â€¢ {int(horizon)} min: {mae:.1f} kW")
                                                                        
                                                                        # Complete dataset export options
                                                                        with st.expander("ðŸ’¾ Export Complete P90 Forecast Dataset"):
                                                                            col_export1, col_export2 = st.columns(2)
                                                                            
                                                                            with col_export1:
                                                                                # CSV export
                                                                                csv_data = df_long_with_bands.to_csv(index=False)
                                                                                st.download_button(
                                                                                    label="ðŸ“„ Download Complete Dataset (CSV)",
                                                                                    data=csv_data,
                                                                                    file_name=f"p90_forecast_complete_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                                                                    mime="text/csv",
                                                                                    help="Export all P90 forecast data for all horizons"
                                                                                )
                                                                            
                                                                            with col_export2:
                                                                                # Parquet export (more efficient for large datasets)
                                                                                import io
                                                                                parquet_buffer = io.BytesIO()
                                                                                df_long_with_bands.to_parquet(parquet_buffer, index=False)
                                                                                st.download_button(
                                                                                    label="ðŸ“¦ Download Complete Dataset (Parquet)",
                                                                                    data=parquet_buffer.getvalue(),
                                                                                    file_name=f"p90_forecast_complete_{datetime.now().strftime('%Y%m%d_%H%M%S')}.parquet",
                                                                                    mime="application/octet-stream",
                                                                                    help="Export all P90 forecast data in efficient Parquet format"
                                                                                )
                                                                    else:
                                                                        st.warning("âš ï¸ Could not compute residual quantiles - insufficient data")
                                                                else:
                                                                    st.warning("âš ï¸ Could not convert to long format - no valid forecast/actual pairs found")
                                                                    
                                                            except Exception as e:
                                                                st.error(f"âŒ Error generating P90 forecasts: {str(e)}")
                                                                import traceback
                                                                st.error(f"Traceback: {traceback.format_exc()}")
                                                        
                                                        st.info("ðŸ’¾ **Data Ready:** P90 forecast bands are generated and stored for visualization and analysis")
                                                        
                                                    except Exception as e:
                                                        st.error(f"âŒ Error generating ROC forecasts: {str(e)}")
                                                        import traceback
                                                        with st.expander("ðŸ› Debug Information"):
                                                            st.code(traceback.format_exc())
                                            
                                            elif enable_backtesting and not horizons:
                                                st.warning("âš ï¸ Please select at least one forecast horizon")
                                            
                                            elif not enable_backtesting:
                                                st.info("ðŸ“Š **Configuration Mode:** Enable backtesting to generate historical forecasts")
                                        
                                        else:
                                            st.info("ðŸ”§ Method configuration and execution will be implemented here")
                                    elif method_details["status"] == "Coming Soon":
                                        st.warning(f"â³ **{selected_method}** implementation in progress")
                                        st.info("ðŸ“… Expected availability in next release")
                                    elif method_details["status"] == "Planned":
                                        st.info(f"ðŸ“‹ **{selected_method}** is planned for future development")
                                        st.info("ðŸ—“ï¸ Scheduled for upcoming releases")
                                    else:  # Future Release
                                        st.info(f"ðŸš€ **{selected_method}** scheduled for future release")
                                        st.info("ðŸ’¡ Advanced feature under research and development")
                                
                            else:
                                st.info("ðŸ“ˆ **Standard Mode:** Enable forecasting to access prediction features")
                            
                            # =============================================================================
                            # SHAVING STRATEGY DECISION TREE SCAFFOLDING
                            # =============================================================================
                            st.markdown("---")
                            st.markdown("## ðŸŽ¯ Demand Shaving Strategy Selection")
                            
                            # Decision tree logic based on forecasting enable/disable
                            if enable_forecasting:
                                st.success("ðŸ”® **Forecast-Based Shaving:** Using P10/P50/P90 forecast data for optimization")
                                
                                # Retrieve stored forecast data
                                forecast_data_available = False
                                p10_data = None
                                p50_data = None 
                                p90_data = None
                                
                                # Check if forecast data exists in session state (with Series ambiguity protection)
                                if 'roc_long_format' in st.session_state:
                                    forecast_df = st.session_state['roc_long_format']
                                    # Safe column checking to prevent Series ambiguity
                                    required_cols = ['forecast_p10', 'forecast_p50', 'forecast_p90']
                                    has_all_cols = all(col in forecast_df.columns for col in required_cols)
                                    if has_all_cols and len(forecast_df) > 0:
                                        forecast_data_available = True
                                        p10_data = forecast_df[['t', 'actual', 'forecast_p10']].copy()
                                        p50_data = forecast_df[['t', 'actual', 'forecast_p50']].copy()
                                        p90_data = forecast_df[['t', 'actual', 'forecast_p90']].copy()
                                        
                                        st.info(f"ðŸ“Š Forecast data loaded: {len(forecast_df):,} records with P10/P50/P90 bands")
                                    else:
                                        st.warning("âš ï¸ Forecast data exists but P10/P50/P90 columns not found")
                                else:
                                    st.warning("âš ï¸ No forecast data available - please generate forecasts first")
                                
                                # Store forecast data for later use
                                if forecast_data_available:
                                    st.session_state['shaving_forecast_data'] = {
                                        'p10': p10_data,
                                        'p50': p50_data,
                                        'p90': p90_data,
                                        'full_data': forecast_df
                                    }
                                
                                # Define forecast-enabled shaving strategies (includes all 6 strategies)
                                shaving_strategies_forecast = [
                                    "Default Shaving",
                                    "SOC-Aware",
                                    "Hybrid",
                                    "Policy A (Forecast Only)",
                                    "Policy B (Forecast Only)", 
                                    "Policy C (Forecast Only)"
                                ]
                                
                            else:
                                st.info("ðŸ“ˆ **Historical Data Shaving:** Using uploaded historical data for optimization")
                                
                                # Use uploaded historical data
                                historical_data_available = False
                                historical_power_data = None
                                
                                # Check if uploaded data exists
                                if uploaded_file is not None and 'df_processed' in st.session_state:
                                    historical_df = st.session_state['df_processed']
                                    # Get the power column name from session state or use a default
                                    if 'v2_power_col' in st.session_state:
                                        power_column = st.session_state['v2_power_col']
                                    else:
                                        # Try to find power column from available columns
                                        power_cols = [col for col in historical_df.columns if any(kw in col.lower() for kw in ['power', 'kw', 'demand', 'load'])]
                                        power_column = power_cols[0] if power_cols else historical_df.columns[0]
                                    
                                    if power_column in historical_df.columns:
                                        historical_data_available = True
                                        # Use the DataFrame with datetime index (no need for separate timestamp column)
                                        historical_power_data = historical_df[[power_column]].copy()
                                        st.info(f"ðŸ“Š Historical data loaded: {len(historical_df):,} records")
                                    else:
                                        st.warning("âš ï¸ Historical data exists but power column not found")
                                else:
                                    st.warning("âš ï¸ No historical data available - please upload data first")
                                
                                # Store historical data for later use
                                if historical_data_available:
                                    st.session_state['shaving_historical_data'] = historical_power_data
                                
                                # Define historical-only shaving strategies (excludes forecast-only policies)
                                shaving_strategies_forecast = [
                                    "Default Shaving",
                                    "SOC-Aware", 
                                    "Hybrid"
                                ]
                            
                            # Shaving Strategy Selection Dropdown
                            st.markdown("#### ðŸ”§ Strategy Configuration")
                            
                            selected_strategy = st.selectbox(
                                "Select Shaving Strategy:",
                                options=shaving_strategies_forecast,
                                key="v2_shaving_strategy",
                                help="Choose the demand shaving strategy based on your optimization goals"
                            )
                            
                            # Display strategy information (no actions implemented yet)
                            strategy_descriptions = {
                                "Default Shaving": {
                                    "description": "Standard peak shaving using fixed thresholds and basic battery operation",
                                    "data_source": "Historical/Forecast",
                                    "complexity": "Low",
                                    "optimization": "Basic peak reduction"
                                },
                                "SOC-Aware": {
                                    "description": "State-of-charge aware shaving that considers battery capacity and health",
                                    "data_source": "Historical/Forecast", 
                                    "complexity": "Medium",
                                    "optimization": "Battery longevity + peak reduction"
                                },
                                "Hybrid": {
                                    "description": "Combination of multiple strategies with dynamic switching based on conditions",
                                    "data_source": "Historical/Forecast",
                                    "complexity": "High", 
                                    "optimization": "Multi-objective optimization"
                                },
                                "Policy A (Forecast Only)": {
                                    "description": "Advanced forecast-based policy using predictive uncertainty bands",
                                    "data_source": "Forecast Only",
                                    "complexity": "High",
                                    "optimization": "Uncertainty-aware peak reduction"
                                },
                                "Policy B (Forecast Only)": {
                                    "description": "Risk-averse strategy using P90 forecast bounds for conservative shaving",
                                    "data_source": "Forecast Only", 
                                    "complexity": "High",
                                    "optimization": "Risk-minimized peak management"
                                },
                                "Policy C (Forecast Only)": {
                                    "description": "Aggressive strategy leveraging P10 forecasts for maximum peak reduction",
                                    "data_source": "Forecast Only",
                                    "complexity": "High", 
                                    "optimization": "Maximum peak reduction with forecast confidence"
                                }
                            }
                            
                            if selected_strategy in strategy_descriptions:
                                strategy_info = strategy_descriptions[selected_strategy]
                                
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.markdown(f"**Description:** {strategy_info['description']}")
                                    st.markdown(f"**Data Source:** {strategy_info['data_source']}")
                                    
                                with col2:
                                    st.markdown(f"**Complexity:** {strategy_info['complexity']}")
                                    st.markdown(f"**Optimization:** {strategy_info['optimization']}")
                            
                            # Strategy status and next steps
                            st.markdown("#### ðŸ“‹ Implementation Status")
                            
                            if enable_forecasting:
                                if forecast_data_available:
                                    st.success("âœ… Forecast data ready for strategy implementation")
                                    if selected_strategy in ["Policy A (Forecast Only)", "Policy B (Forecast Only)", "Policy C (Forecast Only)"]:
                                        st.info(f"ðŸŽ¯ **{selected_strategy}** selected - Advanced forecast-based optimization")
                                    else:
                                        st.info(f"ðŸŽ¯ **{selected_strategy}** selected - Standard optimization with forecast enhancement")
                                else:
                                    st.warning("âš ï¸ Generate forecast data first to enable strategy implementation")
                            else:
                                if 'shaving_historical_data' in st.session_state:
                                    st.success("âœ… Historical data ready for strategy implementation") 
                                    st.info(f"ðŸŽ¯ **{selected_strategy}** selected - Historical data optimization")
                                else:
                                    st.warning("âš ï¸ Upload historical data first to enable strategy implementation")
                            
                    except Exception as e:
                        st.error(f"âŒ Error in V2 battery configuration: {str(e)}")
                        st.info("Some V2 features may not be available in this environment.")
                        
                    # =============================================================================
                    # V2 BATTERY SIMULATION AND RESULTS DISPLAY SECTION
                    # =============================================================================
                    st.markdown("---")
                    st.markdown("## ðŸ”‹ Battery Simulation Results")
                    
                    # Check if we have all necessary data and configuration
                    if battery_config and battery_config.get('run_analysis', False):
                        data_ready = False
                        simulation_data = None
                        power_column = None
                        
                        # Determine data source based on forecast mode
                        if enable_forecasting and forecast_data_available:
                            # Debug the original forecast data structure
                            original_forecast_df = debug_forecast_data_structure()
                            
                            if original_forecast_df is not None:
                                # ðŸ”® SIMPLIFIED FORECAST DATA CONVERSION - Use P50 only
                                st.markdown("### ðŸ”„ **Converting P50 Forecast Data for MD Shaving**")
                                
                                # Check if we have the required forecast columns
                                if 't' in original_forecast_df.columns and 'forecast_p50' in original_forecast_df.columns:
                                    # Create simulation data exactly like historical data format
                                    simulation_data = pd.DataFrame(index=pd.to_datetime(original_forecast_df['t']))
                                    simulation_data['Active Power Demand (kW)'] = original_forecast_df['forecast_p50'].values
                                    simulation_data['Original_Demand'] = original_forecast_df['forecast_p50'].values
                                    
                                    # Set the power column name to match what MD shaving expects
                                    power_col = 'Active Power Demand (kW)'
                                    
                                    st.success("ðŸ”® **Using P50 forecast data for MD shaving simulation**")
                                    data_ready = True
                                    
                                    # Display conversion summary
                                    st.info(f"""
                                    **ðŸ“Š P50 Forecast Data Conversion Summary:**
                                    - **Original forecast data**: {original_forecast_df.shape[0]} rows Ã— {original_forecast_df.shape[1]} columns
                                    - **Converted simulation data**: {simulation_data.shape[0]} rows Ã— {simulation_data.shape[1]} columns
                                    - **Power column**: `{power_col}` (using forecast_p50 values)
                                    - **Index**: Datetime index from forecast timestamps
                                    - **Approach**: Treating P50 forecast exactly like historical demand data
                                    """)
                                    
                                else:
                                    st.error("âŒ Forecast data missing required columns ('t' and 'forecast_p50')")
                                    data_ready = False
                                    simulation_data = None
                            else:
                                st.error("âŒ No forecast data available for conversion")
                                data_ready = False
                                simulation_data = None
                                
                        elif not enable_forecasting and 'shaving_historical_data' in st.session_state:
                            # Use historical data
                            simulation_data = st.session_state['df_processed']
                            power_col = st.session_state.get('v2_power_col', simulation_data.columns[0])
                            st.success("ðŸ“Š **Running simulation with historical data**")
                            data_ready = True
                            
                        else:
                            st.warning("âš ï¸ No data available for simulation. Please generate forecast data or upload historical data.")
                            data_ready = False
                        
                        if data_ready and simulation_data is not None:
                            try:
                                # Get monthly targets from V2 calculation
                                if 'v2_monthly_targets' in st.session_state:
                                    monthly_targets = st.session_state['v2_monthly_targets']
                                else:
                                    st.error("âŒ Monthly targets not calculated. Please configure battery settings first.")
                                    monthly_targets = None
                                
                                if monthly_targets is not None:
                                    # Extract battery parameters from battery_config with corrected key names
                                    battery_sizing = {
                                        'capacity_kwh': battery_config.get('total_energy_capacity', 100),
                                        'power_rating_kw': battery_config.get('total_power_capacity', 100)
                                    }
                                    
                                    battery_params = {
                                        'round_trip_efficiency': 95,  # Default efficiency
                                        'depth_of_discharge': 85      # Default DoD
                                    }
                                    
                                    # Set up simulation parameters - ensure all variables are defined for both modes
                                    interval_hours = 0.25  # 15-minute intervals
                                    selected_tariff = st.session_state.get('selected_tariff_dict')
                                    holidays = st.session_state.get('holidays', set())
                                    
                                    # Ensure session state variables are set for forecast mode compatibility
                                    if enable_forecasting:
                                        if not hasattr(st.session_state, 'tabled_analysis_selected_battery'):
                                            if battery_config and battery_config.get('active_battery_spec'):
                                                st.session_state.tabled_analysis_selected_battery = {
                                                    'spec': battery_config['active_battery_spec'],
                                                    'label': 'Selected Battery'
                                                }
                                        
                                        if not hasattr(st.session_state, 'tabled_analysis_battery_quantity'):
                                            if battery_config:
                                                st.session_state.tabled_analysis_battery_quantity = battery_config.get('selected_quantity', 1)
                                    
                                    # Run the battery simulation
                                    st.markdown("### ðŸ”„ Running Battery Operation Simulation...")
                                    with st.spinner("Simulating battery operation..."):
                                        simulation_results = _simulate_battery_operation_v2(
                                            df=simulation_data,
                                            power_col=power_col,
                                            monthly_targets=monthly_targets,
                                            battery_sizing=battery_sizing,
                                            battery_params=battery_params,
                                            interval_hours=interval_hours,
                                            selected_tariff=selected_tariff,
                                            holidays=holidays
                                        )
                                    
                                    if simulation_results and 'df_sim' in simulation_results:
                                        st.success("âœ… **Battery simulation completed successfully!**")
                                        
                                        # Display simulation summary
                                        df_sim = simulation_results['df_sim']
                                        
                                        # Summary metrics
                                        col1, col2, col3, col4 = st.columns(4)
                                        with col1:
                                            total_discharge = df_sim[df_sim['Battery_Power_kW'] > 0]['Battery_Power_kW'].sum() * interval_hours
                                            st.metric("Total Discharge", f"{total_discharge:.1f} kWh")
                                            
                                        with col2:
                                            total_charge = abs(df_sim[df_sim['Battery_Power_kW'] < 0]['Battery_Power_kW'].sum()) * interval_hours
                                            st.metric("Total Charge", f"{total_charge:.1f} kWh")
                                            
                                        with col3:
                                            peak_reduction = df_sim['Original_Demand'].max() - df_sim['Net_Demand_kW'].max()
                                            st.metric("Peak Reduction", f"{peak_reduction:.1f} kW")
                                            
                                        with col4:
                                            avg_soc = df_sim['Battery_SOC_Percent'].mean()
                                            st.metric("Avg SOC", f"{avg_soc:.1f}%")
                                        
                                        # Display the comprehensive battery simulation chart
                                        st.markdown("### ðŸ“Š Interactive Battery Operation Analysis")
                                        
                                        # Prepare proper sizing dictionary for chart display
                                        if hasattr(st.session_state, 'tabled_analysis_selected_battery'):
                                            selected_battery = st.session_state.tabled_analysis_selected_battery
                                            battery_spec = selected_battery['spec']
                                            quantity = getattr(st.session_state, 'tabled_analysis_battery_quantity', 1)
                                            
                                            sizing_for_chart = {
                                                'power_rating_kw': battery_spec.get('power_kW', 100) * quantity,
                                                'capacity_kwh': battery_spec.get('energy_kWh', 100) * quantity
                                            }
                                        else:
                                            # Fallback sizing from battery_sizing
                                            sizing_for_chart = {
                                                'power_rating_kw': battery_sizing.get('power_rating_kw', 100),
                                                'capacity_kwh': battery_sizing.get('capacity_kwh', 100)
                                            }
                                        
                                        # ðŸ” DEBUG: Data Structure Analysis for df_sim
                                        st.markdown("---")
                                        st.markdown("### ðŸ” **DEBUG - df_sim Data Structure Analysis**")
                                        
                                        if df_sim is not None:
                                            col1, col2 = st.columns(2)
                                            
                                            with col1:
                                                st.markdown("**ðŸ“Š Basic Info:**")
                                                st.write(f"â€¢ **Shape**: {df_sim.shape}")
                                                st.write(f"â€¢ **Index Type**: {type(df_sim.index).__name__}")
                                                st.write(f"â€¢ **Index Range**: {df_sim.index[0]} to {df_sim.index[-1]}")
                                                st.write(f"â€¢ **Memory Usage**: {df_sim.memory_usage(deep=True).sum() / 1024:.1f} KB")
                                                
                                            with col2:
                                                st.markdown("**ðŸ“ Column Analysis:**")
                                                st.write(f"â€¢ **Total Columns**: {len(df_sim.columns)}")
                                                st.write("â€¢ **Column Names**:")
                                                for i, col in enumerate(df_sim.columns, 1):
                                                    st.write(f"  {i}. `{col}` ({df_sim[col].dtype})")
                                            
                                            st.markdown("**ðŸŽ¯ Required Columns Check:**")
                                            required_cols = ['Original_Demand', 'Battery_Power_kW', 'Battery_SOC_Percent', 'Net_Demand_kW']
                                            col_status = []
                                            for col in required_cols:
                                                if col in df_sim.columns:
                                                    col_status.append(f"âœ… `{col}` - Present")
                                                else:
                                                    col_status.append(f"âŒ `{col}` - **Missing**")
                                            
                                            for status in col_status:
                                                st.write(status)
                                            
                                            st.markdown("**ðŸ“ˆ Data Sample (First 3 rows):**")
                                            st.dataframe(df_sim.head(3), use_container_width=True)
                                            
                                            st.markdown("**ðŸ”¢ Data Statistics:**")
                                            numeric_cols = df_sim.select_dtypes(include=['number']).columns
                                            if len(numeric_cols) > 0:
                                                stats_df = df_sim[numeric_cols].describe().round(2)
                                                st.dataframe(stats_df, use_container_width=True)
                                            else:
                                                st.write("No numeric columns found")
                                                
                                            # Check for any potential Series ambiguity issues
                                            st.markdown("**âš ï¸ Potential Issues Check:**")
                                            issue_count = 0
                                            
                                            # Check for empty columns
                                            empty_cols = [col for col in df_sim.columns if df_sim[col].isna().all()]
                                            if empty_cols:
                                                st.warning(f"Empty columns detected: {empty_cols}")
                                                issue_count += 1
                                            
                                            # Check for object columns that might cause issues
                                            object_cols = df_sim.select_dtypes(include=['object']).columns.tolist()
                                            if object_cols:
                                                st.info(f"Object/String columns: {object_cols}")
                                            
                                            # Check index issues
                                            if not isinstance(df_sim.index, pd.DatetimeIndex):
                                                st.warning(f"Index is not DatetimeIndex: {type(df_sim.index)}")
                                                issue_count += 1
                                            
                                            if issue_count == 0:
                                                st.success("âœ… No obvious structural issues detected")
                                        else:
                                            st.error("âŒ df_sim is None - No data to analyze")
                                        
                                        st.markdown("---")
                                        st.markdown("### ðŸ“Š **V2 Battery Operation Visualization**")
                                        
                                        _display_v2_battery_simulation_chart(
                                            df_sim=df_sim,
                                            monthly_targets=monthly_targets,
                                            sizing=sizing_for_chart,
                                            selected_tariff=selected_tariff,
                                            holidays=holidays
                                        )
                                        
                                        # Store simulation results for further analysis
                                        st.session_state['v2_simulation_results'] = simulation_results
                                        
                                    else:
                                        st.error("âŒ Battery simulation failed. Please check your configuration.")
                                        
                            except Exception as e:
                                st.error(f"âŒ Error during battery simulation: {str(e)}")
                                st.info("Please check your data and configuration settings.")
                    
                    else:
                        st.info("ðŸ”‹ **Enable 'Run V2 Analysis' in Battery Configuration to see simulation results**")
                        
                    # Strategy Implementation and Testing
                    st.markdown("#### ðŸš€ Strategy Execution")
                    
                    # Get battery configuration for strategy testing
                    if battery_config and battery_config.get('run_analysis', False):
                        battery_power_kw = battery_config.get('power_kw', 100)  # Default 100kW if not specified
                        
                        # Strategy Testing Interface
                        st.markdown("**ðŸ”¬ Test Strategy Parameters:**")
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            test_soc = st.slider("Current SOC (%)", min_value=5, max_value=100, value=50, step=5, 
                                                help="State of charge to test strategy behavior")
                        with col2:
                            test_excess = st.slider("Demand Excess (kW)", min_value=0, max_value=200, value=80, step=10,
                                                   help="Excess demand above target that needs shaving")
                        with col3:
                            st.metric("Battery Power", f"{battery_power_kw:.0f} kW", help="Maximum discharge power from battery config")
                        
                        # Strategy Comparison
                        if st.button("ðŸ” Compare Strategies", help="Compare Default vs SOC-Aware strategies with current parameters"):
                            
                            # Test both strategies
                            default_result = _get_strategy_aware_discharge("Default Shaving", test_soc, test_excess, battery_power_kw)
                            soc_aware_result = _get_strategy_aware_discharge("SOC-Aware", test_soc, test_excess, battery_power_kw)
                            
                            st.markdown("**ðŸ“Š Strategy Comparison Results:**")
                            
                            # Create comparison table
                            comparison_data = {
                                "Strategy": ["Default (Aggressive)", "SOC-Aware (Conservative)"],
                                "Discharge Power (kW)": [f"{default_result['power_kw']:.1f}", f"{soc_aware_result['power_kw']:.1f}"],
                                "Power Difference": ["Baseline", f"{soc_aware_result['power_kw'] - default_result['power_kw']:+.1f} kW"],
                                "Reasoning": [default_result['reasoning'], soc_aware_result['reasoning']]
                    }
                    
                            comparison_df = pd.DataFrame(comparison_data)
                            st.dataframe(comparison_df, use_container_width=True)
                            
                            # Highlight selected strategy
                            if selected_strategy == "Default Shaving":
                                st.success(f"âœ… **Selected Strategy:** {default_result['strategy_type']} - {default_result['power_kw']:.1f} kW discharge")
                            elif selected_strategy == "SOC-Aware":
                                st.success(f"âœ… **Selected Strategy:** {soc_aware_result['strategy_type']} - {soc_aware_result['power_kw']:.1f} kW discharge")
                            
                            # Strategy recommendations
                            power_diff = abs(soc_aware_result['power_kw'] - default_result['power_kw'])
                            if power_diff > 5:  # Significant difference
                                if test_soc < 25:
                                    st.info("ðŸ’¡ **Recommendation:** SOC-Aware strategy is safer for low battery levels")
                                elif test_excess > 100:
                                    st.info("ðŸ’¡ **Recommendation:** Default strategy provides maximum peak shaving for high demand")
                                else:
                                    st.info("ðŸ’¡ **Recommendation:** Both strategies viable - choose based on priority: battery life vs. peak reduction")
                            else:
                                st.info("ðŸ’¡ **Note:** Strategies produce similar results for these parameters")
                
                # Current Strategy Status (outside battery config scope)
                st.markdown("**ðŸŽ¯ Current Strategy Selection:**")
                if selected_strategy == "Default Shaving":
                    st.success("**Active:** Default (Aggressive)")
                    st.info("**Strategy:** Uses 80% excess discharge, 5% min SOC - prioritizes maximum MD cost savings")
                elif selected_strategy == "SOC-Aware":
                    st.success("**Active:** SOC-Aware (Conservative)")
                    st.info("**Strategy:** Uses 60% excess discharge, 20% min SOC - prioritizes battery longevity")
                else:
                    st.warning(f"**{selected_strategy}** - Advanced implementation pending")
                    
                    # Store selected strategy for future use
                    st.session_state['selected_shaving_strategy'] = selected_strategy
                    st.session_state['strategy_config'] = {
                        'strategy': selected_strategy,
                        'forecasting_enabled': enable_forecasting,
                        'data_available': forecast_data_available if enable_forecasting else ('shaving_historical_data' in st.session_state)
                    }
            
            except Exception as e:
                st.error(f"âŒ Error configuring data inputs: {str(e)}")
                
        except Exception as e:
            st.error(f"âŒ Error processing uploaded file: {str(e)}")
            
    else:
        # Show information when no file is uploaded
        st.info("ðŸ‘† **Upload your energy data file to begin V2 analysis**")
        
        # Information about current development status
        with st.expander("â„¹ï¸ Development Status & Available Functions"):
            st.markdown("""
            **Available V2 Functions:**
            - âœ… `_render_v2_battery_controls()` - Enhanced battery configuration interface
            - âœ… `load_vendor_battery_database()` - Battery database integration
            - âœ… `_calculate_monthly_targets_v2()` - Monthly-based target calculation
            - âœ… `_generate_clustering_summary_table()` - Peak events clustering analysis
            - âœ… `build_daily_simulator_structure()` - Advanced daily simulation structure
            - âœ… Multiple utility functions for enhanced analysis
            
            **Ready for Use:**
            - ðŸ”„ File upload and data processing
            - ðŸ”„ Battery configuration interface
            - ðŸ”„ Data validation and preprocessing
            
            **In Development:**
            - ðŸ”„ Complete V2 user interface
            - ðŸ”„ Advanced battery optimization algorithms
            - ðŸ”„ Multi-scenario comparison engine
            - ðŸ”„ Enhanced cost analysis and ROI calculations
            - ðŸ”„ Advanced visualization suite
            """)
        
        # Information section
        st.subheader("ðŸ“– About MD Shaving V2")
        st.markdown("""
        The MD Shaving Solution V2 represents the next evolution of maximum demand optimization technology,
        building upon the proven foundation of V1 with significant enhancements:
        
        **Key Improvements over V1:**
        - **File Upload Integration**: Seamless data import with validation
        - **Monthly Target Calculation**: More sophisticated target setting algorithms
        - **Battery Database Integration**: Access to vendor specifications and real-world performance data
        - **Enhanced Analytics**: Advanced clustering and event analysis capabilities
        - **Improved User Experience**: Streamlined interface with better visualization
        
        **Technical Architecture:**
        - Modular design with reusable components
        - Backward compatibility with V1 functionality
        - Extensible framework for future enhancements
        - Integration-ready for external systems
        
        **File Format Requirements:**
        - **CSV, Excel**: .csv, .xls, .xlsx formats supported
        - **Columns**: Timestamp (date/time) and Power (kW) columns required
        - **Data Quality**: Clean, continuous time series data recommended
        """)


# ===================================================================================================
# COMMENTED OUT - EVERYTHING AFTER _render_v2_battery_controls()
# ===================================================================================================

# def render_md_shaving_v2():
#     """
#     Main function to display the MD Shaving Solution V2 interface.
#     This is a thin wrapper that reuses V1 components for now.
#     """
#     st.title("ðŸ”‹ 1. MD Shaving Solution (v2)")
#     st.markdown("""
#     **Next-generation Maximum Demand (MD) shaving analysis** with enhanced features and advanced optimization algorithms.
#     
#     ðŸ†• **V2 Enhancements:**
#     - ðŸ”§ **Advanced Battery Sizing**: Multi-parameter optimization algorithms
#     - ðŸ“Š **Multi-Scenario Analysis**: Compare different battery configurations
#     - ðŸ’° **Enhanced Cost Analysis**: ROI calculations and payback period analysis
#     - ðŸ“ˆ **Improved Visualizations**: Interactive charts and detailed reporting
#     - ðŸŽ¯ **Smart Recommendations**: AI-powered optimization suggestions
#     
#     ðŸ’¡ **Status:** This is the next-generation MD shaving tool building upon the proven V1 foundation.
#     """)
#     
#     # Information about current development status
#     with st.expander("â„¹ï¸ Development Status & Roadmap"):
#         st.markdown("""
#         **Current Status:** Enhanced with Battery Database Integration
#         
#         **Completed Features:**
#         - âœ… UI Framework and basic structure
#         - âœ… Integration with existing V1 data processing
#         - âœ… Enhanced interface design
#         - âœ… Battery database integration with vendor specifications
#         - âœ… Monthly-based target calculation (10% shaving per month)
#         - âœ… Interactive battery capacity selection
#         
#         **In Development:**
#         - ðŸ”„ Advanced battery optimization algorithms
#         - ðŸ”„ Multi-scenario comparison engine
#         - ðŸ”„ Enhanced cost analysis and ROI calculations
#         - ðŸ”„ Advanced visualization suite
#         
#         **Planned Features:**
#         - ðŸ“‹ AI-powered battery sizing recommendations
#         - ðŸ“‹ Real-time optimization suggestions
#         - ðŸ“‹ Advanced reporting and export capabilities
#         - ðŸ“‹ Integration with battery vendor databases
#         """)
#     
#     # File upload section (reusing V1 logic)
#     st.subheader("2. ðŸ“ Data Upload")
#     uploaded_file = st.file_uploader(
#         "Upload your energy data file", 
#         type=["csv", "xls", "xlsx"], 
#         key="md_shaving_v2_file_uploader",
#         help="Upload your load profile data (same format as V1)"
#     )
#     
#     if uploaded_file:
#         try:
#             # Reuse V1 file reading logic
#             df = read_uploaded_file(uploaded_file)
#             
#             if df is None or df.empty:
#                 st.error("The uploaded file appears to be empty or invalid.")
#                 return
#             
#             if not hasattr(df, 'columns') or df.columns is None or len(df.columns) == 0:
#                 st.error("The uploaded file doesn't have valid column headers.")
#                 return
#                 
#             st.success("âœ… File uploaded successfully!")
#             
#             # Reuse V1 data configuration (read-only for now)
#             st.subheader("3. ðŸ“‹ Data Configuration")
#             
#             # Column Selection and Holiday Configuration
#             timestamp_col, power_col, holidays = _configure_data_inputs(df)
#             
#             # Only proceed if both columns are detected and valid
#             if (timestamp_col and power_col and 
#                 hasattr(df, 'columns') and df.columns is not None and
#                 timestamp_col in df.columns and power_col in df.columns):
#                 
#                 # Process data
#                 df_processed = _process_dataframe(df, timestamp_col)
#                 
#                 if not df_processed.empty and power_col in df_processed.columns:
#                     # Display tariff selection (reuse V1 logic - read-only)
#                     st.subheader("4. âš¡ Tariff Configuration")
#                     
#                     with st.container():
#                         st.info("ðŸ”§ **Note:** Using V1 tariff selection logic (read-only preview)")
#                         
#                         # Get tariff selection but don't store it yet
#                         try:
#                             selected_tariff = _configure_tariff_selection()
#                             if selected_tariff:
#                                 st.success(f"âœ… Tariff configured: **{selected_tariff.get('Tariff', 'Unknown')}**")
#                         except Exception as e:
#                             st.warning(f"âš ï¸ Tariff configuration error: {str(e)}")
#                             selected_tariff = None
#                     
#                     # V2 Target Setting Configuration
#                     st.subheader("5. ðŸŽ¯ Target Setting (V2)")
#                     
#                     # Get overall max demand for calculations
#                     overall_max_demand = df_processed[power_col].max()
#                     
#                     # Get default values from session state or use defaults
#                     default_shave_percent = st.session_state.get("v2_config_default_shave", 10)
#                     default_target_percent = st.session_state.get("v2_config_default_target", 90)
#                     default_manual_kw = st.session_state.get("v2_config_default_manual", overall_max_demand * 0.8)
#                     
#                     st.markdown(f"**Current Data Max:** {overall_max_demand:.1f} kW")
#                     
#                     # Target setting method selection
#                     target_method = st.radio(
#                         "Target Setting Method:",
#                         options=["Percentage to Shave", "Percentage of Current Max", "Manual Target (kW)"],
#                         index=0,
#                         key="v2_target_method",
#                         help="Choose how to set your monthly target maximum demand"
#                     )
#                     
#                     # Configure target based on selected method
#                     if target_method == "Percentage to Shave":
#                         shave_percent = st.slider(
#                             "Percentage to Shave (%)", 
#                             min_value=1, 
#                             max_value=50, 
#                             value=default_shave_percent, 
#                             step=1,
#                             key="v2_shave_percent",
#                             help="Percentage to reduce from monthly peak (e.g., 20% shaving reduces monthly 1000kW peak to 800kW)"
#                         )
#                         target_percent = None
#                         target_manual_kw = None
#                         target_multiplier = 1 - (shave_percent / 100)
#                         target_description = f"{shave_percent}% monthly shaving"
#                     elif target_method == "Percentage of Current Max":
#                         target_percent = st.slider(
#                             "Target MD (% of monthly max)", 
#                             min_value=50, 
#                             max_value=100, 
#                             value=default_target_percent, 
#                             step=1,
#                             key="v2_target_percent",
#                             help="Set the target maximum demand as percentage of monthly peak"
#                         )
#                         shave_percent = None
#                         target_manual_kw = None
#                         target_multiplier = target_percent / 100
#                         target_description = f"{target_percent}% of monthly max"
#                     else:
#                         target_manual_kw = st.number_input(
#                             "Target MD (kW)",
#                             min_value=0.0,
#                             max_value=overall_max_demand,
#                             value=default_manual_kw,
#                             step=10.0,
#                             key="v2_target_manual",
#                             help="Enter your desired target maximum demand in kW (applied to all months)"
#                         )
#                         target_percent = None
#                         shave_percent = None
#                         target_multiplier = None  # Will be calculated per month
#                         target_description = f"{target_manual_kw:.1f} kW manual target"
#                         effective_target_percent = None
#                         shave_percent = None
#                     
#                     # Display target information
#                     st.info(f"ðŸŽ¯ **V2 Target:** {target_description} (configured in sidebar)")
#                     
#                     # Validate target settings
#                     if target_method == "Manual Target (kW)":
#                         if target_manual_kw <= 0:
#                             st.error("âŒ Target demand must be greater than 0 kW")
#                             return
#                         elif target_manual_kw >= overall_max_demand:
#                             st.warning(f"âš ï¸ Target demand ({target_manual_kw:.1f} kW) is equal to or higher than current max ({overall_max_demand:.1f} kW). No peak shaving needed.")
#                             st.info("ðŸ’¡ Consider setting a lower target to identify shaving opportunities.")
#                     
#                     # V2 Peak Events Timeline visualization with dynamic targets
#                     _render_v2_peak_events_timeline(
#                         df_processed, 
#                         power_col, 
#                         selected_tariff, 
#                         holidays,
#                         target_method, 
#                         shave_percent if target_method == "Percentage to Shave" else None,
#                         target_percent if target_method == "Percentage of Current Max" else None,
#                         target_manual_kw if target_method == "Manual Target (kW)" else None,
#                         target_description
#                     )
#                     
#                 else:
#                     st.error("âŒ Failed to process the uploaded data")
#             else:
#                 st.warning("âš ï¸ Please ensure your file has proper timestamp and power columns")
#                 
#         except Exception as e:
#             st.error(f"âŒ Error processing file: {str(e)}")
#     else:
#         # Show placeholder when no file is uploaded
#         st.info("ðŸ‘† **Upload your energy data file to begin V2 analysis**")
#         
#         # Show sample data format
#         with st.expander("ðŸ“‹ Expected Data Format"):
#             st.markdown("""
#             **Your data file should contain:**
#             - **Timestamp column**: Date and time information
#             - **Power column**: Power consumption values in kW
#             
#             **Supported formats:** CSV, Excel (.xls, .xlsx)
#             """)
#             
#             # Sample data preview
#             sample_data = {
#                 'Timestamp': ['2024-01-01 00:00:00', '2024-01-01 00:15:00', '2024-01-01 00:30:00'],
#                 'Power (kW)': [250.5, 248.2, 252.1],
#                 'Additional Columns': ['Optional', 'Optional', 'Optional']
#             }
#             sample_df = pd.DataFrame(sample_data)
#             st.dataframe(sample_df, use_container_width=True)
# 
# 
# def _render_battery_impact_timeline(df, power_col, selected_tariff, holidays, target_method, shave_percent, target_percent, target_manual_kw, target_description, selected_battery_capacity):
#     """Render the Battery Impact Timeline visualization - duplicate of peak events graph with battery impact overlay."""
#     
#     st.markdown("### 8. ðŸ“Š Battery Impact on Energy Consumption")
#     
#     # This function is under development
#     st.info(f"""
#     **ðŸ”§ Battery Impact Analysis (Under Development)**
#     
#     This section will show how a {selected_battery_capacity} kWh battery system would impact your energy consumption patterns.
#     
#     **Planned Features:**
#     - Battery charge/discharge timeline overlay
#     - Peak shaving effectiveness visualization  
#     - Cost impact analysis with battery intervention
#     - Energy storage utilization patterns
#     
#     **Current Status:** Function implementation in progress
#     """)
#     
#     # Placeholder chart showing original consumption
#     st.markdown("#### ðŸ“ˆ Original Energy Consumption Pattern")
#     
#     if power_col in df.columns:
#         fig = go.Figure()
#         
#         # Add original consumption line
#         fig.add_trace(go.Scatter(
#             x=df.index,
#             y=df[power_col],
#             mode='lines',
#             name='Original Consumption',
#             line=dict(color='blue', width=1),
#             opacity=0.7
#         ))
#         
#         # Add target line if we can calculate it
#         try:
#             monthly_targets, _, _, _ = _calculate_monthly_targets_v2(
#                 df, power_col, selected_tariff, holidays, 
#                 target_method, shave_percent, target_percent, target_manual_kw
#             )
#             
#             if not monthly_targets.empty:
#                 # Create stepped target line
#                 target_line_data = []
#                 target_line_timestamps = []
#                 
#                 for month_period, target_value in monthly_targets.items():
#                     month_start = month_period.start_time
#                     month_end = month_period.end_time
#                     month_mask = (df.index >= month_start) & (df.index <= month_end)
#                     month_data = df[month_mask]
#                     
#                     if not month_data.empty:
#                         for timestamp in month_data.index:
#                             target_line_timestamps.append(timestamp)
#                             target_line_data.append(target_value)
#                 
#                 if target_line_data and target_line_timestamps:
#                     fig.add_trace(go.Scatter(
#                         x=target_line_timestamps,
#                         y=target_line_data,
#                         mode='lines',
#                         name=f'Target MD ({target_description})',
#                         line=dict(color='red', width=2, dash='dash'),
#                         opacity=0.9
#                     ))
#         except Exception as e:
#             st.warning(f"Could not calculate target line: {str(e)}")
#         
#         # Update layout
#         fig.update_layout(
#             title=f"Energy Consumption with {selected_battery_capacity} kWh Battery Impact (Preview)",
#             xaxis_title="Time",
#             yaxis_title="Power (kW)",
#             height=500,
#             showlegend=True,
#             hovermode='x unified'
#         )
#         
#         st.plotly_chart(fig, use_container_width=True)
#         
#         st.info(f"""
#         **ðŸ“Š Preview Information:**
#         - This shows your current energy consumption pattern
#         - Red dashed line indicates monthly targets based on {target_description}
#         - Battery capacity selected: **{selected_battery_capacity} kWh**
#         - Full battery impact analysis coming in future updates
#         """)
#     else:
#         st.error("Power column not found in data")
# 
# 
def _create_v2_conditional_demand_line_with_dynamic_targets(fig, df, power_col, target_series, selected_tariff=None, holidays=None, trace_name="Original Demand"):
    """
    V2 ENHANCEMENT: Enhanced conditional coloring logic for Original Demand line with DYNAMIC monthly targets.
    Creates continuous line segments with different colors based on monthly target conditions.
    
    Key V2 Innovation: Uses dynamic monthly targets instead of static averaging for color decisions.
    
    Color Logic:
    - Red: Above monthly target during Peak Periods (based on selected tariff) - Direct MD cost impact
    - Green: Above monthly target during Off-Peak Periods - No MD cost impact  
    - Blue: Below monthly target (any time) - Within acceptable limits
    
    Args:
        fig: Plotly figure to add traces to
        df: Simulation dataframe
        power_col: Power column name
        target_series: V2's dynamic monthly target series (same index as df)
        selected_tariff: Tariff configuration for period classification
        holidays: Set of holiday dates
        trace_name: Name for the trace
        
    Returns:
        Modified plotly figure with colored demand line segments
    """
    from tariffs.peak_logic import is_peak_rp4, get_period_classification
    
    # Validate inputs
    if target_series is None or len(target_series) == 0:
        st.warning("âš ï¸ V2 Dynamic Coloring: target_series is empty, falling back to single average")
        # Fallback to V1 approach with average target
        avg_target = df[power_col].quantile(0.9)
        return create_conditional_demand_line_with_peak_logic(fig, df, power_col, avg_target, selected_tariff, holidays, trace_name)
    
    # Convert index to datetime if it's not already
    if not pd.api.types.is_datetime64_any_dtype(df.index):
        df_copy = df.copy()
        df_copy.index = pd.to_datetime(df.index)
    else:
        df_copy = df
    
    # Create a series with color classifications using DYNAMIC monthly targets
    df_copy = df_copy.copy()
    df_copy['color_class'] = ''
    
    for i in range(len(df_copy)):
        timestamp = df_copy.index[i]
        demand_value = df_copy.iloc[i][power_col]
        
        # V2 ENHANCEMENT: Get DYNAMIC monthly target for this specific timestamp
        if timestamp in target_series.index:
            current_target = target_series.loc[timestamp]
        else:
            # Fallback to closest available target
            month_period = timestamp.to_period('M')
            available_periods = [t.to_period('M') for t in target_series.index if not pd.isna(target_series.loc[t])]
            if available_periods:
                closest_period_timestamp = min(target_series.index, 
                                             key=lambda t: abs((timestamp - t).total_seconds()))
                current_target = target_series.loc[closest_period_timestamp]
            else:
                current_target = df[power_col].quantile(0.9)  # Safe fallback
        
        # Get MD window classification using RP4 2-period system
        is_md = is_peak_rp4(timestamp, holidays)
        period_type = 'Peak' if is_md else 'Off-Peak'
        
        # V2 LOGIC: Color classification using dynamic monthly target
        if demand_value > current_target:
            if period_type == 'Peak':
                df_copy.iloc[i, df_copy.columns.get_loc('color_class')] = 'red'
            else:
                df_copy.iloc[i, df_copy.columns.get_loc('color_class')] = 'green'
        else:
            df_copy.iloc[i, df_copy.columns.get_loc('color_class')] = 'blue'
    
    # Create continuous line segments with color-coded segments
    x_data = df_copy.index
    y_data = df_copy[power_col]
    colors = df_copy['color_class']
    
    # Track legend status
    legend_added = {'red': False, 'green': False, 'blue': False}
    
    # Create continuous line segments by color groups with bridge points
    i = 0
    while i < len(df_copy):
        current_color = colors.iloc[i]
        
        # Find the end of current color segment
        j = i
        while j < len(colors) and colors.iloc[j] == current_color:
            j += 1
        
        # Extract segment data
        segment_x = list(x_data[i:j])
        segment_y = list(y_data[i:j])
        
        # Add bridge points for better continuity (connect to adjacent segments)
        if i > 0:  # Add connection point from previous segment
            segment_x.insert(0, x_data[i-1])
            segment_y.insert(0, y_data[i-1])
        
        if j < len(colors):  # Add connection point to next segment
            segment_x.append(x_data[j])
            segment_y.append(y_data[j])
        
        # Determine trace name based on color and tariff type
        tariff_description = _get_tariff_description(selected_tariff) if selected_tariff else "RP4 Peak Period"
        
        # Check if it's a TOU tariff for enhanced hover info
        is_tou = False
        if selected_tariff:
            tariff_type = selected_tariff.get('Type', '').lower()
            tariff_name = selected_tariff.get('Tariff', '').lower()
            is_tou = tariff_type == 'tou' or 'tou' in tariff_name
        
        if current_color == 'red':
            segment_name = f'{trace_name} (Above Target - {tariff_description})'
            if is_tou:
                hover_info = f'<b>Above Monthly Target - TOU Peak Rate Period</b><br><i>High Energy Cost + MD Cost Impact</i><br><i>Using V2 Dynamic Monthly Targets</i>'
            else:
                hover_info = f'<b>Above Monthly Target - General Tariff</b><br><i>MD Cost Impact Only (Flat Energy Rate)</i><br><i>Using V2 Dynamic Monthly Targets</i>'
        elif current_color == 'green':
            segment_name = f'{trace_name} (Above Target - Off-Peak)'
            if is_tou:
                hover_info = '<b>Above Monthly Target - TOU Off-Peak</b><br><i>Low Energy Cost, No MD Impact</i><br><i>Using V2 Dynamic Monthly Targets</i>'
            else:
                hover_info = '<b>Above Monthly Target - General Tariff</b><br><i>This should not appear for General tariffs</i><br><i>Using V2 Dynamic Monthly Targets</i>'
        else:  # blue
            segment_name = f'{trace_name} (Below Target)'
            hover_info = '<b>Below Monthly Target</b><br><i>Within Acceptable Limits</i><br><i>Using V2 Dynamic Monthly Targets</i>'
        
        # Only show legend for the first occurrence of each color
        show_legend = not legend_added[current_color]
        legend_added[current_color] = True
        
        # Add line segment
        fig.add_trace(go.Scatter(
            x=segment_x,
            y=segment_y,
            mode='lines',
            line=dict(color=current_color, width=2),
            name=segment_name,
            hovertemplate=f'{trace_name}: %{{y:.2f}} kW<br>%{{x}}<br>{hover_info}<extra></extra>',
            showlegend=show_legend,
            legendgroup=current_color,
            connectgaps=True  # Connect gaps within segments
        ))
        
        i = j
    
    return fig


def _render_v2_peak_events_timeline(df, power_col, selected_tariff, holidays, target_method, shave_percent, target_percent, target_manual_kw, target_description):
    """Render the V2 Peak Events Timeline visualization with dynamic monthly-based targets and enhanced color logic."""
    
    try:
        # Calculate tariff-specific monthly targets using V2 functions
        monthly_targets, reference_peaks, tariff_type, enhanced_target_description = _calculate_monthly_targets_v2(
            df, power_col, selected_tariff, holidays, 
            target_method, shave_percent, target_percent, target_manual_kw
        )
        
        # Create visualization with enhanced color logic
        fig = go.Figure()
        
        # Create a target series that maps monthly targets to the full dataframe index
        target_series = pd.Series(index=df.index, dtype=float)
        
        if not monthly_targets.empty:
            for month_period, target_value in monthly_targets.items():
                month_start = pd.Timestamp(month_period.start_time)
                month_end = pd.Timestamp(month_period.end_time)
                month_mask = (df.index >= month_start) & (df.index <= month_end)
                target_series.loc[month_mask] = target_value
        else:
            # Fallback to a single target
            avg_target = df[power_col].quantile(0.9)
            target_series[:] = avg_target
        
        # Use V2 enhanced conditional demand line with dynamic monthly targets and color logic
        fig = _create_v2_conditional_demand_line_with_dynamic_targets(
            fig, df, power_col, target_series, selected_tariff, holidays, "Power Consumption"
        )
        
        # Add monthly targets as horizontal lines for reference
        if not monthly_targets.empty:
            for month_period, target_value in monthly_targets.items():
                month_start = pd.Timestamp(month_period.start_time)
                month_end = pd.Timestamp(month_period.end_time)
                month_mask = (df.index >= month_start) & (df.index <= month_end)
                month_data = df[month_mask]
                
                if not month_data.empty:
                    fig.add_trace(go.Scatter(
                        x=[month_data.index[0], month_data.index[-1]],
                        y=[target_value, target_value],
                        mode='lines',
                        name=f'Target {month_period}',
                        line=dict(color='orange', width=2, dash='dash'),
                        opacity=0.7,
                        showlegend=False
                    ))
        
        # Update layout
        fig.update_layout(
            title=f"V2 Peak Events Timeline with Color Logic - {tariff_type} ({enhanced_target_description})",
            xaxis_title="Time",
            yaxis_title="Power (kW)",
            height=600,
            showlegend=True,
            hovermode='x unified',
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            )
        )
        
        return fig
        
    except Exception as e:
        st.error(f"Error in _render_v2_peak_events_timeline: {str(e)}")
        return None
        
        return fig
        
    except Exception as e:
        st.error(f"Error in V2 timeline rendering: {str(e)}")
        return None
#     """Render the V2 Peak Events Timeline visualization with dynamic monthly-based targets."""
#     
#     st.markdown("## 6. ðŸ“Š Peak Events Timeline")
#     
#     # Detect and show sampling interval from uploaded data
#     try:
#         detected_interval_hours = _infer_interval_hours(df.index)
#         st.session_state['data_interval_hours'] = detected_interval_hours
#         st.caption(f"ðŸ“Š Detected sampling interval: {int(round(detected_interval_hours * 60))} minutes")
#     except Exception:
#         pass
#     
#     # Calculate tariff-specific monthly targets using new V2 functions
#     if power_col in df.columns:
#         # Use new tariff-specific target calculation
#         monthly_targets, reference_peaks, tariff_type, enhanced_target_description = _calculate_monthly_targets_v2(
#             df, power_col, selected_tariff, holidays, 
#             target_method, shave_percent, target_percent, target_manual_kw
#         )
#         
#         # Also get both General and TOU peaks for comparison display
#         monthly_general_peaks, monthly_tou_peaks, _ = _calculate_tariff_specific_monthly_peaks(
#             df, power_col, selected_tariff, holidays
#         )
#         
#         # Set legend label based on tariff type
#         legend_label = f"Monthly Target - {tariff_type} ({enhanced_target_description})"
#         
#         # Display tariff-specific information
#         st.info(f"""
#         **ðŸŽ¯ Tariff-Specific Target Calculation:**
#         - **Tariff Type**: {tariff_type}
#         - **Reference Peak**: {enhanced_target_description}
#         - **Target Method**: {target_method}
#         - **Months Processed**: {len(monthly_targets)}
#         """)
#         
#         # Show monthly comparison table
#         if not reference_peaks.empty and not monthly_targets.empty:
#             comparison_data = []
#             
#             for month_period in reference_peaks.index:
#                 general_peak = monthly_general_peaks[month_period] if month_period in monthly_general_peaks.index else 0
#                 tou_peak = monthly_tou_peaks[month_period] if month_period in monthly_tou_peaks.index else 0
#                 reference_peak = reference_peaks[month_period]
#                 target = monthly_targets[month_period]
#                 shaving_amount = reference_peak - target
#                 
#                 comparison_data.append({
#                     'Month': str(month_period),
#                     'General Peak (24/7)': f"{general_peak:.1f} kW",
#                     'TOU Peak (2PM-10PM)': f"{tou_peak:.1f} kW",
#                     'Reference Peak': f"{reference_peak:.1f} kW",
#                     'Target MD': f"{target:.1f} kW",
#                     'Shaving Amount': f"{shaving_amount:.1f} kW",
#                     'Tariff Type': tariff_type
#                 })
#             
#             df_comparison = pd.DataFrame(comparison_data)
#             
#             st.markdown("#### 6.1 ðŸ“‹ Monthly Target Calculation Summary")
#             
#             # Highlight the reference column based on tariff type
#             def highlight_reference_peak(row):
#                 colors = []
#                 for col in row.index:
#                     if col == 'Reference Peak':
#                         colors.append('background-color: rgba(0, 255, 0, 0.3)')  # Green highlight
#                     elif col == 'TOU Peak (2PM-10PM)' and tariff_type == 'TOU':
#                         colors.append('background-color: rgba(255, 255, 0, 0.2)')  # Yellow highlight
#                     elif col == 'General Peak (24/7)' and tariff_type == 'General':
#                         colors.append('background-color: rgba(255, 255, 0, 0.2)')  # Yellow highlight
#                     else:
#                         colors.append('')
#                 return colors
#             
#             styled_comparison = df_comparison.style.apply(highlight_reference_peak, axis=1)
#             st.dataframe(styled_comparison, use_container_width=True, hide_index=True)
#             
#             st.info(f"""
#             **ðŸ“Š Target Calculation Explanation:**
#             - **General Peak**: Highest demand anytime (24/7) 
#             - **TOU Peak**: Highest demand during peak period (2PM-10PM weekdays only)
#             - **Reference Peak**: Used for target calculation based on {tariff_type} tariff
#             - **Target MD**: {enhanced_target_description}
#             - ðŸŸ¢ **Green**: Reference peak used for calculations
#             - ðŸŸ¡ **Yellow**: Peak type matching selected tariff
#             """)
#         
#         # Create stepped target line for visualization
#         target_line_data = []
#         target_line_timestamps = []
#         
#         # Create a stepped line that changes at month boundaries
#         for month_period, target_value in monthly_targets.items():
#             # Get start and end of month
#             month_start = month_period.start_time
#             month_end = month_period.end_time
#             
#             # Filter data for this month
#             month_mask = (df.index >= month_start) & (df.index <= month_end)
#             month_data = df[month_mask]
#             
#             if not month_data.empty:
#                 # Add target value for each timestamp in this month
#                 for timestamp in month_data.index:
#                     target_line_timestamps.append(timestamp)
#                     target_line_data.append(target_value)
#         
#         # Create the peak events timeline chart with stepped target line
#         if target_line_data and target_line_timestamps:
#             fig = go.Figure()
#             
#             # Add stepped monthly target line first
#             fig.add_trace(go.Scatter(
#                 x=target_line_timestamps,
#                 y=target_line_data,
#                 mode='lines',
#                 name=legend_label,
#                 line=dict(color='red', width=2, dash='dash'),
#                 opacity=0.9
#             ))
#             
#             # Identify and color-code all data points based on monthly targets and TOU periods
#             all_monthly_events = []
#             
#             # Create continuous colored line segments
#             # Process data chronologically to create continuous segments
#             all_timestamps = sorted(df.index)
#             
#             # Create segments for continuous colored lines
#             segments = []
#             current_segment = {'type': None, 'x': [], 'y': []}
#             
#             for timestamp in all_timestamps:
#                 power_value = df.loc[timestamp, power_col]
#                 
#                 # Get the monthly target for this timestamp
#                 month_period = timestamp.to_period('M')
#                 if month_period in monthly_targets:
#                     target_value = monthly_targets[month_period]
#                     
#                     # Determine the color category for this point
#                     if power_value <= target_value:
#                         segment_type = 'below_target'
#                     else:
#                         is_peak = is_peak_rp4(timestamp, holidays if holidays else set())
#                         if is_peak:
#                             segment_type = 'above_target_peak'
#                         else:
#                             segment_type = 'above_target_offpeak'
#                     
#                     # If this is the start or the segment type changed, finalize previous and start new
#                     if current_segment['type'] != segment_type:
#                         # Finalize the previous segment if it has data
#                         if current_segment['type'] is not None and len(current_segment['x']) > 0:
#                             segments.append(current_segment.copy())
#                         
#                         # Start new segment
#                         current_segment = {
#                             'type': segment_type, 
#                             'x': [timestamp], 
#                             'y': [power_value]
#                         }
#                     else:
#                         # Continue current segment
#                         current_segment['x'].append(timestamp)
#                         current_segment['y'].append(power_value)
#             
#             # Don't forget the last segment
#             if current_segment['type'] is not None and len(current_segment['x']) > 0:
#                 segments.append(current_segment)
#             
#             # Plot the colored segments with proper continuity (based on V1 logic)
#             color_map = {
#                 'below_target': {'color': 'blue', 'name': 'Below Monthly Target'},
#                 'above_target_offpeak': {'color': 'green', 'name': 'Above Monthly Target - Off-Peak Period'},
#                 'above_target_peak': {'color': 'red', 'name': 'Above Monthly Target - Peak Period'}
#             }
#             
#             # Track legend status
#             legend_added = {'below_target': False, 'above_target_offpeak': False, 'above_target_peak': False}
#             
#             # Create continuous line segments by color groups with bridge points (V1 approach)
#             i = 0
#             while i < len(segments):
#                 current_segment = segments[i]
#                 current_type = current_segment['type']
#                 
#                 # Extract segment data
#                 segment_x = list(current_segment['x'])
#                 segment_y = list(current_segment['y'])
#                 
#                 # Add bridge points for better continuity (connect to adjacent segments)
#                 if i > 0:  # Add connection point from previous segment
#                     prev_segment = segments[i-1]
#                     if len(prev_segment['x']) > 0:
#                         segment_x.insert(0, prev_segment['x'][-1])
#                         segment_y.insert(0, prev_segment['y'][-1])
#                 
#                 if i < len(segments) - 1:  # Add connection point to next segment
#                     next_segment = segments[i+1]
#                     if len(next_segment['x']) > 0:
#                         segment_x.append(next_segment['x'][0])
#                         segment_y.append(next_segment['y'][0])
#                 
#                 # Get color info
#                 color_info = color_map[current_type]
#                 
#                 # Only show legend for the first occurrence of each type
#                 show_legend = not legend_added[current_type]
#                 legend_added[current_type] = True
#                 
#                 # Add line segment
#                 fig.add_trace(go.Scatter(
#                     x=segment_x,
#                     y=segment_y,
#                     mode='lines',
#                     line=dict(color=color_info['color'], width=1),
#                     name=color_info['name'],
#                     opacity=0.8,
#                     showlegend=show_legend,
#                     legendgroup=current_type,
#                     connectgaps=True  # Connect gaps within segments
#                 ))
#                 
#                 i += 1
#             
#             # Process peak events for monthly analysis
#             for month_period, target_value in monthly_targets.items():
#                 month_start = month_period.start_time
#                 month_end = month_period.end_time
#                 month_mask = (df.index >= month_start) & (df.index <= month_end)
#                 month_data = df[month_mask]
#                 
#                 if not month_data.empty:
#                     # Find peak events for this month using V1's detection logic
#                     # Auto-detect sampling interval from this month's data
#                     interval_hours = _infer_interval_hours(month_data.index, fallback=0.25)
#                     
#                     # Save detected interval to session state for transparency
#                     try:
#                         st.session_state['data_interval_hours'] = interval_hours
#                     except Exception:
#                         pass
#                     
#                     # Get MD rate from selected tariff (simplified)
#                     total_md_rate = 0
#                     if selected_tariff and isinstance(selected_tariff, dict):
#                         rates = selected_tariff.get('Rates', {})
#                         total_md_rate = rates.get('Capacity Rate', 0) + rates.get('Network Rate', 0)
#                     
#                     peak_events = _detect_peak_events(
#                         month_data, power_col, target_value, total_md_rate, interval_hours, selected_tariff
#                     )
#                     
#                     # Add month info to each event including both reference peaks
#                     for event in peak_events:
#                         event['Month'] = str(month_period)
#                         event['Monthly_Target'] = target_value
#                         event['Monthly_General_Peak'] = monthly_general_peaks[month_period] if month_period in monthly_general_peaks.index else 0
#                         event['Monthly_TOU_Peak'] = monthly_tou_peaks[month_period] if month_period in monthly_tou_peaks.index else 0
#                         event['Reference_Peak'] = reference_peaks[month_period]
#                         event['Shaving_Amount'] = reference_peaks[month_period] - target_value
#                         all_monthly_events.append(event)
#             
#             # Update layout
#             fig.update_layout(
#                 title="Power Consumption with Monthly Peak Events Highlighted",
#                 xaxis_title="Time",
#                 yaxis_title="Power (kW)",
#                 height=600,
#                 showlegend=True,
#                 hovermode='x unified',
#                 legend=dict(
#                     orientation="v",
#                     yanchor="top",
#                     y=1,
#                     xanchor="left",
#                     x=1.02
#                 ),
#                 plot_bgcolor='rgba(0,0,0,0)',
#                 paper_bgcolor='rgba(0,0,0,0)'
#             )
#             
#             st.plotly_chart(fig, use_container_width=True)
#             
#             # Monthly breakdown table
#             
#         # Detailed Peak Event Detection Results
#         if all_monthly_events:
#             st.markdown("#### 6.2 âš¡ Peak Event Detection Results")
#             
#             # Determine tariff type for display enhancements
#             tariff_type = selected_tariff.get('Type', '').lower() if selected_tariff else 'general'
#             tariff_name = selected_tariff.get('Tariff', '').lower() if selected_tariff else ''
#             is_tou_tariff = tariff_type == 'tou' or 'tou' in tariff_name
#             
#             # Enhanced summary with tariff context
#             total_events = len(all_monthly_events)
#             # Count events with actual MD cost impact (cost > 0 or TOU excess > 0)
#             md_impact_events = len([e for e in all_monthly_events 
#                                   if e.get('MD Cost Impact (RM)', 0) > 0 or e.get('TOU Excess (kW)', 0) > 0])
#             total_md_cost = sum(event.get('MD Cost Impact (RM)', 0) for event in all_monthly_events)
#             
#             # Calculate maximum TOU Excess from all events
#             max_tou_excess = max([event.get('TOU Excess (kW)', 0) or 0 for event in all_monthly_events]) if all_monthly_events else 0
#             
#             if is_tou_tariff:
#                 no_md_impact_events = total_events - md_impact_events
#                 summary_text = f"**Showing {total_events} total events (All Events)**\n"
#                 summary_text += f"ðŸ“Š **TOU Tariff Summary:** {md_impact_events} events with MD cost impact, {no_md_impact_events} events without MD impact"
#             else:
#                 summary_text = f"**Showing {total_events} total events (All Events)**\n"
#                 summary_text += f"ðŸ“Š **General Tariff:** All {total_events} events have MD cost impact (24/7 MD charges)"
#             
#             st.markdown(summary_text)
#             
#             # Prepare enhanced dataframe with all detailed columns
#             df_events_summary = pd.DataFrame(all_monthly_events)
#             
#             # Ensure all required columns exist
#             required_columns = ['Start Date', 'Start Time', 'End Date', 'End Time', 
#                               'General Peak Load (kW)', 'General Excess (kW)', 
#                               'TOU Peak Load (kW)', 'TOU Excess (kW)', 'TOU Peak Time',
#                               'Duration (min)', 'General Required Energy (kWh)',
#                               'TOU Required Energy (kWh)', 'MD Cost Impact (RM)', 
#                               'Has MD Cost Impact', 'Tariff Type']
#             
#             # Add missing columns with default values
#             for col in required_columns:
#                 if col not in df_events_summary.columns:
#                     if 'General' in col and 'TOU' in [c for c in df_events_summary.columns]:
#                         # Copy TOU values to General columns if missing
#                         tou_col = col.replace('General', 'TOU')
#                         if tou_col in df_events_summary.columns:
#                             df_events_summary[col] = df_events_summary[tou_col]
#                         else:
#                             df_events_summary[col] = 0
#                     elif col == 'Duration (min)':
#                         df_events_summary[col] = 30.0  # Default duration
#                     elif col == 'TOU Peak Time':
#                         df_events_summary[col] = 'N/A'
#                     elif col == 'Has MD Cost Impact':
#                         # Set based on MD cost impact
#                         df_events_summary[col] = df_events_summary.get('MD Cost Impact (RM)', 0) > 0
#                     elif col == 'Tariff Type':
#                         # Set based on selected tariff
#                         tariff_type_name = selected_tariff.get('Type', 'TOU').upper() if selected_tariff else 'TOU'
#                         df_events_summary[col] = tariff_type_name
#                     else:
#                         df_events_summary[col] = 0
#             
#             # Create styled dataframe with color-coded rows
#             def apply_row_colors(row):
#                 """Apply color coding based on MD cost impact."""
#                 # Check if event has MD cost impact based on actual cost value
#                 md_cost = row.get('MD Cost Impact (RM)', 0) or 0
#                 has_impact = md_cost > 0
#                 
#                 # Alternative check: look for TOU Excess or any excess during peak hours
#                 if not has_impact:
#                     tou_excess = row.get('TOU Excess (kW)', 0) or 0
#                     has_impact = tou_excess > 0
#                 
#                 if has_impact:
#                     return ['background-color: rgba(255, 0, 0, 0.1)'] * len(row)  # Light red for MD cost impact
#                 else:
#                     return ['background-color: rgba(0, 128, 0, 0.1)'] * len(row)  # Light green for no MD cost impact
#             
#             # Select and reorder columns for display (matching original table structure)
#             display_columns = ['Start Date', 'Start Time', 'End Date', 'End Time', 
#                              'General Peak Load (kW)', 'General Excess (kW)', 
#                              'TOU Peak Load (kW)', 'TOU Excess (kW)', 'TOU Peak Time',
#                              'Duration (min)', 'General Required Energy (kWh)',
#                              'TOU Required Energy (kWh)', 'MD Cost Impact (RM)', 
#                              'Has MD Cost Impact', 'Tariff Type']
#             
#             # Filter to display columns that exist
#             available_columns = [col for col in display_columns if col in df_events_summary.columns]
#             display_df = df_events_summary[available_columns]
#             
#             # Define formatting function
#             def fmt(x):
#                 return f"{x:,.2f}" if isinstance(x, (int, float)) else str(x)
#             
#             # Apply styling and formatting
#             styled_df = display_df.style.apply(apply_row_colors, axis=1).format({
#                 'General Peak Load (kW)': lambda x: fmt(x),
#                 'General Excess (kW)': lambda x: fmt(x),
#                 'TOU Peak Load (kW)': lambda x: fmt(x) if x > 0 else 'N/A',
#                 'TOU Excess (kW)': lambda x: fmt(x) if x > 0 else 'N/A',
#                 'Duration (min)': '{:.1f}',
#                 'General Required Energy (kWh)': lambda x: fmt(x),
#                 'TOU Required Energy (kWh)': lambda x: fmt(x),
#                 'MD Cost Impact (RM)': lambda x: f'RM {fmt(x)}' if x is not None else 'RM 0.0000',
#                 'Has MD Cost Impact': lambda x: 'âœ“' if x else 'âœ—',
#                 'Tariff Type': lambda x: str(x)
#             })
#             
#             st.dataframe(styled_df, use_container_width=True)
#             
#             # Enhanced explanation with tariff-specific context
#             if is_tou_tariff:
#                 explanation = """
#         **Column Explanations (TOU Tariff):**
#         - **General Peak Load (kW)**: Highest demand during entire event period (may include off-peak hours)
#         - **General Excess (kW)**: Overall event peak minus target (for reference only)
#         - **TOU Peak Load (kW)**: Highest demand during MD recording hours only (2PM-10PM, weekdays)
#         - **TOU Excess (kW)**: MD peak load minus target - determines MD cost impact
#         - **TOU Peak Time**: Exact time when MD peak occurred (for MD cost calculation)
#         - **General Required Energy (kWh)**: Total energy above target for entire event duration
#         - **TOU Required Energy (kWh)**: Energy above target during MD recording hours only
#         - **MD Cost Impact**: MD Excess (kW) Ã— MD Rate - **ONLY for events during 2PM-10PM weekdays**
#         
#         **ðŸŽ¨ Row Colors:**
#         - ðŸ”´ **Red background**: Events with MD cost impact (occur during 2PM-10PM weekdays)
#         - ðŸŸ¢ **Green background**: Events without MD cost impact (occur during off-peak periods)
#             """
#             else:
#                 explanation = """
#         **Column Explanations (General Tariff):**
#         - **General Peak Load (kW)**: Highest demand during entire event period
#         - **General Excess (kW)**: Event peak minus target
#         - **TOU Peak Load (kW)**: Same as Peak Load (General tariffs have 24/7 MD impact)
#         - **TOU Excess (kW)**: Same as Excess (all events affect MD charges)
#         - **TOU Peak Time**: Time when peak occurred
#         - **General Required Energy (kWh)**: Total energy above target for entire event duration
#         - **TOU Required Energy (kWh)**: Energy above target during MD recording hours only
#         - **MD Cost Impact**: MD Excess (kW) Ã— MD Rate - **ALL events have MD cost impact 24/7**
#         
#         **ðŸŽ¨ Row Colors:**
#         - ðŸ”´ **Red background**: All events have MD cost impact (General tariffs charge MD 24/7)
#             """
#             
#             st.info(explanation)
#             
#             # Summary metrics
#             col1, col2, col3 = st.columns(3)
#             col1.metric("Total Events", total_events)
#             col2.metric("MD Impact Events", md_impact_events)
#             col3.metric("Max TOU Excess", f"{fmt(max_tou_excess)} kW")
#             
#             # === PEAK EVENT CLUSTERING ANALYSIS ===
#             st.markdown("### 6.3 ðŸ”— Peak Event Clusters")
#             st.markdown("**Grouping consecutive peak events that can be managed with a single battery charge/discharge cycle**")
#             
#             # Generate and display clustering summary table
#             try:
#                 clustering_summary_df = _generate_clustering_summary_table(
#                     all_monthly_events, selected_tariff, holidays
#                 )
#                 
#                 if not clustering_summary_df.empty:
#                     st.markdown("#### 6.3.1 ðŸ“Š Daily Clustering Summary")
#                     st.markdown("*Summary of peak events grouped by date with MD cost impact analysis*")
#                     
#                     # Display the clustering summary table
#                     st.dataframe(
#                         clustering_summary_df,
#                         use_container_width=True,
#                         hide_index=True
#                     )
#                     
#                     # Add summary metrics below the table
#                     col1, col2, col3, col4 = st.columns(4)
#                     
#                     total_dates = len(clustering_summary_df)
#                     total_peak_events = clustering_summary_df['Total Peak Events'].sum()
#                     max_daily_cost = clustering_summary_df['Cost Impact (RM/month)'].max()
#                     total_monthly_cost_impact = clustering_summary_df['Cost Impact (RM/month)'].sum()
#                     
#                     col1.metric("Peak Event Days", total_dates)
#                     col2.metric("Total Peak Events", total_peak_events)
#                     col3.metric("Max Daily Cost Impact", f"RM {max_daily_cost:.2f}")
#                     col4.metric("Total Monthly Cost Impact", f"RM {total_monthly_cost_impact:.2f}")
#                     
#                     st.markdown("---")
#                 else:
#                     st.info("No peak events found for clustering analysis.")
#             
#             except Exception as e:
#                 # V2 uses direct calculations without clustering dependency
#                 pass
#             
#             # Generate and display monthly summary table
#             try:
#                 monthly_summary_df = _generate_monthly_summary_table(
#                     all_monthly_events, selected_tariff, holidays
#                 )
#                 
#                 if not monthly_summary_df.empty:
#                     st.markdown("#### 6.3.2 ðŸ“… Monthly Summary")
#                     st.markdown("*Maximum MD excess and energy requirements aggregated by month*")
#                     
#                     # Display the monthly summary table
#                     st.dataframe(
#                         monthly_summary_df,
#                         use_container_width=True,
#                         hide_index=True
#                     )
#                     
#                     # Add summary metrics below the monthly summary table
#                     col1, col2, col3 = st.columns(3)
#                     
#                     total_months = len(monthly_summary_df)
#                     
#                     # Get column names dynamically based on tariff type
#                     tariff_type = 'General'
#                     if selected_tariff:
#                         tariff_name = selected_tariff.get('Tariff', '').lower()
#                         tariff_type_field = selected_tariff.get('Type', '').lower()
#                         if 'tou' in tariff_name or 'tou' in tariff_type_field or tariff_type_field == 'tou':
#                             tariff_type = 'TOU'
#                     
#                     md_excess_col = f'{tariff_type} MD Excess (Max kW)'
#                     energy_col = f'{tariff_type} Required Energy (Max kWh)'
#                     
#                     if md_excess_col in monthly_summary_df.columns:
#                         max_monthly_md_excess = monthly_summary_df[md_excess_col].max()
#                         max_monthly_energy = monthly_summary_df[energy_col].max()
#                         
#                         col1.metric("Total Months", total_months)
#                         col2.metric("Max Monthly MD Excess", f"{max_monthly_md_excess:.2f} kW")
#                         col3.metric("Max Monthly Required Energy", f"{max_monthly_energy:.2f} kWh")
#                     
#                     st.markdown("---")
#                 else:
#                     st.info("No monthly summary data available.")
#                     
#             except Exception as e:
#                 st.error(f"Error generating monthly summary table: {str(e)}")
#                 st.info("Monthly summary not available - continuing with clustering analysis...")
#             
#             # Default battery parameters for clustering (can be customized)
#             battery_params_cluster = {
#                 'unit_energy_kwh': 100,  # Default 100 kWh battery
#                 'soc_min': 5.0,  # Updated to 5% minimum safety SOC
#                 'soc_max': 95.0,  # Updated to 95% maximum SOC
#                 'efficiency': 0.95,
#                 'charge_power_limit_kw': 100  # Increased to 100 kW for more flexible clustering
#             }
#             
#             # MD hours and working days (customize as needed)
#             md_hours = (14, 22)  # 2PM-10PM
#             working_days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri']  # 3-letter abbreviations
#             
#             try:
#                 # Prepare events data for clustering
#                 events_for_clustering = df_events_summary.copy()
#                 
#                 # Add required columns for clustering
#                 if 'start' not in events_for_clustering.columns:
#                     events_for_clustering['start'] = pd.to_datetime(
#                         events_for_clustering['Start Date'].astype(str) + ' ' + events_for_clustering['Start Time'].astype(str)
#                     )
#                 if 'end' not in events_for_clustering.columns:
#                     events_for_clustering['end'] = pd.to_datetime(
#                         events_for_clustering['End Date'].astype(str) + ' ' + events_for_clustering['End Time'].astype(str)
#                     )
#                 if 'peak_abs_kw' not in events_for_clustering.columns:
#                     events_for_clustering['peak_abs_kw'] = events_for_clustering['General Peak Load (kW)']
#                 if 'energy_above_threshold_kwh' not in events_for_clustering.columns:
#                     events_for_clustering['energy_above_threshold_kwh'] = events_for_clustering['General Required Energy (kWh)']
#                 
#                 # Perform clustering
#                 clusters_df, events_for_clustering = cluster_peak_events(
#                     events_for_clustering, battery_params_cluster, md_hours, working_days
#                 )
#                 
#                 if not clusters_df.empty:
#                     st.success(f"âœ… Successfully grouped {len(events_for_clustering)} events into {len(clusters_df)} clusters")
#                     
#                     # Prepare display data
#                     cluster_display = clusters_df.copy()
#                     cluster_display['cluster_duration_hr'] = (cluster_display['cluster_duration_hr'] * 60).round(1)  # Convert to minutes
#                     cluster_display['peak_abs_kw_in_cluster'] = cluster_display['peak_abs_kw_in_cluster'].round(1)
#                     cluster_display['total_energy_above_threshold_kwh'] = cluster_display['total_energy_above_threshold_kwh'].round(2)
#                     
#                     # Rename columns for better display
#                     cluster_display = cluster_display.rename(columns={
#                         'cluster_id': 'Cluster ID',
#                         'num_events_in_cluster': 'Events Count',
#                         'cluster_duration_hr': 'Duration (minutes)',
#                         'peak_abs_kw_in_cluster': 'Peak Power (kW)',
#                         'total_energy_above_threshold_kwh': 'Total Energy (kWh)',
#                         'cluster_start': 'Start Time',
#                         'cluster_end': 'End Time'
#                     })
#                     
#                     # Separate single events (duration = 0) from multi-event clusters
#                     single_events = cluster_display[cluster_display['Duration (minutes)'] == 0.0]
#                     multi_event_clusters = cluster_display[cluster_display['Duration (minutes)'] > 0.0]
#                     
#                     # Display multi-event clusters table
#                     if not multi_event_clusters.empty:
#                         st.markdown("**ðŸ“Š Multi-Event Clusters:**")
#                         display_cols = ['Cluster ID', 'Events Count', 'Duration (minutes)', 
#                                       'Peak Power (kW)', 'Total Energy (kWh)', 'Start Time', 'End Time']
#                         available_cols = [col for col in display_cols if col in multi_event_clusters.columns]
#                         st.dataframe(multi_event_clusters[available_cols], use_container_width=True)
#                     else:
#                         st.info("ðŸ“Š No multi-event clusters found - all events are single occurrences.")
#                     
#                     # Display single events separately
#                     if not single_events.empty:
#                         st.markdown("**ðŸ“ Single Events:**")
#                         single_display_cols = ['Cluster ID', 'Peak Power (kW)', 'Total Energy (kWh)', 'Start Time', 'End Time']
#                         available_single_cols = [col for col in single_display_cols if col in single_events.columns]
#                         st.dataframe(single_events[single_display_cols], use_container_width=True)
#                     
#                     # Quick statistics
#                     st.markdown("**ðŸ“Š Clustering Statistics:**")
#                     col1, col2, col3, col4 = st.columns(4)
#                     col1.metric("Total Events", len(clusters_df))
#                     col2.metric("Multi-Event Clusters", len(multi_event_clusters))
#                     col3.metric("Single Events", len(single_events))
#                     if not multi_event_clusters.empty:
#                         col4.metric("Avg Events/Cluster", f"{multi_event_clusters['Events Count'].mean():.1f}")
#                     else:
#                         col4.metric("Avg Events/Cluster", "0.0")
#                     
#                     # === POWER & ENERGY COMPARISON ANALYSIS ===
#                     st.markdown("### 6.4 âš¡ Peak Power & Energy Analysis")
#                     st.markdown("**Comparison between multi-event clusters and single events**")
#                     
#                     # Calculate total energy (kWh) and power (kW) for clusters vs single events
#                     if 'peak_abs_kw_sum_in_cluster' in clusters_df.columns:
#                         
#                         # Get max total energy from multi-event clusters (kWh)
#                         if not multi_event_clusters.empty:
#                             # For multi-event clusters, use total energy above threshold
#                             max_cluster_energy = clusters_df[clusters_df['cluster_duration_hr'] > 0]['total_energy_above_threshold_kwh'].max()
#                         else:
#                             max_cluster_energy = 0
#                         
#                         # Get max energy from single events (kWh)
#                         if not single_events.empty:
#                             # For single events, get max General Required Energy
#                             single_event_ids = clusters_df[clusters_df['cluster_duration_hr'] == 0]['cluster_id']
#                             single_event_energies = []
#                             for cluster_id in single_event_ids:
#                                 single_events_in_cluster = events_for_clustering[events_for_clustering['cluster_id'] == cluster_id]
#                                 if 'General Required Energy (kWh)' in single_events_in_cluster.columns:
#                                     max_energy_in_cluster = single_events_in_cluster['General Required Energy (kWh)'].max()
#                                     single_event_energies.append(max_energy_in_cluster)
#                             max_single_energy = max(single_event_energies) if single_event_energies else 0
#                         else:
#                             max_single_energy = 0
#                         
#                         # Calculate TOU Excess for clusters and single events (kW)
#                         # For multi-event clusters, get max TOU Excess sum
#                         if not multi_event_clusters.empty:
#                             # Calculate TOU Excess for each cluster by summing individual event TOU Excess values
#                             max_cluster_tou_excess = 0
#                             for cluster_id in clusters_df[clusters_df['cluster_duration_hr'] > 0]['cluster_id']:
#                                 # Get events in this cluster and sum their TOU Excess values
#                                 cluster_events = events_for_clustering[events_for_clustering['cluster_id'] == cluster_id]
#                                 cluster_tou_excess_sum = cluster_events['TOU Excess (kW)'].sum() if 'TOU Excess (kW)' in cluster_events.columns else 0
#                                 max_cluster_tou_excess = max(max_cluster_tou_excess, cluster_tou_excess_sum)
#                         else:
#                             max_cluster_tou_excess = 0
#                         
#                         # For single events, get max individual TOU Excess
#                         if not single_events.empty:
#                             max_single_tou_excess = events_for_clustering[events_for_clustering['cluster_id'].isin(single_events['Cluster ID'])]['TOU Excess (kW)'].max() if 'TOU Excess (kW)' in events_for_clustering.columns else 0
#                         else:
#                             max_single_tou_excess = 0
#                         
#                         # Compare and display results
#                         st.markdown("**ðŸ”‹ Battery Sizing Requirements:**")
#                         
#                         col1, col2, col3, col4 = st.columns(4)
#                         
#                         with col1:
#                             st.metric(
#                                 "Max Cluster Energy (Sum)", 
#                                 f"{max_cluster_energy:.1f} kWh",
#                                 help="Total energy above threshold within the highest-demand cluster"
#                             )
#                         
#                         with col2:
#                             st.metric(
#                                 "Max Single Event Energy", 
#                                 f"{max_single_energy:.1f} kWh",
#                                 help="Highest individual event energy requirement"
#                             )
#                         
#                         with col3:
#                             st.metric(
#                                 "Max Cluster TOU Excess", 
#                                 f"{max_cluster_tou_excess:.1f} kW",
#                                 help="Sum of TOU Excess power within the highest-demand cluster"
#                             )
#                         
#                         with col4:
#                             st.metric(
#                                 "Max Single Event TOU Excess", 
#                                 f"{max_single_tou_excess:.1f} kW",
#                                 help="Highest individual event TOU Excess power"
#                             )
#                         
#                         # Determine overall maximums
#                         overall_max_energy = max(max_cluster_energy, max_single_energy)
#                         overall_max_tou_excess = max(max_cluster_tou_excess, max_single_tou_excess)
#                         
#                         # Recommendations
#                         st.markdown("**ðŸ’¡ Battery Sizing Recommendations:**")
#                         
#                         if overall_max_energy == max_cluster_energy and max_cluster_energy > max_single_energy:
#                             energy_source = "multi-event cluster"
#                             energy_advantage = ((max_cluster_energy - max_single_energy) / max_single_energy * 100) if max_single_energy > 0 else 0
#                         else:
#                             energy_source = "single event"
#                             energy_advantage = 0
#                         
#                         if overall_max_tou_excess == max_cluster_tou_excess and max_cluster_tou_excess > max_single_tou_excess:
#                             tou_excess_source = "multi-event cluster"
#                             tou_excess_advantage = ((max_cluster_tou_excess - max_single_tou_excess) / max_single_tou_excess * 100) if max_single_tou_excess > 0 else 0
#                         else:
#                             tou_excess_source = "single event"
#                             tou_excess_advantage = 0
#                         
#                         st.info(f"""
#                         **Peak Shaving Energy**: {overall_max_energy:.1f} kWh (driven by {energy_source})
#                         **TOU Excess Capacity**: {overall_max_tou_excess:.1f} kW (driven by {tou_excess_source})
#                         
#                         {'ðŸ“ˆ Multi-event clusters require ' + f'{energy_advantage:.1f}% more energy capacity' if energy_advantage > 0 else 'ðŸ“Š Single events determine energy requirements'}
#                         {'ðŸ“ˆ Multi-event clusters require ' + f'{tou_excess_advantage:.1f}% more TOU excess capacity' if tou_excess_advantage > 0 else 'ðŸ“Š Single events determine TOU excess requirements'}
#                         """)
#                         
#                         # Detailed cluster breakdown for multi-event clusters
#                         if not multi_event_clusters.empty and 'peak_abs_kw_sum_in_cluster' in cluster_display.columns:
#                             st.markdown("**ðŸ“‹ Multi-Event Cluster Energy & Power Breakdown:**")
#                             cluster_analysis = multi_event_clusters.copy()
#                             # Display additional cluster details if needed
#                     
#                     else:
#                         st.warning("No clustering data available for detailed power and energy analysis.")
#                 
#                 else:
#                     st.info("No peak events found for clustering analysis.")
#             
#             except Exception as e:
#                 # V2 uses direct calculations without clustering dependency
#                 pass
#             
#             # === BATTERY SIZING RECOMMENDATIONS ===
#             st.markdown("### 6.5 ðŸ”‹ Battery Sizing Analysis")
#             
#             # Check if we have clustering results for battery sizing
#             if 'clusters_df' in locals() and not clusters_df.empty and 'peak_abs_kw_sum_in_cluster' in clusters_df.columns:
#                 st.info("âœ… Using enhanced clustering analysis for battery sizing recommendations")
#                 
#                 # Use clustering analysis results for more accurate power requirements
#                 # Get max values from clustering analysis
#                 max_cluster_energy = clusters_df[clusters_df['cluster_duration_hr'] > 0]['total_energy_above_threshold_kwh'].max() if len(clusters_df[clusters_df['cluster_duration_hr'] > 0]) > 0 else 0
#                 max_single_energy = 0
#                 
#                 # Calculate max energy from single events
#                 if len(clusters_df[clusters_df['cluster_duration_hr'] == 0]) > 0:
#                     single_event_ids = clusters_df[clusters_df['cluster_duration_hr'] == 0]['cluster_id']
#                     single_event_energies = []
#                     for cluster_id in single_event_ids:
#                         cluster_events = events_for_clustering[events_for_clustering['cluster_id'] == cluster_id]
#                         if 'General Required Energy (kWh)' in cluster_events.columns:
#                             single_event_energies.append(cluster_events['General Required Energy (kWh)'].max())
#                     max_single_energy = max(single_event_energies) if single_event_energies else 0
#                 
#                 # Use the Max Monthly Required Energy from Section B2's monthly summary instead of clustering calculation
#                 # This ensures consistency between Battery Sizing Analysis and Section B2
#                 if 'monthly_summary_df' in locals() and not monthly_summary_df.empty:
#                     # Determine tariff type for column selection
#                     tariff_type = 'General'
#                     if selected_tariff:
#                         tariff_name = selected_tariff.get('Tariff', '').lower()
#                         tariff_type_field = selected_tariff.get('Type', '').lower()
#                         if 'tou' in tariff_name or 'tou' in tariff_type_field or tariff_type_field == 'tou':
#                             tariff_type = 'TOU'
#                     
#                     energy_col = f'{tariff_type} Required Energy (Max kWh)'
#                     if energy_col in monthly_summary_df.columns:
#                         recommended_energy_capacity = monthly_summary_df[energy_col].max()
#                         # Debug log to verify synchronization
#                         print(f"ðŸ”‹ DEBUG - Using Max Monthly Required Energy from Section B2: {recommended_energy_capacity:.2f} kWh")
#                     else:
#                         # Fallback to clustering calculation if monthly summary doesn't have the column
#                         recommended_energy_capacity = max(max_cluster_energy, max_single_energy)
#                         print(f"ðŸ”‹ DEBUG - Column '{energy_col}' not found, using clustering calculation: {recommended_energy_capacity:.2f} kWh")
#                 else:
#                     # Fallback to clustering calculation if monthly summary is not available
#                     recommended_energy_capacity = max(max_cluster_energy, max_single_energy)
#                 
#                 # Calculate power requirements from TOU Excess
#                 max_cluster_tou_excess = 0
#                 if len(clusters_df[clusters_df['cluster_duration_hr'] > 0]) > 0:
#                     for cluster_id in clusters_df[clusters_df['cluster_duration_hr'] > 0]['cluster_id']:
#                         cluster_events = events_for_clustering[events_for_clustering['cluster_id'] == cluster_id]
#                         cluster_tou_excess_sum = cluster_events['TOU Excess (kW)'].sum() if 'TOU Excess (kW)' in cluster_events.columns else 0
#                         max_cluster_tou_excess = max(max_cluster_tou_excess, cluster_tou_excess_sum)
#                 
#                 # Get max individual TOU Excess from single events
#                 max_single_tou_excess = 0
#                 if len(clusters_df[clusters_df['cluster_duration_hr'] == 0]) > 0:
#                     single_event_ids = clusters_df[clusters_df['cluster_duration_hr'] == 0]['cluster_id']
#                     max_single_tou_excess = events_for_clustering[events_for_clustering['cluster_id'].isin(single_event_ids)]['TOU Excess (kW)'].max() if 'TOU Excess (kW)' in events_for_clustering.columns else 0
#                 
#                 # Use the larger value for power requirement
#                 max_power_shaving_required = max(max_cluster_tou_excess, max_single_tou_excess)
#                 
#             else:
#                 # V2 uses direct calculations without clustering dependency
#                 # Try to use Max Monthly Required Energy from Section B2's monthly summary for consistency
#                 recommended_energy_capacity = 0
#                 if 'monthly_summary_df' in locals() and not monthly_summary_df.empty:
#                     # Determine tariff type for column selection
#                     tariff_type = 'General'
#                     if selected_tariff:
#                         tariff_name = selected_tariff.get('Tariff', '').lower()
#                         tariff_type_field = selected_tariff.get('Type', '').lower()
#                         if 'tou' in tariff_name or 'tou' in tariff_type_field or tariff_type_field == 'tou':
#                             tariff_type = 'TOU'
#                     
#                     energy_col = f'{tariff_type} Required Energy (Max kWh)'
#                     if energy_col in monthly_summary_df.columns:
#                         recommended_energy_capacity = monthly_summary_df[energy_col].max()
#                 
#                 max_power_shaving_required = 0
#                 
#                 if monthly_targets is not None and len(monthly_targets) > 0:
#                     # Calculate max shaving power directly from monthly targets and reference peaks
#                     shaving_amounts = []
#                     for month_period, target_demand in monthly_targets.items():
#                         if month_period in reference_peaks:
#                             max_demand = reference_peaks[month_period]
#                             shaving_amount = max_demand - target_demand
#                             if shaving_amount > 0:
#                                 shaving_amounts.append(shaving_amount)
#                     
#                     max_power_shaving_required = max(shaving_amounts) if shaving_amounts else 0
#                 
#                 # Calculate max TOU excess from individual events (power-based, not energy)
#                 max_tou_excess_fallback = max([event.get('TOU Excess (kW)', 0) or 0 for event in all_monthly_events]) if 'all_monthly_events' in locals() and all_monthly_events else 0
#                 max_power_shaving_required = max(max_power_shaving_required, max_tou_excess_fallback)
#                 
#                 # If monthly summary wasn't available, use power shaving as energy capacity estimate
#                 if recommended_energy_capacity == 0:
#                     recommended_energy_capacity = max_power_shaving_required
#             
#             # Round up to nearest whole number for recommended capacity
#             recommended_capacity_rounded = int(np.ceil(recommended_energy_capacity)) if recommended_energy_capacity > 0 else 0
#             
#             # Display key metrics only
#             col1, col2 = st.columns(2)
#             
#             with col1:
#                 st.metric(
#                     "Max Power Shaving Required",
#                     f"{max_power_shaving_required:.1f} kW",
#                     help="Maximum power reduction required based on TOU excess from clustering analysis"
#                 )
#             
#             with col2:
#                 st.metric(
#                     "Max Required Energy",
#                     f"{recommended_energy_capacity:.1f} kWh", 
#                     help="Maximum monthly energy requirement from Section B2 monthly summary analysis"
#                 )
#         
#         # Battery Impact Analysis Section moved to separate function
#         
#         # Render battery selection dropdown right before battery sizing analysis
#         _render_battery_selection_dropdown()
#         
#         # Calculate shared analysis variables for both battery sizing and simulation
#         # These need to be available in broader scope for battery simulation section
#         max_power_shaving_required = 0
#         recommended_energy_capacity = 0
#         total_md_cost = 0
#         
#         # Console logging for debugging - check conditions first
#         print(f"ðŸ”‹ DEBUG - Battery Sizing Conditions Check:")
#         print(f"   all_monthly_events exists: {'all_monthly_events' in locals()}")
#         if 'all_monthly_events' in locals():
#             print(f"   all_monthly_events length: {len(all_monthly_events) if all_monthly_events else 0}")
#         print(f"   clusters_df exists: {'clusters_df' in locals()}")
#         if 'clusters_df' in locals():
#             print(f"   clusters_df empty: {clusters_df.empty if 'clusters_df' in locals() else 'N/A'}")
#             print(f"   has peak_abs_kw_sum_in_cluster: {'peak_abs_kw_sum_in_cluster' in clusters_df.columns if 'clusters_df' in locals() and not clusters_df.empty else 'N/A'}")
#         
#         if all_monthly_events:
#             # Check if clustering analysis was performed and has results
#             if ('clusters_df' in locals() and not clusters_df.empty and 
#                 'peak_abs_kw_sum_in_cluster' in clusters_df.columns):
#                 
#                 # Use clustering analysis results for more accurate power requirements
#                 # Get max total peak power from multi-event clusters
#                 if len(clusters_df[clusters_df['cluster_duration_hr'] > 0]) > 0:
#                     max_cluster_sum_power = clusters_df[clusters_df['cluster_duration_hr'] > 0]['peak_abs_kw_sum_in_cluster'].max()
#                     max_cluster_energy = clusters_df[clusters_df['cluster_duration_hr'] > 0]['total_energy_above_threshold_kwh'].max()
#                 else:
#                     max_cluster_sum_power = 0
#                     max_cluster_energy = 0
#                 
#                 # Get max power from single events
#                 if len(clusters_df[clusters_df['cluster_duration_hr'] == 0]) > 0:
#                     max_single_power = clusters_df[clusters_df['cluster_duration_hr'] == 0]['peak_abs_kw_in_cluster'].max()
#                     
#                     # Get max energy from single events
#                     single_event_ids = clusters_df[clusters_df['cluster_duration_hr'] == 0]['cluster_id']
#                     single_event_energies = []
#                     for cluster_id in single_event_ids:
#                         cluster_events = events_for_clustering[events_for_clustering['cluster_id'] == cluster_id]
#                         if not cluster_events.empty:
#                             single_event_energies.append(cluster_events['General Required Energy (kWh)'].max())
#                     max_single_energy = max(single_event_energies) if single_event_energies else 0
#                 else:
#                     max_single_power = 0
#                     max_single_energy = 0
#                 
#                 # Calculate Excess for clusters and single events based on tariff type (same logic as first section)
#                 # Determine which excess column to use based on tariff type
#                 excess_col = 'TOU Excess (kW)' if tariff_type == 'TOU' else 'General Excess (kW)'
#                 
#                 # For multi-event clusters, get max excess sum
#                 if len(clusters_df[clusters_df['cluster_duration_hr'] > 0]) > 0:
#                     max_cluster_excess = 0
#                     for cluster_id in clusters_df[clusters_df['cluster_duration_hr'] > 0]['cluster_id']:
#                         cluster_events = events_for_clustering[events_for_clustering['cluster_id'] == cluster_id]
#                         cluster_excess_sum = cluster_events[excess_col].sum() if excess_col in cluster_events.columns else 0
#                         max_cluster_excess = max(max_cluster_excess, cluster_excess_sum)
#                 else:
#                     max_cluster_excess = 0
#                 
#                 # For single events, get max individual excess
#                 if len(clusters_df[clusters_df['cluster_duration_hr'] == 0]) > 0:
#                     single_event_ids = clusters_df[clusters_df['cluster_duration_hr'] == 0]['cluster_id']
#                     max_single_excess = events_for_clustering[events_for_clustering['cluster_id'].isin(single_event_ids)][excess_col].max() if excess_col in events_for_clustering.columns else 0
#                 else:
#                     max_single_excess = 0
#                 
#                 # Use the larger value between clusters and single events for power requirement
#                 max_power_shaving_required = max(max_cluster_excess, max_single_excess)
#                 recommended_energy_capacity = max(max_cluster_energy, max_single_energy)  # Energy capacity from clustering analysis
#                 
#                 # Console logging for debugging - CLUSTERING ANALYSIS RESULTS
#                 print(f"ðŸ”‹ DEBUG - Battery Sizing Values (CLUSTERING ANALYSIS):")
#                 print(f"   Selected tariff type: {tariff_type}")
#                 print(f"   Using excess column: {excess_col}")
#                 print(f"   max_power_shaving_required = {max_power_shaving_required:.1f} kW")
#                 print(f"   recommended_energy_capacity = {recommended_energy_capacity:.1f} kWh")
#                 print(f"   max_cluster_sum_power = {max_cluster_sum_power:.1f} kW")
#                 print(f"   max_single_power = {max_single_power:.1f} kW")
#                 
#                 st.info(f"""
#                 **ðŸ”‹ Enhanced Battery Sizing (from Clustering Analysis):**
#                 - **Tariff Type**: {tariff_type}
#                 - **Max Cluster Energy**: {max_cluster_energy:.1f} kWh
#                 - **Max Single Event Energy**: {max_single_energy:.1f} kWh
#                 - **Max Cluster {tariff_type} Excess**: {max_cluster_excess:.1f} kW
#                 - **Max Single Event {tariff_type} Excess**: {max_single_excess:.1f} kW
#                 - **Selected Energy Capacity**: {recommended_energy_capacity:.1f} kWh
#                 - **Selected Power Requirement**: {max_power_shaving_required:.1f} kW
#                 """)
#                 
#             else:
#                 # V2 uses direct calculations without clustering dependency
#                 
#                 # Calculate max shaving power from monthly targets and max demands
#                 if monthly_targets is not None and len(monthly_targets) > 0:
#                     shaving_amounts = []
#                     for month_period, target_demand in monthly_targets.items():
#                         if month_period in reference_peaks:
#                             max_demand = reference_peaks[month_period]
#                             shaving_amount = max_demand - target_demand
#                             if shaving_amount > 0:
#                                 shaving_amounts.append(shaving_amount)
#                     max_power_shaving_required = max(shaving_amounts) if shaving_amounts else 0
#                 
#                 # Calculate max excess from individual events based on tariff type (power-based, not energy)
#                 if tariff_type == 'TOU':
#                     max_excess_fallback = max([event.get('TOU Excess (kW)', 0) or 0 for event in all_monthly_events]) if all_monthly_events else 0
#                 else:  # General tariff
#                     max_excess_fallback = max([event.get('General Excess (kW)', 0) or 0 for event in all_monthly_events]) if all_monthly_events else 0
#                 max_power_shaving_required = max(max_power_shaving_required, max_excess_fallback)
#                 
#                 # Calculate recommended energy capacity from energy fields based on tariff type (kWh not kW)
#                 if tariff_type == 'TOU':
#                     recommended_energy_capacity = max([event.get('TOU Required Energy (kWh)', 0) or 0 for event in all_monthly_events]) if all_monthly_events else 0
#                 else:  # General tariff
#                     recommended_energy_capacity = max([event.get('General Required Energy (kWh)', 0) or 0 for event in all_monthly_events]) if all_monthly_events else 0
#                 
#                 # Console logging for debugging - FALLBACK CALCULATION
#                 print(f"ðŸ”‹ DEBUG - Battery Sizing Values (FALLBACK METHOD):")
#                 print(f"   Selected tariff type: {tariff_type}")
#                 print(f"   max_power_shaving_required = {max_power_shaving_required:.1f} kW")
#                 print(f"   recommended_energy_capacity = {recommended_energy_capacity:.1f} kWh")
#                 print(f"   monthly_targets available: {monthly_targets is not None and len(monthly_targets) > 0}")
#                 print(f"   number of all_monthly_events: {len(all_monthly_events) if all_monthly_events else 0}")
#             
#             # Calculate total MD cost from events (same for both methods)
#             total_md_cost = sum(event.get('MD Cost Impact (RM)', 0) for event in all_monthly_events)
#         
#         # Console logging for debugging - FINAL RESULTS (always executes)
#         print(f"ðŸ”‹ DEBUG - Final Battery Sizing Results:")
#         print(f"   FINAL max_power_shaving_required = {max_power_shaving_required:.1f} kW")
#         print(f"   FINAL recommended_energy_capacity = {recommended_energy_capacity:.1f} kWh")
#         print(f"   FINAL total_md_cost = RM {total_md_cost:.2f}")
#         
#         # NEW: Battery Quantity Recommendation Section 
#         _render_battery_quantity_recommendation(max_power_shaving_required, recommended_energy_capacity)
#         
#         # Call the battery sizing analysis function with the calculated values
#         _render_battery_sizing_analysis(max_power_shaving_required, recommended_energy_capacity, total_md_cost)
#         
#         # Battery Simulation Analysis Section
#         st.markdown("#### 6.6 ðŸ”‹ Battery Simulation Analysis")
#         
#         # Display battery simulation chart using selected battery specifications
#         if (hasattr(st.session_state, 'tabled_analysis_selected_battery') and 
#             st.session_state.tabled_analysis_selected_battery):
#             
#             # Get selected battery specifications
#             selected_battery = st.session_state.tabled_analysis_selected_battery
#             battery_spec = selected_battery['spec']
#             
#             # Extract battery parameters from selected battery specifications
#             battery_capacity_kwh = battery_spec.get('energy_kWh', 0)
#             battery_power_kw = battery_spec.get('power_kW', 0)
#             
#             # Check if we have the required analysis data with enhanced validation
#             prerequisites_met = True
#             error_messages = []
#             
#             # Validate peak analysis data
#             if max_power_shaving_required <= 0:
#                 prerequisites_met = False
#                 error_messages.append("Max shaving power not calculated or invalid")
#             
#             if recommended_energy_capacity <= 0:
#                 prerequisites_met = False
#                 error_messages.append("Max TOU excess not calculated or invalid")
#             
#             # Validate battery specifications
#             if battery_power_kw <= 0:
#                 prerequisites_met = False
#                 error_messages.append(f"Invalid battery power: {battery_power_kw} kW")
#             
#             if battery_capacity_kwh <= 0:
#                 prerequisites_met = False
#                 error_messages.append(f"Invalid battery capacity: {battery_capacity_kwh} kWh")
#             
#             # Validate data structure
#             if not hasattr(df, 'columns') or power_col not in df.columns:
#                 prerequisites_met = False
#                 error_messages.append(f"Power column '{power_col}' not found in dataframe")
#             
#             if prerequisites_met:
#                 
#                 # ðŸŽ›ï¸ INTEGRATION: Use user-configured battery quantity from Battery Quantity Configuration
#                 if hasattr(st.session_state, 'tabled_analysis_battery_quantity') and st.session_state.tabled_analysis_battery_quantity:
#                     # Use quantity configured by user in Battery Quantity Configuration section
#                     optimal_units = int(st.session_state.tabled_analysis_battery_quantity)
#                     quantity_source = "User-configured from Battery Quantity Configuration"
#                     
#                     # Display success message for configured quantity
#                     st.success(f"âœ… **Using Battery Quantity Configuration**: {optimal_units} units as configured in 'ðŸŽ›ï¸ Battery Quantity Configuration' section above.")
#                 else:
#                     # Fallback: Calculate optimal number of units based on the analysis
#                     units_for_power = int(np.ceil(max_power_shaving_required / battery_power_kw)) if battery_power_kw > 0 else 1
#                     units_for_excess = int(np.ceil(recommended_energy_capacity / battery_power_kw)) if battery_power_kw > 0 else 1
#                     optimal_units = max(units_for_power, units_for_excess, 1)
#                     quantity_source = "Auto-calculated based on requirements"
#                     
#                     # Display info message about auto-calculation
#                     st.info(f"â„¹ï¸ **Auto-calculating Battery Quantity**: {optimal_units} units. You can configure a specific quantity in the 'ðŸŽ›ï¸ Battery Quantity Configuration' section above to override this calculation.")
#                 
#                 # Calculate total system specifications using user-configured or calculated quantity
#                 total_battery_capacity = optimal_units * battery_capacity_kwh
#                 total_battery_power = optimal_units * battery_power_kw
#                 
#                 st.info(f"""
#                 **ðŸ”‹ Battery Simulation Parameters:**
#                 - **Selected Battery**: {selected_battery['label']}
#                 - **Battery Model**: {battery_spec.get('model', 'Unknown')}
#                 - **Unit Specifications**: {battery_capacity_kwh:.1f} kWh, {battery_power_kw:.1f} kW per unit
#                 - **System Configuration**: {optimal_units} units ({quantity_source})
#                 - **Total System Capacity**: {total_battery_capacity:.1f} kWh
#                 - **Total System Power**: {total_battery_power:.1f} kW
#                 - **Based on**: Selected Power Requirement ({max_power_shaving_required:.1f} kW) & Selected Energy Capacity ({recommended_energy_capacity:.1f} kWh)
#                 """)
#                 
#                 # Call the battery simulation workflow (simulation + chart display)
#                 try:
#                     # === STEP 1: Prepare V1-compatible dataframe ===
#                     df_for_v1 = df.copy()
#                     
#                     # Add required columns that V1 expects
#                     if 'Original_Demand' not in df_for_v1.columns:
#                         df_for_v1['Original_Demand'] = df_for_v1[power_col]
#                     
#                     # === STEP 2: Prepare V1-compatible sizing parameter ===
#                     sizing_dict = {
#                         'capacity_kwh': total_battery_capacity,
#                         'power_rating_kw': total_battery_power,
#                         'units': optimal_units,
#                         'c_rate': battery_spec.get('c_rate', 1.0),
#                         'efficiency': 0.95  # Default efficiency
#                     }
#                     
#                     # === STEP 3: Calculate proper target demand ===
#                     if 'monthly_targets' in locals() and len(monthly_targets) > 0:
#                         target_demand_for_sim = float(monthly_targets.iloc[0])
#                     else:
#                         target_demand_for_sim = float(df[power_col].quantile(0.8))
#                     
#                     # === STEP 4: CRITICAL - Run battery simulation first ===
#                     st.info("âš¡ Running battery simulation...")
#                     
#                     # Prepare all required parameters for V1 simulation function
#                     battery_sizing = {
#                         'capacity_kwh': total_battery_capacity,
#                         'power_rating_kw': total_battery_power,
#                         'units': optimal_units
#                     }
#                     
#                     battery_params = {
#                         'efficiency': 0.95,
#                         'round_trip_efficiency': 95.0,  # Percentage
#                         'c_rate': battery_spec.get('c_rate', 1.0),
#                         'min_soc': 5.0,  # Updated to 5% minimum safety SOC
#                         'max_soc': 95.0,  # Updated to 95% maximum SOC
#                         'depth_of_discharge': 80.0  # Max usable % of capacity
#                     }
#                     
#                     # Auto-detect global sampling interval (fallback to 15 minutes)
#                     interval_hours = _infer_interval_hours(df_for_v1.index, fallback=0.25)
#                     try:
#                         st.session_state['data_interval_hours'] = interval_hours
#                     except Exception:
#                         pass
#                     
#                     st.info(f"ðŸ”§ Using {interval_hours*60:.0f}-minute intervals for V2 battery simulation")
#                     
#                     # V2 ENHANCEMENT: Use monthly targets instead of static target
#                     simulation_results = _simulate_battery_operation_v2(
#                         df_for_v1,                     # DataFrame with demand data
#                         power_col,                     # Column name containing power demand
#                         monthly_targets,               # V2: Dynamic monthly targets instead of static target
#                         battery_sizing,                # Battery sizing dictionary
#                         battery_params,                # Battery parameters dictionary  
#                         interval_hours,                # Interval length in hours
#                         selected_tariff,               # Tariff configuration
#                         holidays if 'holidays' in locals() else set()  # Holidays set
#                     )
#                     
#                     # === STEP 5: Display results and metrics ===
#                     if simulation_results and 'df_simulation' in simulation_results:
#                         st.success("âœ… V2 Battery simulation with monthly targets completed successfully!")
#                         
#                         # Show key simulation metrics
#                         col1, col2, col3, col4 = st.columns(4)
#                         
#                         with col1:
#                             st.metric(
#                                 "Peak Reduction", 
#                                 f"{simulation_results.get('peak_reduction_kw', 0): .1f} kW",
#                                 help="Maximum demand reduction achieved"
#                             )
#                         
#                         with col2:
#                             st.metric(
#                                 "Success Rate",
#                                 f"{simulation_results.get('success_rate_percent', 0):.1f}%",
#                                 help="Percentage of peak events successfully managed"
#                             )
#                         
#                         with col3:
#                             st.metric(
#                                 "Energy Discharged",
#                                 f"{simulation_results.get('total_energy_discharged', 0):.1f} kWh",
#                                 help="Total energy discharged during peak periods"
#                             )
#                         
#                         with col4:
#                             st.metric(
#                                 "Average SOC",
#                                 f"{simulation_results.get('average_soc', 0):.1f}%",
#                                 help="Average state of charge throughout simulation"
#                             )
#                         
#                         # === STEP 6: Display the battery simulation chart ===
#                         st.subheader("ðŸ“Š Battery Operation Simulation")
#                         _display_v2_battery_simulation_chart(
#                             simulation_results['df_simulation'],  # Simulated dataframe
#                             monthly_targets,              # V2 dynamic monthly targets
#                             sizing_dict,                        # Battery sizing dictionary
#                             selected_tariff,                    # Tariff configuration
#                             holidays if 'holidays' in locals() else set()  # Holidays set
#                         )
#                         
#                         # === STEP 6.1: TOU PERFORMANCE ANALYSIS (Missing Integration Fixed) ===
#                         # Fix for "local variable 'st' referenced before assignment" error
#                         # These TOU display functions were orphaned and never called in the main workflow
#                         if selected_tariff:
#                             tariff_type = selected_tariff.get('Type', '').lower()
#                             tariff_name = selected_tariff.get('Tariff', '').lower()
#                             is_tou_tariff = tariff_type == 'tou' or 'tou' in tariff_name
#                             
#                             if is_tou_tariff:
#                                 st.markdown("---")
#                                 st.subheader("ðŸŒ… TOU Tariff Performance Analysis")
#                                 
#                                 # Display TOU performance summary
#                                 _display_tou_performance_summary(simulation_results, selected_tariff)
#                                 
#                                 # Display TOU vs General comparison
#                                 _display_tou_vs_general_comparison(simulation_results, selected_tariff)
#                         
#                         # === STEP 7: Enhanced BESS Dispatch Simulation & Savings Analysis ===
#                         st.markdown("---")
#                         st.markdown("#### 6.7 ðŸ”‹ BESS Dispatch Simulation & Comprehensive Analysis")
#                         st.markdown("**Advanced battery dispatch simulation with engineering constraints and financial analysis**")
#                         
#                         if all_monthly_events:
#                             # SECTION 6: DISPATCH SIMULATION
#                             dispatch_results = []
#                             
#                             # Battery engineering parameters with proper DoD, efficiency, and C-rate limits
#                             battery_specs = selected_battery['spec']
#                             nameplate_energy_kwh = battery_specs.get('energy_kWh', 0) * optimal_units
#                             nameplate_power_kw = battery_specs.get('power_kW', 0) * optimal_units
#                             c_rate = battery_specs.get('c_rate', 1.0)
#                             
#                             # Engineering constraints
#                             depth_of_discharge = 85  # % (preserve battery life)
#                             round_trip_efficiency = 92  # % (charging + discharging losses)
#                             degradation_factor = 90  # % (end-of-life performance)
#                             safety_margin = 10  # % buffer for real conditions
#                             
#                             # Calculate usable specifications
#                             usable_energy_kwh = (nameplate_energy_kwh * 
#                                                depth_of_discharge / 100 * 
#                                                degradation_factor / 100)
#                             
#                             usable_power_kw = (nameplate_power_kw * 
#                                              degradation_factor / 100)
#                             
#                             # C-rate power limit
#                             max_continuous_power_kw = min(usable_power_kw, usable_energy_kwh * c_rate)
#                             
#                             # SOC operating window
#                             soc_min = (100 - depth_of_discharge) / 2  # e.g., 7.5% for 85% DoD
#                             soc_max = soc_min + depth_of_discharge   # e.g., 92.5% for 85% DoD
#                             
#                             # Start at 80% SOC (near full but allowing charging headroom)
#                             running_soc = 80.0
#                             
#                             st.info(f"""
#                             **ðŸ”§ BESS Engineering Parameters:**
#                             - **Fleet Capacity**: {nameplate_energy_kwh:.1f} kWh nameplate â†’ {usable_energy_kwh:.1f} kWh usable
#                             - **Fleet Power**: {nameplate_power_kw:.1f} kW nameplate â†’ {max_continuous_power_kw:.1f} kW continuous
#                             - **SOC Window**: {soc_min:.1f}% - {soc_max:.1f}% ({depth_of_discharge}% DoD)
#                             - **Starting SOC**: {running_soc:.1f}% (Near-full for maximum availability)
#                             - **Round-trip Efficiency**: {round_trip_efficiency}%
#                             - **C-rate Limit**: {c_rate}C ({max_continuous_power_kw:.1f} kW max)
#                             """)
#                             
#                             # Additional debug info for troubleshooting
#                             st.markdown(f"""
#                             **ðŸ” Debug Info:**
#                             - Available SOC Range at Start: {running_soc - soc_min:.1f}%
#                             - Available Energy at Start: {(usable_energy_kwh * (running_soc - soc_min) / 100):.1f} kWh
#                             - Total Events to Process: {len(all_monthly_events)}
#                             """)
#                             
#                             # Process each peak event with proper dispatch logic including recharging
#                             previous_event_end = None
#                             
#                             for i, event in enumerate(all_monthly_events):
#                                 event_id = f"Event_{i+1:03d}"
#                                 
#                                 # Event parameters
#                                 start_date = pd.to_datetime(f"{event['Start Date']} {event['Start Time']}")
#                                 end_date = pd.to_datetime(f"{event['End Date']} {event['End Time']}")
#                                 duration_hours = event.get('Duration (min)', 0) / 60
#                                 
#                                 # RECHARGING LOGIC: Charge battery between events during off-peak periods
#                                 if previous_event_end is not None and start_date > previous_event_end:
#                                     # Calculate time between events for potential charging
#                                     time_between_events = (start_date - previous_event_end).total_seconds() / 3600  # hours
#                                     
#                                     # Assume charging during off-peak hours (simplified: charge if gap > 2 hours)
#                                     if time_between_events >= 2.0 and running_soc < soc_max:
#                                         # Calculate charging potential
#                                         charging_headroom_soc = soc_max - running_soc  # Available SOC to charge
#                                         charging_headroom_energy = (usable_energy_kwh * charging_headroom_soc / 100)
#                                         
#                                         # Charging power (limited by C-rate and available time)
#                                         max_charging_power_kw = max_continuous_power_kw * 0.8  # Conservative charging rate
#                                         available_charging_time = min(time_between_events, 8.0)  # Max 8 hours charging
#                                         
#                                         # Energy that can be charged
#                                         max_chargeable_energy = max_charging_power_kw * available_charging_time
#                                         
#                                         # Actual charging (limited by headroom and efficiency)
#                                         charging_energy_kwh = min(charging_headroom_energy, max_chargeable_energy)
#                                         actual_stored_energy = charging_energy_kwh * (round_trip_efficiency / 100)  # Account for charging losses
#                                         
#                                         # Update SOC with charging
#                                         soc_increase = (actual_stored_energy / usable_energy_kwh) * 100
#                                         running_soc = min(soc_max, running_soc + soc_increase)
#                                 
#                                 # DISCHARGE LOGIC: Handle peak event
#                                 original_peak_kw = event.get('General Peak Load (kW)', 0)
#                                 excess_kw = event.get('General Excess (kW)', 0)
#                                 target_md_kw = original_peak_kw - excess_kw
#                                 
#                                 # Available energy for discharge (considering SOC and usable capacity)
#                                 available_soc_range = max(0, running_soc - soc_min)
#                                 available_energy_kwh = (usable_energy_kwh * available_soc_range / 100)
#                                 
#                                 # Power constraints for shaving (consider all limiting factors)
#                                 power_constraint_kw = min(
#                                     excess_kw,  # Don't discharge more than needed
#                                     max_continuous_power_kw,  # C-rate limit
#                                     available_energy_kwh / duration_hours if duration_hours > 0 else 0  # Energy limit over duration
#                                 )
#                                 
#                                 # Calculate actual shaving performance
#                                 shaved_power_kw = max(0, power_constraint_kw)  # Ensure non-negative
#                                 shaved_energy_kwh = shaved_power_kw * duration_hours
#                                 
#                                 # Apply efficiency losses to energy calculation
#                                 actual_energy_consumed = shaved_energy_kwh / (round_trip_efficiency / 100)  # Account for losses
#                                 
#                                 deficit_kw = max(0, excess_kw - shaved_power_kw)
#                                 fully_shaved = deficit_kw <= 0.1  # 0.1 kW tolerance
#                                 
#                                 # Update SOC (account for actual energy consumed including losses)
#                                 soc_decrease = (actual_energy_consumed / usable_energy_kwh) * 100
#                                 new_soc = max(soc_min, running_soc - soc_decrease)
#                                 actual_soc_used = running_soc - new_soc
#                                 running_soc = new_soc
#                                 
#                                 # Update previous event end time for next iteration
#                                 previous_event_end = end_date
#                                 
#                                 # Calculate final load after shaving
#                                 final_peak_kw = original_peak_kw - shaved_power_kw
#                                 
#                                 # MD cost impact calculation
#                                 md_rate_rm_per_kw = 0
#                                 if selected_tariff and isinstance(selected_tariff, dict):
#                                     rates = selected_tariff.get('Rates', {})
#                                     md_rate_rm_per_kw = rates.get('Capacity Rate', 0) + rates.get('Network Rate', 0)
#                                 
#                                 # Monthly savings potential
#                                 monthly_md_reduction_kw = shaved_power_kw
#                                 monthly_savings_rm = monthly_md_reduction_kw * md_rate_rm_per_kw
#                                 
#                                 # Store dispatch results with corrected values including charging info
#                                 charging_info = "No charging" if previous_event_end is None else f"Charged between events"
#                                 if previous_event_end is not None and start_date > previous_event_end:
#                                     time_gap = (start_date - previous_event_end).total_seconds() / 3600
#                                     if time_gap >= 2.0:
#                                         charging_info = f"Charged for {time_gap:.1f}h gap"
#                                     else:
#                                         charging_info = f"Gap too short ({time_gap:.1f}h)"
#                                 
#                                 dispatch_result = {
#                                     'Event_ID': event_id,
#                                     'Event_Period': f"{event['Start Date']} {event['Start Time']} - {event['End Date']} {event['End Time']}",
#                                     'Duration_Hours': round(duration_hours, 2),
#                                     'Original_Peak_kW': round(original_peak_kw, 1),
#                                     'Target_MD_kW': round(target_md_kw, 1),
#                                     'Excess_kW': round(excess_kw, 1),
#                                     'Available_Energy_kWh': round(available_energy_kwh, 1),
#                                     'Power_Constraint_kW': round(power_constraint_kw, 1),
#                                     'Shaved_Power_kW': round(shaved_power_kw, 1),
#                                     'Shaved_Energy_kWh': round(shaved_energy_kwh, 2),
#                                     'Actual_Energy_Consumed_kWh': round(actual_energy_consumed, 2),
#                                     'Deficit_kW': round(deficit_kw, 1),
#                                     'Final_Peak_kW': round(final_peak_kw, 1),
#                                     'Fully_Shaved': 'âœ… Yes' if fully_shaved else 'âŒ No',
#                                     'SOC_Before_%': round(running_soc + actual_soc_used, 1),
#                                     'SOC_After_%': round(running_soc, 1),
#                                     'SOC_Used_%': round(actual_soc_used, 1),
#                                     'Charging_Status': charging_info,
#                                     'Monthly_Savings_RM': round(monthly_savings_rm, 2),
#                                     'Constraint_Type': _determine_constraint_type(excess_kw, max_continuous_power_kw, available_energy_kwh, duration_hours),
#                                     'BESS_Utilization_%': round((actual_energy_consumed / usable_energy_kwh) * 100, 1) if usable_energy_kwh > 0 else 0
#                                 }
#                                 dispatch_results.append(dispatch_result)
#                             
#                             # SECTION 7: SAVINGS CALCULATION
#                             # Convert dispatch results to DataFrame for analysis
#                             df_dispatch = pd.DataFrame(dispatch_results)
#                             
#                             # Calculate monthly savings aggregation
#                             monthly_savings = []
#                             
#                             # Group events by month for savings analysis
#                             df_dispatch['Month'] = pd.to_datetime(df_dispatch['Event_Period'].str.split(' - ').str[0]).dt.to_period('M')
#                             
#                             for month_period in df_dispatch['Month'].unique():
#                                 month_events = df_dispatch[df_dispatch['Month'] == month_period]
#                                 
#                                 # Calculate actual monthly MD (from original data)
#                                 # Get the month's actual maximum demand from the full dataset
#                                 month_start = month_period.start_time
#                                 month_end = month_period.end_time
#                                 month_mask = (df.index >= month_start) & (df.index <= month_end)
#                                 month_data = df[month_mask]
#                                 
#                                 if not month_data.empty:
#                                     # Original monthly MD = maximum demand in the month
#                                     original_md_kw = month_data[power_col].max()
#                                     
#                                     # Calculate shaved monthly MD by simulating battery impact on entire month
#                                     # For simplification, assume the maximum shaving achieved in any event
#                                     # could be sustained, so shaved MD = original MD - max shaving achieved
#                                     max_shaving_achieved = month_events['Shaved_Power_kW'].max() if not month_events.empty else 0
#                                     
#                                     # More conservative approach: only count shaving if it was consistently successful
#                                     successful_events = month_events[month_events['Fully_Shaved'].str.contains('Yes', na=False)]
#                                     if not successful_events.empty:
#                                         # Use average successful shaving as sustainable shaving
#                                         sustainable_shaving_kw = successful_events['Shaved_Power_kW'].mean()
#                                     else:
#                                         # If no fully successful events, use partial shaving average
#                                         sustainable_shaving_kw = month_events['Shaved_Power_kW'].mean() if not month_events.empty else 0
#                                     
#                                     # Shaved MD = Original MD - sustainable shaving
#                                     shaved_md_kw = max(0, original_md_kw - sustainable_shaving_kw)
#                                     md_reduction_kw = original_md_kw - shaved_md_kw
#                                 else:
#                                     original_md_kw = 0
#                                     shaved_md_kw = 0
#                                     md_reduction_kw = 0
#                                 
#                                 # Monthly savings calculation
#                                 if selected_tariff and isinstance(selected_tariff, dict):
#                                     rates = selected_tariff.get('Rates', {})
#                                     md_rate_rm_per_kw = rates.get('Capacity Rate', 0) + rates.get('Network Rate', 0)
#                                     monthly_saving_rm = md_reduction_kw * md_rate_rm_per_kw
#                                 else:
#                                     monthly_saving_rm = 0
#                                 
#                                 # BESS utilization for the month
#                                 total_shaved_energy = month_events['Shaved_Energy_kWh'].sum()
#                                 num_events = len(month_events)
#                                 bess_utilization_pct = (total_shaved_energy / (usable_energy_kwh * num_events)) * 100 if num_events > 0 and usable_energy_kwh > 0 else 0
#                                 
#                                 monthly_savings.append({
#                                     'Month': str(month_period),
#                                     'Original_MD_kW': round(original_md_kw, 1),
#                                     'Shaved_MD_kW': round(shaved_md_kw, 1),
#                                     'MD_Reduction_kW': round(md_reduction_kw, 1),
#                                     'Monthly_Saving_RM': round(monthly_saving_rm, 2),
#                                     'BESS_Utilization_%': round(bess_utilization_pct, 1),
#                                     'Events_Count': num_events
#                                 })
#                             
#                             df_monthly_savings = pd.DataFrame(monthly_savings)
#                             total_annual_saving_rm = df_monthly_savings['Monthly_Saving_RM'].sum()
#                             avg_monthly_saving_rm = df_monthly_savings['Monthly_Saving_RM'].mean()
#                             avg_md_reduction_kw = df_monthly_savings['MD_Reduction_kW'].mean()
#                             
#                             # Display comprehensive results
#                             st.markdown("#### ðŸ“Š Dispatch Simulation Results")
#                             
#                             # Summary KPIs
#                             col1, col2, col3, col4 = st.columns(4)
#                             col1.metric("Total Events", len(dispatch_results))
#                             col2.metric("Success Rate", f"{len([r for r in dispatch_results if 'Yes' in r['Fully_Shaved']]) / len(dispatch_results) * 100:.1f}%")
#                             col3.metric("Avg MD Reduction", f"{avg_md_reduction_kw:.1f} kW")
#                             col4.metric("Annual Savings", f"RM {total_annual_saving_rm:,.0f}")
#                             
#                             # Enhanced dispatch results table with color coding
#                             def highlight_dispatch_performance(row):
#                                 colors = []
#                                 for col in row.index:
#                                     if col == 'Fully_Shaved':
#                                         if 'Yes' in str(row[col]):
#                                             colors.append('background-color: rgba(0, 255, 0, 0.2)')  # Green
#                                         else:
#                                             colors.append('background-color: rgba(255, 0, 0, 0.2)')  # Red
#                                     elif col == 'BESS_Utilization_%':
#                                         util = row[col] if isinstance(row[col], (int, float)) else 0
#                                         if util >= 80:
#                                             colors.append('background-color: rgba(0, 255, 0, 0.1)')  # Light green
#                                         elif util >= 50:
#                                             colors.append('background-color: rgba(255, 255, 0, 0.1)')  # Light yellow
#                                         else:
#                                             colors.append('background-color: rgba(255, 0, 0, 0.1)')  # Light red
#                                     elif col == 'Constraint_Type':
#                                         if 'Power' in str(row[col]):
#                                             colors.append('background-color: rgba(255, 165, 0, 0.2)')  # Orange
#                                         elif 'Energy' in str(row[col]):
#                                             colors.append('background-color: rgba(255, 255, 0, 0.2)')  # Yellow
#                                         else:
#                                             colors.append('')
#                                     else:
#                                         colors.append('')
#                                 return colors
#                             
#                             # Display dispatch results table
#                             styled_dispatch = df_dispatch.drop(['Month'], axis=1).style.apply(highlight_dispatch_performance, axis=1).format({
#                                 'Duration_Hours': '{:.2f}',
#                                 'Original_Peak_kW': '{:.1f}',
#                                 'Target_MD_kW': '{:.1f}',
#                                 'Excess_kW': '{:.1f}',
#                                 'Available_Energy_kWh': '{:.1f}',
#                                 'Power_Constraint_kW': '{:.1f}',
#                                 'Shaved_Power_kW': '{:.1f}',
#                                 'Shaved_Energy_kWh': '{:.2f}',
#                                 'Actual_Energy_Consumed_kWh': '{:.2f}',
#                                 'Deficit_kW': '{:.1f}',
#                                 'Final_Peak_kW': '{:.1f}',
#                                 'SOC_Before_%': '{:.1f}',
#                                 'SOC_After_%': '{:.1f}',
#                                 'SOC_Used_%': '{:.1f}',
#                                 'Monthly_Savings_RM': 'RM {:.2f}',
#                                 'BESS_Utilization_%': '{:.1f}%'
#                             })
#                             
#                             st.dataframe(styled_dispatch, use_container_width=True)
#                             
#                             # Explanations for the comprehensive table
#                             st.info("""
#                             **ðŸ“Š Comprehensive Dispatch Analysis Columns:**
#                             
#                             **Event Details:**
#                             - **Event_ID**: Unique identifier for each peak event
#                             - **Duration_Hours**: Event duration in hours
#                             - **Original_Peak_kW**: Peak demand without battery intervention
#                             - **Excess_kW**: Demand above target MD level
#                             
#                             **BESS Performance:**
#                             - **Available_Energy_kWh**: Usable battery energy (considering SOC, DoD, efficiency)
#                             - **Power_Constraint_kW**: Maximum power available (C-rate, energy, or demand limited)
#                             - **Shaved_Power_kW**: Actual power reduction achieved
#                             - **Shaved_Energy_kWh**: Total energy discharged during event
#                             - **Deficit_kW**: Remaining excess after battery intervention
#                             - **Final_Peak_kW**: Resulting peak demand after shaving
#                             
#                             **Battery State:**
#                             - **SOC_Before/After_%**: Battery state of charge before and after event
#                             - **SOC_Used_%**: Percentage of battery capacity utilized
#                             - **BESS_Utilization_%**: Energy efficiency (discharged/available ratio)
#                             
#                             **Economic Impact:**
#                             - **Monthly_Savings_RM**: Potential monthly savings from MD reduction
#                             - **Constraint_Type**: Limiting factor (Power/Energy/Demand limited)
#                             
#                             **ðŸŽ¨ Color Coding:**
#                             - ðŸŸ¢ **Green**: Successful shaving or high utilization (â‰¥80%)
#                             - ðŸŸ¡ **Yellow**: Moderate performance (50-79%) or energy-constrained
#                             - ðŸŸ  **Orange**: Power-constrained events
#                             - ðŸ”´ **Red**: Failed events or low utilization (<50%)
#                             """)
#                             
#                             # Monthly savings analysis
#                             st.markdown("#### 6.7.1 ðŸ’° Monthly Savings Analysis")
#                             
#                             # Display monthly savings table
#                             styled_monthly = df_monthly_savings.style.format({
#                                 'Original_MD_kW': '{:.1f}',
#                                 'Shaved_MD_kW': '{:.1f}',
#                                 'MD_Reduction_kW': '{:.1f}',
#                                 'Monthly_Saving_RM': '{:.2f}',
#                                 'BESS_Utilization_%': '{:.1f}'
#                             })
#                             
#                             st.dataframe(styled_monthly, use_container_width=True)
#                             
#                             # Annual summary
#                             st.success(f"""
#                             **ðŸ’° Annual Financial Summary:**
#                             - **Total Annual Savings**: RM {total_annual_saving_rm:,.0f}
#                             - **Average Monthly Savings**: RM {avg_monthly_saving_rm:,.0f}
#                             - **Average MD Reduction**: {avg_md_reduction_kw:.1f} kW
#                             - **ROI Analysis**: Based on {len(dispatch_results)} peak events across {len(df_monthly_savings)} months
#                             """)
#                             
#                             # Visualization - Monthly MD comparison
#                             fig_monthly = go.Figure()
#                             
#                             fig_monthly.add_trace(go.Scatter(
#                                 x=df_monthly_savings['Month'],
#                                 y=df_monthly_savings['Original_MD_kW'],
#                                 mode='lines+markers',
#                                 name='Original MD',
#                                 line=dict(color='red', width=2),
#                                 marker=dict(size=8)
#                             ))
#                             
#                             fig_monthly.add_trace(go.Scatter(
#                                 x=df_monthly_savings['Month'],
#                                 y=df_monthly_savings['Shaved_MD_kW'],
#                                 mode='lines+markers',
#                                 name='Battery-Assisted MD',
#                                 line=dict(color='green', width=2),
#                                 marker=dict(size=8)
#                             ))
#                             
#                             fig_monthly.update_layout(
#                                 title="Monthly Maximum Demand: Original vs Battery-Assisted",
#                                 xaxis_title="Month",
#                                 yaxis_title="Maximum Demand (kW)",
#                                 height=400,
#                                 showlegend=True,
#                                 plot_bgcolor='rgba(0,0,0,0)',
#                                 paper_bgcolor='rgba(0,0,0,0)'
#                             )
#                             
#                             st.plotly_chart(fig_monthly, use_container_width=True)
#                             
#                             # Monthly savings bar chart
#                             fig_savings = go.Figure(data=[
#                                 go.Bar(
#                                     x=df_monthly_savings['Month'],
#                                     y=df_monthly_savings['Monthly_Saving_RM'],
#                                     text=df_monthly_savings['Monthly_Saving_RM'].round(0),
#                                     textposition='auto',
#                                     marker_color='lightblue'
#                                 )
#                             ])
#                             
#                             fig_savings.update_layout(
#                                 title="Monthly Savings from MD Reduction",
#                                 xaxis_title="Month",
#                                 yaxis_title="Savings (RM)",
#                                 height=400,
#                                 plot_bgcolor='rgba(0,0,0,0)',
#                                 paper_bgcolor='rgba(0,0,0,0)'
#                             )
#                             
#                             st.plotly_chart(fig_savings, use_container_width=True)
#                             
#                         else:
#                             st.warning("No peak events found for dispatch simulation analysis.")
#                     
#                     
#                 except Exception as e:
#                     st.error(f"âŒ Error in BESS dispatch simulation: {str(e)}")
#                     with st.expander("Debug Details"):
#                         st.write(f"Error details: {str(e)}")
#                         st.write(f"Number of events: {len(all_monthly_events) if all_monthly_events else 0}")
#                         st.write(f"Selected battery: {selected_battery['label'] if selected_battery else 'None'}")
#                         st.write(f"Battery capacity: {total_battery_capacity if 'total_battery_capacity' in locals() else 'Unknown'} kWh")
#                         st.write(f"Battery power: {total_battery_power if 'total_battery_power' in locals() else 'Unknown'} kW")
#                         st.write(f"Optimal units: {optimal_units if 'optimal_units' in locals() else 'Unknown'}")
#                     
#                     # Fallback: Show basic configuration info
#                     st.warning("âš ï¸ Falling back to basic battery configuration display...")
#                     if 'selected_battery' in locals() and selected_battery:
#                         st.write(f"**Configured Battery System:**")
#                         st.write(f"- Battery: {selected_battery['label']}")
#                         st.write(f"- Units: {optimal_units if 'optimal_units' in locals() else 'Unknown'}")
#                         st.write(f"- Total Capacity: {total_battery_capacity if 'total_battery_capacity' in locals() else 'Unknown'} kWh")
#                         st.write(f"- Total Power: {total_battery_power if 'total_battery_power' in locals() else 'Unknown'} kW")
#             else:
#                 st.warning("âš ï¸ Prerequisites not met for battery simulation:")
#                 for msg in error_messages:
#                     st.warning(f"- {msg}")
#                     
#         else:
#             st.warning("âš ï¸ **No Battery Selected**: Please select a battery from the 'ðŸ“‹ Tabled Analysis' dropdown above to perform enhanced analysis.")
#             st.info("ðŸ’¡ Navigate to the top of this page and select a battery from the dropdown to see detailed battery analysis.")
# 
# 
# def _determine_constraint_type(excess_kw, max_power_kw, available_energy_kwh, duration_hours):
#     """Determine what constraint limits the battery dispatch."""
#     if duration_hours <= 0:
#         return "Invalid Duration"
#     
#     energy_limited_power = available_energy_kwh / duration_hours
#     
#     if excess_kw <= min(max_power_kw, energy_limited_power):
#         return "Demand Limited"
#     elif max_power_kw < energy_limited_power:
#         return "Power Limited"
#     else:
#         return "Energy Limited"
#         
#         # V2 Enhancement Preview
#         st.markdown("#### ðŸš€ V2 Monthly-Based Enhancements")
#         st.info(f"""
#         **ðŸ“ˆ Monthly-Based Features Implemented:**
#         - **âœ… Monthly Target Calculation**: Each month uses {target_description} target
#         - **âœ… Stepped Target Profile**: Sawtooth target line that changes at month boundaries
#         - **âœ… Month-Specific Event Detection**: Peak events detected using appropriate monthly targets
#         - **âœ… Monthly Breakdown Table**: Detailed monthly analysis with individual targets and shaving amounts
#         
#         **ðŸ”„ Advanced Features Coming Soon:**
#         - **Interactive Monthly Thresholds**: Adjust shaving percentage per month individually
#         - **Seasonal Optimization**: Different strategies for high/low demand seasons
#         - **Monthly ROI Analysis**: Cost-benefit analysis per billing period
#         - **Cross-Month Battery Optimization**: Optimize battery usage across multiple months
#         """)
# 
# 
# def render_battery_impact_visualization():
#     """Render the Battery Impact Analysis section as a separate component."""
#     # Only render if we have the necessary data in session state
#     if (hasattr(st.session_state, 'processed_df') and 
#         st.session_state.processed_df is not None and 
#         hasattr(st.session_state, 'power_column') and 
#         st.session_state.power_column and
#         hasattr(st.session_state, 'selected_tariff')):
#         
#         # Get data from session state
#         df = st.session_state.processed_df
#         power_col = st.session_state.power_column
#         selected_tariff = st.session_state.selected_tariff
#         holidays = getattr(st.session_state, 'holidays', [])
#         target_method = getattr(st.session_state, 'target_method', 'percentage')
#         shave_percent = getattr(st.session_state, 'shave_percent', 10)
#         target_percent = getattr(st.session_state, 'target_percent', 85)
#         target_manual_kw = getattr(st.session_state, 'target_manual_kw', 100)
#         target_description = getattr(st.session_state, 'target_description', 'percentage-based')
#         
#         st.markdown("---")  # Separator
#         st.markdown("### ðŸ”‹ Battery Impact Analysis")
#         st.info("Configure battery specifications and visualize their impact on energy consumption patterns:")
#         
#         # Get battery configuration from the widget
#         battery_config = _render_v2_battery_controls()
#         
#         # Render impact visualization if analysis is enabled and we have data context
#         if (battery_config and battery_config.get('run_analysis') and 
#             battery_config.get('selected_capacity', 0) > 0):
#             
#             st.markdown("---")  # Separator between config and visualization
#             st.markdown("#### ðŸ“ˆ Battery Impact Visualization")
#             st.info(f"Impact analysis for {battery_config['selected_capacity']} kWh battery:")
#             
#             # Render the actual battery impact timeline
#             _render_battery_impact_timeline(
#                 df, 
#                 power_col, 
#                 selected_tariff, 
#                 holidays,
#                 target_method, 
#                 shave_percent,
#                 target_percent,
#                 target_manual_kw,
#                 target_description,
#                 battery_config['selected_capacity']
#             )
#     else:
#         st.info("ðŸ’¡ **Upload data in the MD Shaving (v2) section above to see battery impact visualization.**")
# 
# 
# # Main function for compatibility
# def show():
#     """Compatibility function that calls the main render function."""
#     render_md_shaving_v2()
# 
# 
# # ===================================================================================================
# # TOU PERFORMANCE DISPLAY FUNCTIONS
# # ===================================================================================================
# 
# def _display_tou_performance_summary(results, selected_tariff=None):
#     """
#     Display TOU-specific performance metrics and readiness analysis.
#     
#     Args:
#         results: Dictionary from battery simulation results
#         selected_tariff: Selected tariff configuration
#     """
#     if not results.get('is_tou_tariff', False):
#         return
#     
#     st.markdown("---")
#     st.subheader("ðŸ”‹ TOU Tariff Performance Summary")
#     st.caption("TOU-specific charging strategy and 95% SOC readiness analysis")
#     
#     tou_stats = results.get('tou_readiness_stats', {})
#     
#     if tou_stats:
#         # TOU Readiness Metrics
#         col1, col2, col3, col4 = st.columns(4)
#         
#         col1.metric(
#             "TOU Readiness Rate", 
#             f"{tou_stats.get('readiness_rate_percent', 0):.1f}%",
#             delta=f"{tou_stats.get('ready_days', 0)}/{tou_stats.get('total_weekdays', 0)} days"
#         )
#         
#         col2.metric(
#             "Avg SOC at 2 PM", 
#             f"{tou_stats.get('avg_soc_at_2pm', 0):.1f}%",
#             delta=f"{tou_stats.get('avg_soc_at_2pm', 95) - 95:+.1f}% vs target"
#         )
#         
#         col3.metric(
#             "Min SOC at 2 PM", 
#             f"{tou_stats.get('min_soc_at_2pm', 0):.1f}%",
#             delta=f"{tou_stats.get('min_soc_at_2pm', 95) - 95:+.1f}% vs target"
#         )
#         
#         col4.metric(
#             "SOC Target", 
#             f"{tou_stats.get('target_soc', 95):.0f}%",
#             delta="MD Readiness"
#         )
#         
#         # Performance classification
#         readiness_rate = tou_stats.get('readiness_rate_percent', 0)
#         if readiness_rate >= 95:
#             st.success(f"âœ… **Excellent TOU Performance**: {readiness_rate:.1f}% days meet 95% SOC target by 2 PM")
#         elif readiness_rate >= 85:
#             st.success(f"âœ… **Good TOOU Performance**: {readiness_rate:.1f}% days meet 95% SOC target by 2 PM")
#         elif readiness_rate >= 70:
#             st.warning(f"âš ï¸ **Moderate TOU Performance**: {readiness_rate:.1f}% days meet 95% SOC target by 2 PM")
#         else:
#             st.error(f"ðŸš¨ **Poor TOU Performance**: {readiness_rate:.1f}% days meet 95% SOC target by 2 PM - Consider larger battery capacity")
#         
#         # Additional insights
#         if tou_stats.get('min_soc_at_2pm', 100) < 80:
#             st.warning(f"âš ï¸ **Risk Alert**: Minimum 2 PM SOC was {tou_stats.get('min_soc_at_2pm', 0):.1f}% - Potential inadequate MD preparation on some days")
#         
#     else:
#         st.warning("âš ï¸ No TOU readiness data available - Check if weekday 2 PM data exists")
#     
#     # TOU Strategy Summary
#     with st.expander("ðŸ“‹ TOU Charging Strategy Details"):
#         st.markdown("""
#         **TOU Charging Windows:**
#         - **Primary Charging**: 10 PM - 2 PM next day (overnight)
#         - **Target**: 95% SOC by 2 PM on weekdays
#         - **MD Window**: 2 PM - 10 PM weekdays (discharge period)
#         
#         **Charging Urgency Levels:**
#         - **ðŸš¨ CRITICAL**: < 4 hours to MD window, aggressive charging up to max power
#         - **âš¡ HIGH**: 4-8 hours to MD window, enhanced charging rates
#         - **ðŸ”‹ NORMAL**: > 8 hours to MD window, standard overnight charging
#         
#         **Benefits:**
#         - Ensures battery readiness for peak demand shaving
#         - Optimizes charging during off-peak periods
#         - Reduces risk of inadequate SOC during critical MD periods
#         """)
# 
# def _display_tou_vs_general_comparison(results, selected_tariff=None):
#     """
#     Display comparison between TOU and General tariff performance.
#     
#     Args:
#         results: Dictionary from battery simulation results
#         selected_tariff: Selected tariff configuration
#     """
#     if not results.get('is_tou_tariff', False):
#         st.info("""
#         ðŸ’¡ **General Tariff Detected**: This analysis uses standard 24/7 MD recording logic.
#         
#         **To enable TOU-specific features:**
#         - Select a TOU tariff (e.g., "Medium Voltage TOU")
#         - Experience enhanced charging strategy with 95% SOC readiness
#         - Get TOU-specific performance metrics and insights
#         """)
#         return
#     
#     st.markdown("---")
#     st.subheader("ðŸ“Š TOU vs General Tariff Comparison")
#     st.caption("How TOU tariff strategy differs from General tariff approach")
#     
#     comparison_data = [
#         {
#             "Aspect": "MD Recording Window",
#             "General Tariff": "24/7 (Continuous)",
#             "TOU Tariff": "2 PM - 10 PM (Weekdays only)",
#             "TOU Advantage": "More focused discharge strategy"
#         },
#         {
#             "Aspect": "Charging Strategy",
#             "General Tariff": "95% SOC target (Standardized)",
#             "TOU Tariff": "95% SOC target (Standardized)",
#             "TOU Advantage": "Same target, but enhanced charging urgency logic"
#         },
#         {
#             "Aspect": "Charging Windows",
#             "General Tariff": "Based on SOC + demand thresholds",
#             "TOU Tariff": "10 PM - 2 PM (Optimized for MD readiness)",
#             "TOU Advantage": "Predictable overnight charging"
#         },
#         {
#             "Aspect": "Performance Monitoring",
#             "General Tariff": "Standard shaving metrics",
#             "TOU Tariff": "TOU readiness + standard metrics",
#             "TOU Advantage": "Additional 2 PM readiness validation"
#         }
#     ]
#     
#     import pandas as pd
#     df_comparison = pd.DataFrame(comparison_data)
#     
#     st.dataframe(
#         df_comparison.style.apply(
#             lambda x: ['background-color: rgba(78, 205, 196, 0.1)' for _ in x], axis=0
#         ),
#         use_container_width=True,
#         hide_index=True
#     )
# 
# 
# # Complex daily proactive charging function removed - replaced with simple SOC-based charging in main algorithm
# 
# 
# def is_md_window(timestamp, holidays=None):
#     """
#     RP4 MD Window Classification Alias
#     
#     Thin alias for is_peak_rp4() that indicates when Maximum Demand (MD) is recorded
#     under the RP4 2-period tariff system (peak/off-peak only).
#     
#     Unit Labels & MD Recording Logic:
#     - TOU Tariff: MD recorded only during 14:00-22:00 weekdays (excluding holidays)
#     - General Tariff: MD recorded 24/7 (all periods are MD windows)
#     
#     This replaces the old 3-period system that included "Shoulder" periods.
#     All tariff logic now uses the simplified RP4 2-period classification.
#     
#     Args:
#         timestamp: Datetime to classify
#         holidays: Set of holiday dates (auto-detected if None)
#         
#     Returns:
#         bool: True if timestamp is within MD recording window (peak period)
#     """
#     return is_peak_rp4(timestamp, holidays)
if __name__ == "__main__":
    # For testing purposes
    render_md_shaving_v2()
# 
# def cluster_peak_events(events_df, battery_params, md_hours, working_days):
#     """
#     Mock clustering function for peak events analysis.
#     
#     Args:
#         events_df: DataFrame with peak events data
#         battery_params: Dictionary with battery parameters
#         md_hours: Tuple of (start_hour, end_hour) for MD period
#         working_days: List of working days
#         
#     Returns:
#         tuple: (clusters_df, events_for_clustering)
#     """
#     if events_df.empty:
#         return pd.DataFrame(), events_df
#     
#     # Create a simple clustering based on date grouping
#     events_for_clustering = events_df.copy()
#     
#     # Add cluster_id based on date
#     events_for_clustering['cluster_id'] = events_for_clustering.index.date.astype(str)
#     
#     # Create clusters summary
#     clusters_data = []
#     for cluster_id, group in events_for_clustering.groupby('cluster_id'):
#         clusters_data.append({
#             'cluster_id': cluster_id,
#             'num_events_in_cluster': len(group),
#             'cluster_duration_hr': len(group) * 0.5 if len(group) > 1 else 0,  # Multi-event clusters
#             'peak_abs_kw_in_cluster': group.get('General Peak Load (kW)', pd.Series([0])).max(),
#             'peak_abs_kw_sum_in_cluster': group.get('General Peak Load (kW)', pd.Series([0])).sum(),
#             'total_energy_above_threshold_kwh': group.get('General Required Energy (kWh)', pd.Series([0])).sum(),
#             'cluster_start': group.index[0] if len(group) > 0 else None,
#             'cluster_end': group.index[-1] if len(group) > 0 else None
#         })
#     
#     clusters_df = pd.DataFrame(clusters_data)
#     
#     return clusters_df, events_for_clustering
# 
# 
# def _compute_per_event_bess_dispatch(all_monthly_events, monthly_targets, selected_tariff, holidays, battery_spec=None, quantity=1, interval_hours=None):
#     """
#     Compute per-event BESS dispatch results using existing V2 logic.
#     
#     Args:
#         all_monthly_events: List of peak events from peak events detection
#         monthly_targets: Series of monthly targets from _calculate_monthly_targets_v2
#         selected_tariff: Selected tariff configuration
#         holidays: Set of holiday dates
#         battery_spec: Battery specifications dict
#         quantity: Number of battery units
#         interval_hours: Data sampling interval in hours
#         
#     Returns:
#         pd.DataFrame: Event results table with all required columns
#     """
#     if not all_monthly_events or not battery_spec:
#         return pd.DataFrame()
#     
#     # Add dynamic interval detection if not provided
#     if interval_hours is None:
#         interval_hours = _get_dynamic_interval_hours(pd.DataFrame(index=pd.to_datetime(['2024-01-01'])))
#     
#     # Determine tariff type using existing logic
#     tariff_type = 'General'
#     if selected_tariff:
#         tariff_name = selected_tariff.get('Tariff', '').lower()
#         tariff_type_field = selected_tariff.get('Type', '').lower()
#         if 'tou' in tariff_name or 'tou' in tariff_type_field or tariff_type_field == 'tou':
#             tariff_type = 'TOU'
#     
#     # Get MD rate from tariff
#     md_rate_rm_per_kw = 0
#     if selected_tariff and isinstance(selected_tariff, dict):
#         rates = selected_tariff.get('Rates', {})
#         md_rate_rm_per_kw = rates.get('Capacity Rate', 0) + rates.get('Network Rate', 0)
#     
#     # Battery system parameters (updated to standardized 95%/5% SOC limits)
#     rated_power_kw = battery_spec.get('power_kW', 0) * quantity
#     capacity_kwh = battery_spec.get('energy_kWh', 0) * quantity
#     soc_min_percent = 5.0   # Standardized 5% minimum safety SOC
#     soc_max_percent = 95.0  # Standardized 95% maximum SOC
#     ready_soc_percent = 80.0  # Starting SOC (within 5%-95% range)
#     eta_charge = 0.95  # Charging efficiency
#     eta_discharge = 0.95  # Discharging efficiency
#     round_trip_efficiency = eta_charge * eta_discharge
#     max_charge_kw = rated_power_kw  # Assume same as discharge
#     max_discharge_kw = rated_power_kw
#     
#     # Event processing
#     event_results = []
#     current_soc_percent = ready_soc_percent
#     cluster_id = 1  # Simple cluster assignment
#     previous_event_end = None
#     
#     for i, event in enumerate(all_monthly_events):
#         try:
#             # Basic event info
#             event_id = f"E{i+1:03d}"
#             start_date = event.get('Start Date')
#             end_date = event.get('End Date')
#             start_time = event.get('Start Time', '00:00')
#             end_time = event.get('End Time', '00:00')
#             
#             # Parse timestamps
#             start_timestamp = pd.to_datetime(f"{start_date} {start_time}")
#             end_timestamp = pd.to_datetime(f"{end_date} {end_time}")
#             duration_min = (end_timestamp - start_timestamp).total_seconds() / 60
#             duration_h = duration_min / 60
#             
#             # Monthly context
#             month = start_timestamp.to_period('M')
#             month_str = month.strftime('%Y-%m')
#             
#             # Get monthly target for this event
#             target_md_kw = monthly_targets.get(month, 0) if month in monthly_targets.index else 0
#             
#             # Event power characteristics
#             original_peak_kw = event.get('General Peak Load (kW)', 0)
#             excess_above_target_kw = max(0, original_peak_kw - target_md_kw)
#             
#             # TOU period determination using existing logic
#             tou_period = True  # Default for General tariff
#             md_window = "24/7"  # Default for General
#             
#             if tariff_type == 'TOU':
#                 # Use existing is_peak_rp4 function for TOU detection
#                 tou_period = is_peak_rp4(start_timestamp, holidays if holidays else set())
#                 md_window = "2PM-10PM" if tou_period else "Off-Peak"
#             
#             # Holiday check
#             is_holiday = start_timestamp.date() in (holidays if holidays else set())
#             
#             # BESS state before event
#             soc_before_percent = current_soc_percent
#             available_energy_kwh = capacity_kwh * (soc_before_percent/100 - soc_min_percent/100)
#             available_energy_kwh = max(0, available_energy_kwh)
#             
#             # Maximum energy that can be discharged during this event
#             power_limited_energy = rated_power_kw * duration_h
#             energy_limited_energy = available_energy_kwh * eta_discharge
#             max_event_discharge_kwh = min(power_limited_energy, energy_limited_energy)
#             
#             # Dispatch calculation
#             if excess_above_target_kw > 0 and tou_period:
#                 # Power shaving calculation
#                 power_shaved_kw = min(excess_above_target_kw, rated_power_kw)
#                 
#                 # Energy constraint check
#                 required_energy_kwh = power_shaved_kw * duration_h / eta_discharge
#                 if required_energy_kwh > available_energy_kwh:
#                     # Energy limited
#                     actual_energy_discharged = available_energy_kwh * eta_discharge
#                     power_shaved_kw = actual_energy_discharged / duration_h
#                     constraint_type = "Energy-limited"
#                     reason_detail = f"Required {required_energy_kwh:.1f}kWh > available {available_energy_kwh:.1f}kWh"
#                 else:
#                     # Power limited or successful
#                     actual_energy_discharged = required_energy_kwh
#                     if power_shaved_kw >= excess_above_target_kw:
#                         constraint_type = "None"
#                         reason_detail = f"Successfully shaved {power_shaved_kw:.1f}kW"
#                     else:
#                         constraint_type = "Power-limited"
#                         reason_detail = f"Required {excess_above_target_kw:.1f}kW > rated {rated_power_kw:.1f}kW"
#                 
#                 energy_discharged_kwh = actual_energy_discharged
#                 
#             elif not tou_period and tariff_type == 'TOU':
#                 # Outside MD window for TOU tariff
#                 power_shaved_kw = 0
#                 energy_discharged_kwh = 0
#                 constraint_type = "Not-in-MD-window"
#                 reason_detail = f"Event outside MD window ({md_window})"
#                 
#             else:
#                 # No excess or no shaving needed
#                 power_shaved_kw = 0
#                 energy_discharged_kwh = 0
#                 constraint_type = "None"
#                 reason_detail = "No excess above target"
#             
#             # Post-event calculations
#             final_peak_after_bess_kw = original_peak_kw - power_shaved_kw
#             residual_above_target_kw = max(0, final_peak_after_bess_kw - target_md_kw)
#             
#             # SOC after event
#             soc_used_kwh = energy_discharged_kwh / eta_discharge
#             soc_used_percent = (soc_used_kwh / capacity_kwh) * 100 if capacity_kwh > 0 else 0
#             soc_after_percent = max(soc_min_percent, soc_before_percent - soc_used_percent)
#             current_soc_percent = soc_after_percent
#             
#             # Shaving success classification - FIXED LOGIC
#             if not tou_period and tariff_type == 'TOU':
#                 # Events outside MD window should not be classified as failures
#                 shaving_success = "âšª Not Applicable"
#             elif excess_above_target_kw <= 0.1:
#                 # No excess to shave
#                 shaving_success = "âœ… Complete"
#             elif residual_above_target_kw <= 0.1:
#                 # Successfully reduced residual to near zero
#                 shaving_success = "âœ… Complete"
#             elif power_shaved_kw > 0:
#                 # Some shaving achieved but not complete
#                 shaving_success = "ðŸŸ¡ Partial"
#             else:
#                 # Should have shaved (during MD window with excess) but couldn't
#                 shaving_success = "ðŸ”´ Failed"
#             
#             # Recharge analysis for next event
#             recharge_window_min = 0
#             recharge_required_kwh = 0
#             recharge_possible_kwh = 0
#             recharge_feasible = True
#             
#             if i < len(all_monthly_events) - 1:
#                 next_event = all_monthly_events[i + 1]
#                 next_start = pd.to_datetime(f"{next_event.get('Start Date')} {next_event.get('Start Time', '00:00')}")
#                 recharge_window_min = (next_start - end_timestamp).total_seconds() / 60
#                 
#                 # Required recharge to reach ready SOC
#                 target_soc_increase = ready_soc_percent - soc_after_percent
#                 recharge_required_kwh = (target_soc_increase / 100) * capacity_kwh
#                 
#                 # Possible recharge given time window
#                 recharge_time_h = recharge_window_min / 60
#                 max_recharge_energy = max_charge_kw * recharge_time_h * eta_charge
#                 recharge_possible_kwh = min(max_recharge_energy, recharge_required_kwh)
#                 
#                 recharge_feasible = recharge_possible_kwh >= recharge_required_kwh
#                 
#                 # Update SOC for next event if recharge is possible
#                 if recharge_feasible:
#                     current_soc_percent = ready_soc_percent
#                 else:
#                     # Partial recharge
#                     soc_increase = (recharge_possible_kwh / capacity_kwh) * 100
#                     current_soc_percent = min(soc_max_percent, soc_after_percent + soc_increase)
#             
#             # MD savings calculation (only for events in MD window)
#             md_savings_rm = 0
#             if tou_period or tariff_type == 'General':
#                 # Use monthly attribution approach from existing logic
#                 attribution_factor = 1.0  # Simplified attribution
#                 md_savings_rm = power_shaved_kw * md_rate_rm_per_kw * attribution_factor
#             
#             # Append event result
#             event_results.append({
#                 'event_id': event_id,
#                 'month': month_str,
#                 'start_time': start_timestamp.strftime('%Y-%m-%d %H:%M'),
#                 'end_time': end_timestamp.strftime('%Y-%m-%d %H:%M'),
#                 'duration_min': round(duration_min, 1),
#                 'original_peak_kw': round(original_peak_kw, 1),
#                 'target_md_kw': round(target_md_kw, 1),
#                 'excess_above_target_kw': round(excess_above_target_kw, 1),
#                 'tou_period': 'âœ…' if tou_period else 'âŒ',
#                 'cluster_id': cluster_id,
#                 'rated_power_kw': round(rated_power_kw, 1),
#                 'capacity_kwh': round(capacity_kwh, 1),
#                 'soc_before_%': round(soc_before_percent, 1),
#                 'available_energy_kwh': round(available_energy_kwh, 1),
#                 'max_event_discharge_kwh': round(max_event_discharge_kwh, 1),
#                 'power_shaved_kw': round(power_shaved_kw, 1),
#                 'energy_discharged_kwh': round(energy_discharged_kwh, 1),
#                 'final_peak_after_bess_kw': round(final_peak_after_bess_kw, 1),
#                 'residual_above_target_kw': round(residual_above_target_kw, 1),
#                 'soc_after_%': round(soc_after_percent, 1),
#                 'shaving_success': shaving_success,
#                 'constraint_type': constraint_type,
#                 'reason_detail': reason_detail,
#                 'rte_%': round(round_trip_efficiency * 100, 1),
#                 'md_window': md_window,
#                 'recharge_window_min': round(recharge_window_min, 1),
#                 'recharge_required_kwh': round(recharge_required_kwh, 1),
#                 'recharge_possible_kwh': round(recharge_possible_kwh, 1),
#                 'recharge_feasible': 'âœ…' if recharge_feasible else 'âŒ',
#                 'md_savings_rm': round(md_savings_rm, 2),
#                 'holiday': 'âœ…' if is_holiday else 'âŒ',
#                 'data_gaps': 'âŒ',  # Simplified
#                 'notes': f"{tariff_type} tariff, {constraint_type.lower()} dispatch"
#             })
#             
#             # Simple cluster ID increment (simplified clustering)
#             if recharge_window_min < 120:  # Less than 2 hours gap
#                 cluster_id += 0  # Keep same cluster
#             else:
#                 cluster_id += 1  # New cluster
#                 
#             previous_event_end = end_timestamp
#             
#         except Exception as e:
#             st.warning(f"Error processing event {i+1}: {str(e)}")
#             continue
#     
#     # Create DataFrame
#     df_results = pd.DataFrame(event_results)
#     
#     return df_results
# 
# 
# def _render_event_results_table(all_monthly_events, monthly_targets, selected_tariff, holidays):
#     """
#     Render the MD Shaving - Event Results (All Events) table.
#     
#     Args:
#         all_monthly_events: List of peak events from peak events detection
#         monthly_targets: Series of monthly targets
#         selected_tariff: Selected tariff configuration  
#         holidays: Set of holiday dates
#     """
#     
#     st.markdown("#### 7.1.5 ðŸ“Š MD Shaving â€“ Event Results (All Events)")
#     
#     # Check if battery is selected
#     if not (hasattr(st.session_state, 'tabled_analysis_selected_battery') and st.session_state.tabled_analysis_selected_battery):
#         st.warning("âš ï¸ **No Battery Selected**: Please select a battery from the 'ðŸ“‹ Tabled Analysis' dropdown above to view event-level dispatch results.")
#         return
#     
#     # Get battery configuration
#     selected_battery = st.session_state.tabled_analysis_selected_battery
#     battery_spec = selected_battery['spec']
#     quantity = getattr(st.session_state, 'tabled_analysis_battery_quantity', 1)
#     
#     if not all_monthly_events:
#         st.info("No peak events available for analysis.")
#         return
#     
#     # Validation checks
#     validation_warnings = []
#     
#     # Check if monthly targets are available
#     if monthly_targets.empty:
#         validation_warnings.append("Monthly targets are missing - some calculations may be inaccurate")
#     
#     # Check for missing tariff configuration
#     if not selected_tariff:
#         validation_warnings.append("Tariff configuration missing - using default General tariff assumptions")
#     
#     if validation_warnings:
#         for warning in validation_warnings:
#             st.warning(f"âš ï¸ {warning}")
#     
#     # Compute event results
#     with st.spinner("Computing per-event BESS dispatch results..."):
#         # Get dynamic interval hours for accurate energy calculations
#         interval_hours = _get_dynamic_interval_hours(pd.DataFrame(index=pd.to_datetime(['2024-01-01'])))
#         
#         df_results = _compute_per_event_bess_dispatch(
#             all_monthly_events, monthly_targets, selected_tariff, holidays, 
#             battery_spec, quantity, interval_hours
#         )
#     
#     if df_results.empty:
#         st.error("âŒ Failed to compute event results")
#         return
#     
#     # Display summary metrics - Updated to handle "Not Applicable" events
#     col1, col2, col3, col4 = st.columns(4)
#     
#     total_events = len(df_results)
#     not_applicable_events = len(df_results[df_results['shaving_success'] == 'âšª Not Applicable'])
#     applicable_events = df_results[df_results['shaving_success'] != 'âšª Not Applicable']
#     total_applicable = len(applicable_events)
#     
#     if total_applicable > 0:
#         complete_events = len(applicable_events[applicable_events['shaving_success'] == 'âœ… Complete'])
#         partial_events = len(applicable_events[applicable_events['shaving_success'] == 'ðŸŸ¡ Partial'])
#         failed_events = len(applicable_events[applicable_events['shaving_success'] == 'ðŸ”´ Failed'])
#         
#         col1.metric("Total Events", f"{total_events} ({total_applicable} applicable)")
#         col2.metric("Complete Shaving", f"{complete_events} ({complete_events/total_applicable*100:.1f}%)")
#         col3.metric("Partial Shaving", f"{partial_events} ({partial_events/total_applicable*100:.1f}%)")
#         col4.metric("Failed Shaving", f"{failed_events} ({failed_events/total_applicable*100:.1f}%)")
#         
#         if not_applicable_events > 0:
#             st.info(f"â„¹ï¸ **{not_applicable_events} events outside MD window** (not counted in success rates)")
#     else:
#         col1.metric("Total Events", total_events)
#         col2.metric("All Off-Peak Events", f"{not_applicable_events} events")
#         col3.metric("No MD Window Events", "Success rate: N/A")
#         col4.metric("", "")
#         
#         st.warning("âš ï¸ All events are outside MD billing window - no applicable shaving opportunities")
#     
#     # Additional summary metrics
#     col1, col2, col3, col4 = st.columns(4)
#     
#     avg_power_shaved = df_results['power_shaved_kw'].mean()
#     total_energy_discharged = df_results['energy_discharged_kwh'].sum()
#     recharge_feasible_count = len(df_results[df_results['recharge_feasible'] == 'âœ…'])
#     total_md_savings = df_results['md_savings_rm'].sum()
#     
#     col1.metric("Avg Power Shaved", f"{avg_power_shaved:.1f} kW")
#     col2.metric("Total Energy Discharged", f"{total_energy_discharged:.1f} kWh")  
#     col3.metric("Recharge Feasible Rate", f"{recharge_feasible_count/total_events*100:.1f}%")
#     col4.metric("Total MD Savings", f"RM {total_md_savings:.2f}")
#     
#     # Filters
#     st.markdown("**ðŸ” Table Filters:**")
#     filter_col1, filter_col2, filter_col3 = st.columns(3)
#     
#     with filter_col1:
#         show_residual_only = st.checkbox("Show only events with residual > 0", False)
#         
#     with filter_col2:
#         constraint_filter = st.multiselect(
#             "Filter by constraint type:",
#             options=['Power-limited', 'Energy-limited', 'Recharge-limited', 'Not-in-MD-window', 'None'],
#             default=[]
#         )
#         
#     with filter_col3:
#         tou_only = st.checkbox("Show TOU period events only", False)
#     
#     # Month filter
#     available_months = sorted(df_results['month'].unique())
#     selected_months = st.multiselect(
#         "Filter by month:",
#         options=available_months,
#         default=available_months
#     )
#     
#     # Apply filters
#     df_filtered = df_results.copy()
#     
#     if show_residual_only:
#         df_filtered = df_filtered[df_filtered['residual_above_target_kw'] > 0]
#     
#     if constraint_filter:
#         df_filtered = df_filtered[df_filtered['constraint_type'].isin(constraint_filter)]
#     
#     if tou_only:
#         df_filtered = df_filtered[df_filtered['tou_period'] == 'âœ…']
#     
#     if selected_months:
#         df_filtered = df_filtered[df_filtered['month'].isin(selected_months)]
#     
#     st.markdown(f"**Showing {len(df_filtered)} of {len(df_results)} events**")
#     
#     # Style the dataframe with color coding
#     def highlight_success(row):
#         colors = []
#         for col in df_filtered.columns:
#             if col == 'shaving_success':
#                 if 'âœ… Complete' in str(row[col]):
#                     colors.append('background-color: rgba(0, 255, 0, 0.2)')  # Green
#                 elif 'ðŸŸ¡ Partial' in str(row[col]):
#                     colors.append('background-color: rgba(255, 255, 0, 0.2)')  # Yellow
#                 elif 'ðŸ”´ Failed' in str(row[col]):
#                     colors.append('background-color: rgba(255, 0, 0, 0.2)')  # Red
#                 else:
#                     colors.append('')
#             elif col == 'recharge_feasible' and 'âŒ' in str(row[col]):
#                 colors.append('background-color: rgba(255, 165, 0, 0.1)')  # Orange for recharge issues
#             else:
#                 colors.append('')
#         return colors
#     
#     # Display the table
#     if not df_filtered.empty:
#         styled_df = df_filtered.style.apply(highlight_success, axis=1)
#         st.dataframe(styled_df, use_container_width=True, hide_index=True)
#         
#         # Download options
#         st.markdown("**ðŸ“¥ Download Options:**")
#         
#         col1, col2 = st.columns(2)
#         
#         with col1:
#             # CSV download for filtered data
#             csv_buffer = io.StringIO()
#             df_filtered.to_csv(csv_buffer, index=False)
#             st.download_button(
#                 label="ðŸ“Š Download Filtered Results (CSV)",
#                 data=csv_buffer.getvalue(),
#                 file_name=f"event_results_filtered_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
#                 mime="text/csv"
#             )
#             
#         with col2:
#             # CSV download for full dataset
#             csv_buffer_full = io.StringIO()
#             df_results.to_csv(csv_buffer_full, index=False)
#             st.download_button(
#                 label="ðŸ“Š Download Full Dataset (CSV)",
#                 data=csv_buffer_full.getvalue(),
#                 file_name=f"event_results_full_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
#                 mime="text/csv"
#             )
#     
#     else:
#         st.info("No events match the current filter criteria.")
#     
#     # Footer summary for filtered results
#     if not df_filtered.empty:
#         st.markdown("---")
#         st.markdown("**ðŸ“Š Filtered Results Summary:**")
#         
#         filtered_complete = len(df_filtered[df_filtered['shaving_success'] == 'âœ… Complete'])
#         filtered_partial = len(df_filtered[df_filtered['shaving_success'] == 'ðŸŸ¡ Partial'])
#         filtered_failed = len(df_filtered[df_filtered['shaving_success'] == 'ðŸ”´ Failed'])
#         filtered_avg_power = df_filtered['power_shaved_kw'].mean()
#         filtered_total_energy = df_filtered['energy_discharged_kwh'].sum()
#         filtered_recharge_rate = len(df_filtered[df_filtered['recharge_feasible'] == 'âœ…']) / len(df_filtered) * 100
#         filtered_md_savings = df_filtered['md_savings_rm'].sum()
#         
#         summary_col1, summary_col2 = st.columns(2)
#         
#         with summary_col1:
#             st.markdown(f"""
#             - **Events**: {len(df_filtered)} total
#             - **Success Rate**: {filtered_complete}/{len(df_filtered)} complete ({filtered_complete/len(df_filtered)*100:.1f}%)
#             - **Partial**: {filtered_partial} events ({filtered_partial/len(df_filtered)*100:.1f}%)
#             - **Failed**: {filtered_failed} events ({filtered_failed/len(df_filtered)*100:.1f}%)
#             """)
#             
#         with summary_col2:
#             st.markdown(f"""
#             - **Avg Power Shaved**: {filtered_avg_power:.1f} kW
#             - **Total Energy Discharged**: {filtered_total_energy:.1f} kWh
#             - **Recharge Feasible**: {filtered_recharge_rate:.1f}%
#             - **Total MD Savings**: RM {filtered_md_savings:.2f}
#             """)
#     
#     # Technical notes
#     with st.expander("â„¹ï¸ Technical Notes & Methodology"):
#         st.markdown("""
#         **Calculation Methodology:**
#         
#         **Tariff-Aware Processing:**
#         - **General Tariff**: All events are eligible for MD savings (24/7 MD billing)
#         - **TOU Tariff**: Only events during 2PM-10PM weekdays are eligible for MD savings
#         
#         **BESS Dispatch Logic:**
#         1. **Power Constraint**: `power_shaved_kw = min(excess_above_target_kw, rated_power_kw)`
#         2. **Energy Constraint**: Verify sufficient battery energy considering efficiency losses
#         3. **SOC Constraints**: Maintain SOC between configured min/max limits
#         4. **Recharge Analysis**: Evaluate time window and power availability for recharging
#         
#         **Success Classification:**
#         - âšª **Not Applicable**: Events outside MD billing window (TOU tariff off-peak periods)
#         - âœ… **Complete**: Successfully reduced demand to target level (residual â‰¤ 0.1 kW)
#         - ðŸŸ¡ **Partial**: Some power shaved but did not fully meet target (residual > 0.1 kW)  
#         - ðŸ”´ **Failed**: No power shaved despite being in MD window with excess demand
#         
#         **MD Savings Attribution:**
#         - Uses monthly maximum attribution methodology
#         - Only credits events within MD billing windows
#         - Applies configured MD rates from selected tariff
#         
#         **Validation Checks:**
#         - Energy accounting: Î”SOC Ã— capacity â‰ˆ discharged_energy / Î·_discharge
#         - TOU off-window events: Verified md_savings_rm = 0
#         - Recharge feasibility: Time window vs charging power limits
#         """)
# 
# 
# def _display_v2_battery_simulation_chart(df_sim, monthly_targets=None, sizing=None, selected_tariff=None, holidays=None):
#     """
#     V2-specific battery operation simulation chart with DYNAMIC monthly targets.
#     
#     Key V2 Enhancement: Replaces static target line with stepped monthly target line.
#     
#     Args:
#         df_sim: Simulation dataframe with battery operation data
#         monthly_targets: V2's dynamic monthly targets (Series with Period index)
#         sizing: Battery sizing dictionary from V2 analysis
#         selected_tariff: Tariff configuration for MD period detection
#         holidays: Set of holiday dates
#     """
#     import plotly.graph_objects as go
#     from plotly.subplots import make_subplots
#     
#     # Handle None parameters with safe defaults
#     if monthly_targets is None:
#         st.error("âŒ V2 Chart Error: monthly_targets is required for dynamic target visualization")
#         return
#         
#     if sizing is None:
#         sizing = {'power_rating_kw': 100, 'capacity_kwh': 100}
#     
#     # ===== V2 TWO-LEVEL CASCADING FILTERING =====
#     st.markdown("##### ðŸŽ¯ V2 Two-Level Cascading Filters")
#     
#     # Success/Failure dropdown filter instead of timestamp filter
#     if len(df_sim) > 0:
#         # Calculate shaving success for each point if not already available
#         if 'Shaving_Success' not in df_sim.columns:
#             # Use the comprehensive battery status if Success_Status exists
#             if 'Success_Status' in df_sim.columns:
#                 df_sim['Shaving_Success'] = df_sim['Success_Status']
#             else:
#                 df_sim['Shaving_Success'] = df_sim.apply(lambda row: _get_enhanced_shaving_success(row, holidays), axis=1)
#         
#         # ===== LEVEL 1: DAY TYPE FILTER =====
#         col1, col2 = st.columns([4, 1])
#         with col1:
#             filter_options = [
#                 "All Days",
#                 "All Success Days", 
#                 "All Partial Days",
#                 "All Failed Days"
#             ]
#             
#             selected_filter = st.selectbox(
#                 "ðŸŽ¯ Level 1: Filter by Day Type:",
#                 options=filter_options,
#                 index=0,
#                 key="chart_success_filter",
#                 help="First level: Filter chart data to show complete days that contain specific event types"
#             )
#             
#         with col2:
#             if st.button("ðŸ”„ Reset All Filters", key="reset_chart_success_filter"):
#                 st.session_state.chart_success_filter = "All Days"
#                 if 'specific_day_filter' in st.session_state:
#                     del st.session_state.specific_day_filter
#                 st.rerun()
#         
#         # ===== LEVEL 2: SPECIFIC DAY FILTER (Always show regardless of Level 1 selection) =====
#         level2_days = []
#         
#         # Get available days based on Level 1 filter
#         if selected_filter == "All Success Days":
#             # Updated patterns for simplified 4-category system
#             success_patterns = 'âœ… Success'
#             success_days = df_sim[df_sim['Shaving_Success'].str.contains(success_patterns, na=False)].index.date
#             level2_days = sorted(set(success_days))
#         elif selected_filter == "All Partial Days":
#             # Updated patterns for simplified 4-category system  
#             partial_patterns = 'ðŸŸ¡ Partial'
#             partial_days = df_sim[df_sim['Shaving_Success'].str.contains(partial_patterns, na=False)].index.date
#             level2_days = sorted(set(partial_days))
#         elif selected_filter == "All Failed Days":
#             # Updated patterns for simplified 4-category system
#             failed_patterns = 'ðŸ”´ Failed'
#             failed_days = df_sim[df_sim['Shaving_Success'].str.contains(failed_patterns, na=False)].index.date
#             level2_days = sorted(set(failed_days))
#         else:
#             # "All Days" - show all available days
#             all_days = sorted(set(df_sim.index.date))
#             level2_days = all_days
#         
#         # Always show Level 2 filter interface
#         st.markdown("**Level 2: Select Specific Day for Detailed Analysis**")
#         col3, col4 = st.columns([5, 1])
#         
#         with col3:
#             # Create options for specific day selection
#             if selected_filter == "All Days":
#                 day_options = ["All Days"]
#             else:
#                 day_options = ["All " + selected_filter.split()[-2] + " " + selected_filter.split()[-1]]  # e.g., "All Success Days"
#             
#             # Add individual days if available
#             if level2_days:
#                 day_options.extend([str(day) for day in level2_days])
#             
#             selected_specific_day = st.selectbox(
#                 "ðŸŽ¯ Select Specific Day:",
#                 options=day_options,
#                 index=0,
#                 key="specific_day_filter",
#                 help="Second level: Choose a specific date for detailed analysis, or keep 'All' to show all days of the selected type"
#             )
#         
#         with col4:
#             if st.button("ðŸ”„ Reset Day", key="reset_specific_day_filter"):
#                 if 'specific_day_filter' in st.session_state:
#                     del st.session_state.specific_day_filter
#                 st.rerun()
#         
#         # ===== APPLY TWO-LEVEL CASCADING FILTERS =====
#         df_sim_filtered = df_sim.copy()
#         
#         # Level 1: Day Type Filter
#         if selected_filter == "All Success Days":
#             # Find all days that contain success events - Updated for simplified 4-category system
#             success_patterns = 'âœ… Success'
#             success_days = df_sim[df_sim['Shaving_Success'].str.contains(success_patterns, na=False)].index.date
#             success_days_set = set(success_days)
#             # Show all data for those days - use pd.Series.isin() instead of numpy array.isin()
#             df_sim_filtered = df_sim[pd.Series(df_sim.index.date).isin(success_days_set).values]
#         elif selected_filter == "All Partial Days":
#             # Find all days that contain partial events - Updated for simplified 4-category system
#             partial_patterns = 'ðŸŸ¡ Partial'
#             partial_days = df_sim[df_sim['Shaving_Success'].str.contains(partial_patterns, na=False)].index.date
#             partial_days_set = set(partial_days)
#             # Show all data for those days - use pd.Series.isin() instead of numpy array.isin()
#             df_sim_filtered = df_sim[pd.Series(df_sim.index.date).isin(partial_days_set).values]
#         elif selected_filter == "All Failed Days":
#             # Find all days that contain failed events - Updated for simplified 4-category system
#             failed_patterns = 'ðŸ”´ Failed'
#             failed_days = df_sim[df_sim['Shaving_Success'].str.contains(failed_patterns, na=False)].index.date
#             failed_days_set = set(failed_days)
#             # Show all data for those days - use pd.Series.isin() instead of numpy array.isin()
#             df_sim_filtered = df_sim[pd.Series(df_sim.index.date).isin(failed_days_set).values]
#         else:
#             # "All Days" - show everything (no Level 1 filtering)
#             df_sim_filtered = df_sim
#         
#         # Level 2: Specific Day Filter (apply regardless of Level 1 selection)
#         if 'specific_day_filter' in st.session_state:
#             selected_specific_day = st.session_state.get('specific_day_filter', '')
#             
#             # Check if a specific day is selected (not an "All [Type]" option)
#             if selected_specific_day and not selected_specific_day.startswith("All "):
#                 try:
#                     # Parse the selected date
#                     from datetime import datetime
#                     specific_date = datetime.strptime(selected_specific_day, "%Y-%m-%d").date()
#                     
#                     # Filter to show only data from the specific day
#                     df_sim_filtered = df_sim_filtered[df_sim_filtered.index.date == specific_date]
#                     
#                 except (ValueError, TypeError):
#                     st.warning(f"âš ï¸ Could not parse selected date: {selected_specific_day}")
#         
#         # Calculate day breakdown counts using simplified 4-category system (always calculate)
#         success_days = len(set(df_sim[df_sim['Shaving_Success'].str.contains('âœ… Success', na=False)].index.date))
#         partial_days = len(set(df_sim[df_sim['Shaving_Success'].str.contains('ðŸŸ¡ Partial', na=False)].index.date))
#         failed_days = len(set(df_sim[df_sim['Shaving_Success'].str.contains('ðŸ”´ Failed', na=False)].index.date))
#         total_days = len(set(df_sim.index.date))
#         filtered_days = len(set(df_sim_filtered.index.date))
#         
#         # Display cascading filter results summary
#         if len(df_sim_filtered) < len(df_sim):
#             
#             # Check if Level 2 filter is active (updated for always-visible interface)
#             level2_active = ('specific_day_filter' in st.session_state and 
#                            st.session_state.get('specific_day_filter', '').strip() and 
#                            not st.session_state.get('specific_day_filter', '').startswith("All "))
#             
#             if level2_active:
#                 specific_day = st.session_state.get('specific_day_filter', '')
#                 st.info(f"""
#                 ðŸŽ¯ **Two-Level Filter Results**: 
#                 - **Level 1**: {selected_filter} 
#                 - **Level 2**: Specific Day ({specific_day})
#                 - **Showing**: {len(df_sim_filtered):,} records from {filtered_days} day(s)
#                 """)
#             else:
#                 st.info(f"""
#                 ðŸ“Š **Level 1 Filter Results**: Showing {len(df_sim_filtered):,} records from {filtered_days} days of {len(df_sim):,} total records ({filtered_days}/{total_days} days, {len(df_sim_filtered)/len(df_sim)*100:.1f}%)
#                 
#                 **Day Breakdown:**
#                 - âœ… **Success Days**: {success_days} days
#                 - ðŸŸ¡ **Partial Days**: {partial_days} days
#                 - ðŸ”´ **Failed Days**: {failed_days} days
#                 """)
#         else:
#             # Always show day breakdown even when no filters are applied
#             st.info(f"""
#             ðŸ“Š **All Days**: Showing {len(df_sim_filtered):,} records from {total_days} days
#             
#             **Day Breakdown:**
#             - âœ… **Success Days**: {success_days} days
#             - ðŸŸ¡ **Partial Days**: {partial_days} days
#             - ðŸ”´ **Failed Days**: {failed_days} days
#             """)
#         
#         # Use filtered data for the rest of the chart function
#         df_sim = df_sim_filtered
#         
#         # Validation check after filtering
#         if len(df_sim) == 0:
#             st.warning("âš ï¸ No days match the selected filter criteria. Please choose a different filter.")
#             return
#     
#     # Resolve Net Demand column name flexibly
#     net_candidates = ['Net_Demand_kW', 'Net_Demand_KW', 'Net_Demand']
#     net_col = next((c for c in net_candidates if c in df_sim.columns), None)
#     
#     # Validate required columns exist
#     required_base = ['Original_Demand', 'Battery_Power_kW', 'Battery_SOC_Percent']
#     missing_columns = [col for col in required_base if col not in df_sim.columns]
#     if net_col is None:
#         missing_columns.append('Net_Demand_kW')
#     
#     if missing_columns:
#         st.error(f"âŒ Missing required columns in V2 simulation data: {missing_columns}")
#         st.info("Available columns: " + ", ".join(df_sim.columns.tolist()))
#         return
#     
#     # Create V2 dynamic target series (stepped monthly targets) - filtered to match chart data
#     target_series = _create_v2_dynamic_target_series(df_sim.index, monthly_targets)
#     
#     # Display filtered event range info
#     if selected_filter != "All Events" and len(df_sim) > 0:
#         filter_start = df_sim.index.min()
#         filter_end = df_sim.index.max()
#         st.info(f"ðŸ“… **Filtered Event Range**: {filter_start.strftime('%Y-%m-%d %H:%M')} to {filter_end.strftime('%Y-%m-%d %H:%M')}")
#     
#     # Panel 1: V2 Enhanced MD Shaving Effectiveness with Dynamic Monthly Targets
#     st.markdown("##### 1ï¸âƒ£ V2 MD Shaving Effectiveness: Demand vs Battery vs Dynamic Monthly Targets")
#     
#     # Display filtering status info (updated for always-visible Level 2)
#     level2_active = ('specific_day_filter' in st.session_state and 
#                     st.session_state.get('specific_day_filter', '').strip() and 
#                     not st.session_state.get('specific_day_filter', '').startswith("All "))
#     
#     if level2_active:
#         specific_day = st.session_state.get('specific_day_filter', '')
#         st.info(f"ðŸ†• **V2 Enhancement with Two-Level Filtering**: Target line changes monthly based on V2 configuration, showing **{selected_filter}** filtered to **{specific_day}**")
#     elif selected_filter != "All Days":
#         st.info(f"ðŸ†• **V2 Enhancement with Level 1 Filtering**: Target line changes monthly based on V2 configuration, showing only **{selected_filter.lower()}**")
#     else:
#         st.info("ðŸ†• **V2 Enhancement**: Target line changes monthly based on your V2 target configuration")
#     
#     fig = go.Figure()
#     
#     # Add demand lines
#     fig.add_trace(
#         go.Scatter(x=df_sim.index, y=df_sim[net_col], 
#                   name='Net Demand (with Battery)', line=dict(color='#00BFFF', width=2),
#                   hovertemplate='Net: %{y:.1f} kW<br>%{x}<extra></extra>')
#     )
#     
#     # V2 ENHANCEMENT: Add stepped monthly target line instead of static line
#     fig.add_trace(
#         go.Scatter(x=df_sim.index, y=target_series, 
#                   name='Monthly Target (V2 Dynamic)', 
#                   line=dict(color='green', dash='dash', width=3),
#                   hovertemplate='Monthly Target: %{y:.1f} kW<br>%{x}<extra></extra>')
#     )
#     
#     # Replace area fills with bar charts for battery discharge/charge
#     discharge_series = df_sim['Battery_Power_kW'].where(df_sim['Battery_Power_kW'] > 0, other=0)
#     charge_series = df_sim['Battery_Power_kW'].where(df_sim['Battery_Power_kW'] < 0, other=0)
#     
#     # Discharge bars
#     fig.add_trace(go.Bar(
#         x=df_sim.index,
#         y=discharge_series,
#         name='Battery Discharge (kW)',
#         marker=dict(color='orange'),
#         opacity=0.6,
#         hovertemplate='Discharge: %{y:.1f} kW<br>%{x}<extra></extra>',
#         yaxis='y2'
#     ))
#     
#     # Charge bars (negative values)
#     fig.add_trace(go.Bar(
#         x=df_sim.index,
#         y=charge_series,
#         name='Battery Charge (kW)',
#         marker=dict(color='green'),
#         opacity=0.6,
#         hovertemplate='Charge: %{y:.1f} kW<br>%{x}<extra></extra>',
#         yaxis='y2'
#     ))
#     
#     # V2 ENHANCEMENT: Add dynamic conditional coloring using monthly targets instead of static average
#     # This replaces the V1 averaging approach with dynamic monthly target-based coloring
#     fig = _create_v2_conditional_demand_line_with_dynamic_targets(
#         fig, df_sim, 'Original_Demand', target_series, selected_tariff, holidays, "Original Demand"
#     )
#     
#     # Compute symmetric range for y2 to show positive/negative bars
#     try:
#         max_abs_power = float(df_sim['Battery_Power_kW'].abs().max())
#     except Exception:
#         max_abs_power = float(sizing.get('power_rating_kw', 100))
#     y2_limit = max(max_abs_power * 1.1, sizing.get('power_rating_kw', 100) * 0.5)
#     
#     fig.update_layout(
#         title='ðŸŽ¯ V2 MD Shaving Effectiveness: Demand vs Battery vs Dynamic Monthly Targets',
#         xaxis_title='Time',
#         yaxis_title='Power Demand (kW)',
#         yaxis2=dict(
#             title='Battery Power (kW) [+ discharge | - charge]',
#             overlaying='y',
#             side='right',
#             range=[-y2_limit, y2_limit],
#             zeroline=True,
#             zerolinecolor='gray'
#         ),
#         height=500,
#         hovermode='x unified',
#         legend=dict(
#             orientation="h",
#             yanchor="top", 
#             y=-0.15,
#             xanchor="center", 
#             x=0.5
#         ),
#         margin=dict(b=100),
#         barmode='overlay',
#         template="none",
#         plot_bgcolor='rgba(0,0,0,0)',
#         paper_bgcolor='rgba(0,0,0,0)'
#     )
#     
#     st.plotly_chart(fig, use_container_width=True)
#     
#     # V2 ENHANCEMENT INFO: Add explanation about dynamic color coding
#     st.info("""
#     ðŸ†• **V2 Color Coding Enhancement**: The colored line segments now use **dynamic monthly targets** instead of a static average target.
#     - **Blue segments**: Below monthly target (acceptable levels)
#     - **Green segments**: Above monthly target during off-peak periods (energy cost only)
#     - **Red segments**: Above monthly target during peak periods (energy + MD cost impact)
#     
#     This provides more accurate visual feedback about when intervention is needed based on realistic monthly billing patterns.
#     """)
#     
#     # ===== V2 TABLE VISUALIZATION INTEGRATION BETWEEN CHART 1 AND 2 =====
#     # Get dynamic interval hours for energy calculations
#     interval_hours = _get_dynamic_interval_hours(df_sim)
#     
#     _display_battery_simulation_tables(df_sim, {
#         'peak_reduction_kw': sizing.get('power_rating_kw', 0) if sizing else 0,
#         'success_rate_percent': 85.0,  # Default placeholder
#         'total_energy_discharged': df_sim['Battery_Power_kW'].where(df_sim['Battery_Power_kW'] > 0, 0).sum() * interval_hours,
#         'total_energy_charged': abs(df_sim['Battery_Power_kW'].where(df_sim['Battery_Power_kW'] < 0, 0).sum()) * interval_hours,
#         'average_soc': df_sim['Battery_SOC_Percent'].mean(),
#         'min_soc': df_sim['Battery_SOC_Percent'].min(),
#         'max_soc': df_sim['Battery_SOC_Percent'].max(),
#         'monthly_targets_count': len(monthly_targets) if monthly_targets is not None else 0,
#         'v2_constraint_violations': len(df_sim[df_sim['Net_Demand_kW'] > df_sim['Monthly_Target']])
#     }, selected_tariff, holidays)
#     
#     # Panel 2: Combined SOC and Battery Power Chart (same as V1)
#     st.markdown("##### 2ï¸âƒ£ Combined SOC and Battery Power Chart")
#     
#     fig2 = make_subplots(specs=[[{"secondary_y": True}]])
#     
#     # SOC line (left y-axis)
#     fig2.add_trace(
#         go.Scatter(x=df_sim.index, y=df_sim['Battery_SOC_Percent'],
#                   name='SOC (%)', line=dict(color='purple', width=2),
#                   hovertemplate='SOC: %{y:.1f}%<br>%{x}<extra></extra>'),
#         secondary_y=False
#     )
#     
#     # Battery power line (right y-axis) 
#     fig2.add_trace(
#         go.Scatter(x=df_sim.index, y=df_sim['Battery_Power_kW'],
#                   name='Battery Power', line=dict(color='orange', width=2),
#                   hovertemplate='Power: %{y:.1f} kW<br>%{x}<extra></extra>'),
#         secondary_y=True
#     )
#     
#     # Add horizontal line for minimum SOC warning (updated to 10% based on 5% safety limit)
#     fig2.add_hline(y=10, line_dash="dot", line_color="red", 
#                    annotation_text="Low SOC Warning (10% - 5% Safety Limit)", secondary_y=False)
#     
#     # Update axes
#     fig2.update_xaxes(title_text="Time")
#     fig2.update_yaxes(title_text="State of Charge (%)", secondary_y=False, range=[0, 100])
#     fig2.update_yaxes(title_text="Battery Discharge Power (kW)", secondary_y=True)
#     
#     fig2.update_layout(
#         title='âš¡ SOC vs Battery Power: Timing Analysis',
#         height=400,
#         hovermode='x unified',
#         template="none",
#         plot_bgcolor='rgba(0,0,0,0)',
#         paper_bgcolor='rgba(0,0,0,0)'
#     )
#     
#     st.plotly_chart(fig2, use_container_width=True)
#     
#     # Panel 3: Battery Power Utilization Heatmap (same as V1)
#     st.markdown("##### 3ï¸âƒ£ Battery Power Utilization Heatmap")
#     
#     # Prepare data for heatmap
#     df_heatmap = df_sim.copy()
#     df_heatmap['Date'] = df_heatmap.index.date
#     df_heatmap['Hour'] = df_heatmap.index.hour
#     df_heatmap['Battery_Utilization_%'] = (df_heatmap['Battery_Power_kW'] / sizing['power_rating_kw'] * 100).clip(0, 100)
#     
#     # Create pivot table for heatmap
#     heatmap_data = df_heatmap.pivot_table(
#         values='Battery_Utilization_%', 
#         index='Hour', 
#         columns='Date', 
#         aggfunc='mean',
#         fill_value=0
#     )
#     
#     # Create heatmap
#     fig3 = go.Figure(data=go.Heatmap(
#         z=heatmap_data.values,
#         x=[str(d) for d in heatmap_data.columns],
#         y=heatmap_data.index,
#         colorscale='Viridis',
#         hoverongaps=False,
#         hovertemplate='Date: %{x}<br>Hour: %{y}<br>Utilization: %{z:.1f}%<extra></extra>',
#         colorbar=dict(title="Battery Utilization (%)")
#     ))
#     
#     fig3.update_layout(
#         title='ðŸ”¥ Battery Power Utilization Heatmap (% of Rated Power)',
#         xaxis_title='Date',
#         yaxis_title='Hour of Day',
#         height=400,
#         template="none",
#         plot_bgcolor='rgba(0,0,0,0)',
#         paper_bgcolor='rgba(0,0,0,0)'
#     )
#     
#     st.plotly_chart(fig3, use_container_width=True)
#     
#     # Panel 4: V2 Enhanced Daily Peak Shave Effectiveness with Monthly Target Context
#     st.markdown("##### 4ï¸âƒ£ V2 Daily Peak Shave Effectiveness & Success Analysis (MD Peak Periods Only)")
#     st.info("ðŸ†• **V2 Enhancement**: Success/failure calculated against dynamic monthly targets")
#     
#     # Filter data for MD peak periods only (2 PM-10 PM, weekdays)
#     def is_md_peak_period_for_effectiveness(timestamp):
#         return timestamp.weekday() < 5 and 14 <= timestamp.hour < 22
#         
#     df_md_peak = df_sim[df_sim.index.to_series().apply(is_md_peak_period_for_effectiveness)]
#     
#     # Calculate daily analysis using MD peak periods only WITH V2 monthly targets
#     if len(df_md_peak) > 0:
#         daily_analysis = df_md_peak.groupby(df_md_peak.index.date).agg({
#             'Original_Demand': 'max',
#             net_col: 'max',
#             'Battery_Power_kW': 'max',
#             'Battery_SOC_Percent': ['min', 'mean']
#         }).reset_index()
#         
#         # Flatten column names
#         daily_analysis.columns = ['Date', 'Original_Peak_MD', 'Net_Peak_MD', 'Max_Battery_Power', 'Min_SOC', 'Avg_SOC']
#         
#         # V2 ENHANCEMENT: Get monthly target for each day
#         daily_analysis['Monthly_Target'] = daily_analysis['Date'].apply(
#             lambda date: _get_monthly_target_for_date(date, monthly_targets)
#         )
#         
#         # Calculate detailed metrics based on V2 monthly targets
#         md_rate_estimate = 97.06  # RM/kW from Medium Voltage TOU
#         daily_analysis['Peak_Reduction'] = daily_analysis['Original_Peak_MD'] - daily_analysis['Net_Peak_MD']
#         daily_analysis['Est_Monthly_Saving'] = daily_analysis['Peak_Reduction'] * md_rate_estimate
#         
#         # V2 SUCCESS LOGIC: Compare against monthly targets instead of static target
#         daily_analysis['Success'] = daily_analysis['Net_Peak_MD'] <= daily_analysis['Monthly_Target'] * 1.05  # 5% tolerance
#         daily_analysis['Peak_Shortfall'] = (daily_analysis['Net_Peak_MD'] - daily_analysis['Monthly_Target']).clip(lower=0)
#         daily_analysis['Required_Additional_Power'] = daily_analysis['Peak_Shortfall']
#         
#         # Add informational note about V2 monthly target logic
#         st.info("""
#         ðŸ“‹ **V2 Monthly Target Analysis Note:**
#         This analysis uses **dynamic monthly targets** instead of a static target.
#         Each day's success is evaluated against its specific month's target.
#         Success rate reflects effectiveness against V2's monthly optimization strategy.
#         """)
#     else:
#         st.warning("âš ï¸ No MD peak period data found (weekdays 2-10 PM). Cannot calculate V2 MD-focused effectiveness.")
#         return
#     
#     # Categorize failure reasons with V2 context (updated for 5% minimum SOC safety limit)
#     def categorize_failure_reason(row):
#         if row['Success']:
#             return 'Success'
#         elif row['Min_SOC'] < 10:  # Updated from 20% to 10% (based on 5% safety limit)
#             return 'Low SOC (Battery Depleted)'
#         elif row['Max_Battery_Power'] < sizing['power_rating_kw'] * 0.9:
#             return 'Insufficient Battery Power'
#         elif row['Peak_Shortfall'] > sizing['power_rating_kw']:
#             return 'Demand Exceeds Battery Capacity'
#         else:
#             return 'Other (Algorithm/Timing)'
#     
#     daily_analysis['Failure_Reason'] = daily_analysis.apply(categorize_failure_reason, axis=1)
#     
#     # Create enhanced visualization with monthly target context
#     fig4 = go.Figure()
#     
#     # V2 Enhancement: Add monthly target reference lines instead of single target line
#     for month_period, target_value in monthly_targets.items():
#         month_start = max(month_period.start_time, df_sim.index.min())
#         month_end = min(month_period.end_time, df_sim.index.max())
#         
#         # Add horizontal line for this month's target
#         fig4.add_shape(
#             type="line",
#             x0=month_start, y0=target_value,
#             x1=month_end, y1=target_value,
#             line=dict(color="green", width=2, dash="dash"),
#         )
#         
#         # Add annotation for the target value
#         fig4.add_annotation(
#             x=month_start + (month_end - month_start) / 2,
#             y=target_value,
#             text=f"{target_value:.0f} kW",
#             showarrow=False,
#             yshift=10,
#             bgcolor="rgba(255,255,255,0.8)"
#         )
#     
#     # Color code bars based on success/failure
#     bar_colors = ['green' if success else 'red' for success in daily_analysis['Success']]
#     
#     # Original peaks (MD peak periods only)
#     fig4.add_trace(go.Bar(
#         x=daily_analysis['Date'], y=daily_analysis['Original_Peak_MD'],
#         name='Original Peak (MD Periods)', marker_color='lightcoral', opacity=0.6,
#         hovertemplate='Original MD Peak: %{y:.0f} kW<br>Date: %{x}<extra></extra>'
#     ))
#     
#     # Net peaks (after battery) - color coded by success
#     fig4.add_trace(go.Bar(
#         x=daily_analysis['Date'], y=daily_analysis['Net_Peak_MD'],
#         name='Net Peak (MD Periods with Battery)', 
#         marker_color=bar_colors, opacity=0.8,
#         hovertemplate='Net MD Peak: %{y:.0f} kW<br>Status: %{customdata}<br>Date: %{x}<extra></extra>',
#         customdata=['SUCCESS' if s else 'FAILED' for s in daily_analysis['Success']]
#     ))
#     
#     fig4.update_layout(
#         title='ðŸ“Š V2 Daily Peak Shaving Effectiveness - MD Periods with Monthly Targets (Green=Success, Red=Failed)',
#         xaxis_title='Date',
#         yaxis_title='Peak Demand during MD Hours (kW)',
#         height=400,
#         barmode='group',
#         template="none",
#         plot_bgcolor='rgba(0,0,0,0)',
#         paper_bgcolor='rgba(0,0,0,0)'
#     )
#     
#     st.plotly_chart(fig4, use_container_width=True)
#     
#     # Summary stats with V2 synchronized success rate
#     # Use synchronized calculation instead of local daily analysis for consistency
#     if 'Success_Status' in df_sim.columns:
#         sync_success_metrics = _calculate_success_rate_from_shaving_status(df_sim, holidays=holidays)
#         success_rate = sync_success_metrics['success_rate_percent']
#         successful_intervals = sync_success_metrics['successful_intervals']
#         total_md_intervals = sync_success_metrics['total_md_intervals']
#         
#         col1, col2, col3, col4 = st.columns(4)
#         col1.metric("MD Intervals", f"{total_md_intervals}")
#         col2.metric("Successful Intervals", f"{successful_intervals}", delta=f"{success_rate:.1f}%")
#         col3.metric("Failed Intervals", f"{total_md_intervals - successful_intervals}", delta=f"{100-success_rate:.1f}%")
#         col4.metric("V2 Synchronized Success Rate", f"{success_rate:.1f}%")
#     else:
#         # Fallback to daily analysis if Success_Status not available
#         total_days = len(daily_analysis)
#         successful_days = sum(daily_analysis['Success'])
#         failed_days = total_days - successful_days
#         success_rate = (successful_days / total_days * 100) if total_days > 0 else 0
#         
#         col1, col2, col3, col4 = st.columns(4)
#         col1.metric("Total Days", f"{total_days}")
#         col2.metric("Successful Days", f"{successful_days}", delta=f"{success_rate:.1f}%")
#         col3.metric("Failed Days", f"{failed_days}", delta=f"{100-success_rate:.1f}%")
#         col4.metric("V2 Success Rate (Fallback)", f"{success_rate:.1f}%")
#     
#     # Panel 5: V2 Cumulative Energy Analysis with Monthly Target Context
#     st.markdown("##### 5ï¸âƒ£ V2 Cumulative Energy Analysis: Energy Discharged vs Required (MD Peak Periods)")
#     st.info("ðŸ†• **V2 Enhancement**: Energy requirements calculated using dynamic monthly targets")
#     
#     # Use the same daily analysis data but with V2 monthly target logic
#     if len(daily_analysis) > 0:
#         # Calculate energy requirements using V2 monthly target approach
#         daily_analysis_energy = daily_analysis.copy()
#         
#         # V2 Energy Required: Calculate based on daily peak reduction needs using monthly targets
#         daily_analysis_energy['Daily_Energy_Required_kWh'] = 0.0
#         
#         # For each day, calculate energy required based on monthly target instead of static target
#         for idx, row in daily_analysis_energy.iterrows():
#             original_peak = row['Original_Peak_MD']
#             net_peak = row['Net_Peak_MD']
#             monthly_target = row['Monthly_Target']
#             
#             if original_peak > monthly_target:
#                 # Calculate energy required to shave this day's peak to monthly target
#                 if net_peak <= monthly_target * 1.05:  # Successful day
#                     # Energy that was successfully shaved (based on actual peak reduction)
#                     energy_shaved = row['Peak_Reduction'] * interval_hours  # Convert kW to kWh using dynamic interval
#                 else:  # Failed day
#                     # Energy that would be needed to reach monthly target
#                     energy_needed = (original_peak - monthly_target) * interval_hours
#                     energy_shaved = energy_needed
#                 
#                 daily_analysis_energy.loc[idx, 'Daily_Energy_Required_kWh'] = energy_shaved
#         
#         # Calculate energy discharged from battery during MD peak periods for each day
#         daily_analysis_energy['Daily_Energy_Discharged_kWh'] = 0.0
#         
#         # Group simulation data by date and sum battery discharge during MD peak periods
#         df_sim_md_peak = df_sim[df_sim.index.to_series().apply(is_md_peak_period_for_effectiveness)]
#         if len(df_sim_md_peak) > 0:
#             daily_battery_discharge = df_sim_md_peak.groupby(df_sim_md_peak.index.date).agg({
#                 'Battery_Power_kW': lambda x: (x.clip(lower=0) * interval_hours).sum()  # Only positive (discharge) using dynamic interval
#             }).reset_index()
#             daily_battery_discharge.columns = ['Date', 'Daily_Battery_Discharge_kWh']
#             
#             # Merge with daily analysis
#             daily_analysis_energy['Date'] = pd.to_datetime(daily_analysis_energy['Date'])
#             daily_battery_discharge['Date'] = pd.to_datetime(daily_battery_discharge['Date'])
#             daily_analysis_energy = daily_analysis_energy.merge(
#                 daily_battery_discharge, on='Date', how='left'
#             ).fillna(0)
#             
#             daily_analysis_energy['Daily_Energy_Discharged_kWh'] = daily_analysis_energy['Daily_Battery_Discharge_kWh']
#         else:
#             st.warning("No MD peak period data available for V2 energy analysis.")
#             return
#     
#         # Sort by date for cumulative calculation
#         daily_analysis_energy = daily_analysis_energy.sort_values('Date').reset_index(drop=True)
#         
#         # Calculate cumulative values
#         daily_analysis_energy['Cumulative_Energy_Required'] = daily_analysis_energy['Daily_Energy_Required_kWh'].cumsum()
#         daily_analysis_energy['Cumulative_Energy_Discharged'] = daily_analysis_energy['Daily_Energy_Discharged_kWh'].cumsum()
#         daily_analysis_energy['Cumulative_Energy_Shortfall'] = daily_analysis_energy['Cumulative_Energy_Required'] - daily_analysis_energy['Cumulative_Energy_Discharged']
#         
#         # Create the chart using the daily aggregated data with V2 context
#         if len(daily_analysis_energy) > 0:
#             fig5 = go.Figure()
#             
#             # Energy Discharged line (from daily analysis)
#             fig5.add_trace(go.Scatter(
#                 x=daily_analysis_energy['Date'],
#                 y=daily_analysis_energy['Cumulative_Energy_Discharged'],
#                 mode='lines+markers',
#                 name='Cumulative Energy Discharged (MD Periods)',
#                 line=dict(color='blue', width=2),
#                 hovertemplate='Discharged: %{y:.1f} kWh<br>Date: %{x}<extra></extra>'
#             ))
#             
#             # Energy Required line (from daily analysis with V2 monthly targets)
#             fig5.add_trace(go.Scatter(
#                 x=daily_analysis_energy['Date'],
#                 y=daily_analysis_energy['Cumulative_Energy_Required'],
#                 mode='lines+markers',
#                 name='Cumulative Energy Required (V2 Monthly Targets)',
#                 line=dict(color='red', width=2, dash='dot'),
#                 hovertemplate='Required (V2): %{y:.1f} kWh<br>Date: %{x}<extra></extra>'
#             ))
#             
#             # Add area fill for energy shortfall
#             fig5.add_trace(go.Scatter(
#                 x=daily_analysis_energy['Date'],
#                 y=daily_analysis_energy['Cumulative_Energy_Shortfall'].clip(lower=0),
#                 fill='tozeroy',
#                 fillcolor='rgba(255,0,0,0.2)',
#                 line=dict(color='rgba(255,0,0,0)'),
#                 name='Cumulative Energy Shortfall (V2)',
#                 hovertemplate='Shortfall: %{y:.1f} kWh<br>Date: %{x}<extra></extra>'
#             ))
#             
#             fig5.update_layout(
#                 title='ðŸ“ˆ V2 Cumulative Energy Analysis: Monthly Target-Based Daily Aggregation',
#                 xaxis_title='Date',
#                 yaxis_title='Cumulative Energy (kWh)',
#                 height=500,
#                 hovermode='x unified',
#                 template="none",
#                 plot_bgcolor='rgba(0,0,0,0)',
#                 paper_bgcolor='rgba(0,0,0,0)'
#             )
#             
#             st.plotly_chart(fig5, use_container_width=True)
#             
#             # Display metrics using V2 monthly target calculations
#             total_energy_required = daily_analysis_energy['Daily_Energy_Required_kWh'].sum()
#             total_energy_discharged = daily_analysis_energy['Daily_Energy_Discharged_kWh'].sum()
#             
#             col1, col2, col3 = st.columns(3)
#             col1.metric("Total Energy Required (V2 MD)", f"{total_energy_required:.1f} kWh")
#             col2.metric("Total Energy Discharged (V2 MD)", f"{total_energy_discharged:.1f} kWh")
#             
#             if total_energy_required > 0:
#                 fulfillment_rate = (total_energy_discharged / total_energy_required) * 100
#                 col3.metric("V2 MD Energy Fulfillment", f"{fulfillment_rate:.1f}%")
#             else:
#                 col3.metric("V2 MD Energy Fulfillment", "100%")
#             
#             # Add detailed breakdown table with V2 context
#             with st.expander("ðŸ“Š V2 Daily Energy Breakdown (Monthly Target-Based Analysis)"):
#                 display_columns = ['Date', 'Original_Peak_MD', 'Net_Peak_MD', 'Peak_Reduction', 'Monthly_Target',
#                                  'Daily_Energy_Required_kWh', 'Daily_Energy_Discharged_kWh', 'Success']
#                 
#                 if all(col in daily_analysis_energy.columns for col in display_columns):
#                     daily_display = daily_analysis_energy[display_columns].copy()
#                     daily_display.columns = ['Date', 'Original Peak (kW)', 'Net Peak (kW)', 'Peak Reduction (kW)', 
#                                            'Monthly Target (kW)', 'Energy Required (kWh)', 'Energy Discharged (kWh)', 'Success']
#                     
#                     formatted_daily = daily_display.style.format({
#                         'Original Peak (kW)': '{:.1f}',
#                         'Net Peak (kW)': '{:.1f}',
#                         'Peak Reduction (kW)': '{:.1f}',
#                         'Monthly Target (kW)': '{:.1f}',
#                         'Energy Required (kWh)': '{:.2f}',
#                         'Energy Discharged (kWh)': '{:.2f}'
#                     })
#                     
#                     st.dataframe(formatted_daily, use_container_width=True)
#                 else:
#                     st.warning("Some columns missing from V2 daily analysis data.")
#             
#             # Add V2-specific information box
#             st.info(f"""
#             **ðŸ“‹ V2 Data Source Alignment Confirmation:**
#             - **Energy Required**: Calculated from daily peak reduction needs using **dynamic monthly targets**
#             - **Energy Discharged**: Sum of battery discharge energy during MD recording hours per day  
#             - **Calculation Method**: V2 monthly target-based approach vs V1 static target approach
#             - **Monthly Targets**: {len(monthly_targets)} different monthly targets used
#             - **Total Days Analyzed**: {len(daily_analysis_energy)} days with MD peak period data
#             - **Success Rate**: {(daily_analysis_energy['Success'].sum() / len(daily_analysis_energy) * 100):.1f}% (based on monthly targets)
#             
#             âœ… **V2 Innovation**: This chart uses dynamic monthly targets instead of static targets for more accurate analysis.
#             """)
#             
#         else:
#             st.warning("No daily analysis data available for V2 cumulative energy chart.")
#     else:
#         st.warning("No MD peak period data available for V2 energy analysis.")
#     
#     # V2 Key insights with monthly target context
#     st.markdown("##### ðŸ” V2 Key Insights from Enhanced Monthly Target Analysis")
#     
#     insights = []
#     
#     # Use V2 energy efficiency calculation
#     if 'total_energy_required' in locals() and 'total_energy_discharged' in locals():
#         energy_efficiency = (total_energy_discharged / total_energy_required * 100) if total_energy_required > 0 else 100
#         
#         if energy_efficiency < 80:
#             insights.append("âš ï¸ **V2 MD Energy Shortfall**: Battery capacity may be insufficient for complete monthly target-based MD peak shaving")
#         elif energy_efficiency >= 95:
#             insights.append("âœ… **Excellent V2 MD Coverage**: Battery effectively handles all monthly target energy requirements")
#     
#     # Check V2 success rate
#     if 'success_rate' in locals():
#         if success_rate > 90:
#             insights.append("âœ… **High V2 Success Rate**: Battery effectively manages most peak events against dynamic monthly targets")
#         elif success_rate < 60:
#             insights.append("âŒ **Low V2 Success Rate**: Consider increasing battery power rating or capacity for better monthly target management")
#     
#     # Check battery utilization if heatmap data is available
#     if 'df_heatmap' in locals() and len(df_heatmap) > 0:
#         avg_utilization = df_heatmap['Battery_Utilization_%'].mean()
#         if avg_utilization < 30:
#             insights.append("ðŸ“Š **Under-utilized**: Battery power rating may be oversized for V2 monthly targets")
#         elif avg_utilization > 80:
#             insights.append("ðŸ”¥ **High Utilization**: Battery operating near maximum capacity for V2 monthly targets")
#     
#     # Check for low SOC events (updated to 10% warning threshold based on 5% safety limit)
#     low_soc_events = len(df_sim[df_sim['Battery_SOC_Percent'] < 10])
#     if low_soc_events > 0:
#         insights.append(f"ðŸ”‹ **Low SOC Warning**: {low_soc_events} intervals with SOC below 10% during V2 operation (5% safety limit)")
#     
#     # Add insight about V2 methodology
#     if len(monthly_targets) > 0:
#         insights.append(f"ðŸ“Š **V2 Innovation**: Analysis uses {len(monthly_targets)} dynamic monthly targets vs traditional static targets for superior accuracy")
#         insights.append(f"ðŸŽ¨ **V2 Color Enhancement**: Line color coding now reflects dynamic monthly targets instead of static averaging - providing month-specific intervention guidance")
#     
#     if not insights:
#         insights.append("âœ… **Optimal V2 Performance**: Battery system operating within acceptable parameters with monthly targets")
#     
#     for insight in insights:
#         st.info(insight)
# 
# 
# def _create_v2_dynamic_target_series(simulation_index, monthly_targets):
#     """
#     Create a dynamic target series that matches the simulation dataframe index
#     with stepped monthly targets from V2's monthly_targets.
#     
#     Args:
#         simulation_index: DatetimeIndex from the simulation dataframe
#         monthly_targets: V2's monthly targets (Series with Period index)
#         
#     Returns:
#         Series with same index as simulation_index, containing monthly target values
#     """
#     target_series = pd.Series(index=simulation_index, dtype=float)
#     
#     for timestamp in simulation_index:
#         # Get the month period for this timestamp
#         month_period = timestamp.to_period('M')
#         
#         # Find the corresponding monthly target
#         if month_period in monthly_targets.index:
#             target_series.loc[timestamp] = monthly_targets.loc[month_period]
#         else:
#             # Fallback: use the closest available monthly target
#             available_months = list(monthly_targets.index)
#             if available_months:
#                 # Find the closest month
#                 closest_month = min(available_months, 
#                                   key=lambda m: abs((timestamp.to_period('M') - m).n))
#                 target_series.loc[timestamp] = monthly_targets.loc[closest_month]
#             else:
#                 # Ultimate fallback
#                 target_series.loc[timestamp] = 1000.0  # Safe default
#     
#     return target_series
# 
# 
# def _get_monthly_target_for_date(date, monthly_targets):
#     """
#     Get the monthly target value for a specific date from V2's monthly targets.
#     
#     Args:
#         date: Date to get target for
#         monthly_targets: V2's monthly targets (Series with Period index)
#         
#     Returns:
#         float: Monthly target value for the given date
#     """
#     # Convert date to period
#     if isinstance(date, pd.Timestamp):
#         month_period = date.to_period('M')
#     else:
#         month_period = pd.to_datetime(date).to_period('M')
#     
#     # Return the monthly target for this period
#     if month_period in monthly_targets.index:
#         return monthly_targets.loc[month_period]
#     else:
#         # Fallback: use the first available target
#         if len(monthly_targets) > 0:
#             return monthly_targets.iloc(0)
#         else:
#             return 1000.0  # Safe fallback
# 
# 
# 
# # ==========================================
# # V2 SIMPLIFIED BATTERY ALGORITHMS
# # ==========================================
# # Complex health parameter system removed for cleaner, more maintainable code
# 
# # Removed functions for cleaner V2 algorithm:
# # - _calculate_battery_health_parameters() 
# # - _calculate_c_rate_limited_power()
# # - _get_soc_protection_levels()
# # - _apply_soc_protection_constraints()
# # - _calculate_intelligent_charge_strategy()
# 
# # These were over-engineered for MD shaving use case. 
# # V2 now uses simplified approach with basic SOC limits and C-rate constraints.
# 
# def _calculate_intelligent_charge_strategy_simple(current_soc_percent, tariff_period, battery_health_params, 
#                                                available_excess_power_kw, max_charge_power_kw):
#     """
#     SIMPLIFIED CHARGING STRATEGY for MD Shaving - removed health factors and protection levels
#     """
#     # Simple SOC-based charging levels (no complex protection levels)
#     if current_soc_percent <= 10:
#         urgency_level = 'low'
#         charge_multiplier = 0.8
#         tariff_consideration = 0.3
#     elif current_soc_percent <= 50:
#         urgency_level = 'normal'
#         charge_multiplier = 0.6
#         tariff_consideration = 0.7
#     else:
#         urgency_level = 'maintenance'
#         charge_multiplier = 0.3
#         tariff_consideration = 1.0
#     
#     # Calculate recommended charge power (no health factors)
#     base_charge_power = available_excess_power_kw * charge_multiplier
#     recommended_charge_power_kw = min(base_charge_power, max_charge_power_kw)
#     
#     return {
#         'urgency_level': urgency_level,
#         'recommended_charge_power_kw': recommended_charge_power_kw,
#         'charge_multiplier': charge_multiplier,
#         'tariff_consideration': tariff_consideration,
#         'strategy_description': f"Simplified {urgency_level} charging strategy",
#         'period_strategy': f"RP4 {tariff_period} period"
#     }
#     
#     # âœ… ENHANCED SOC-BASED CHARGING URGENCY with MD Constraint Awareness
#     if current_soc_percent <= 5:
#         # CRITICAL PROTECTION: Controlled charging that never exceeds monthly target
#         urgency_level = 'critical_protection'
#         charge_multiplier = 0.5  # Reduced from 1.0 - controlled charging only
#         tariff_consideration = 0.3  # Light tariff consideration but MD compliance priority
#         md_constraint_priority = True
#     elif current_soc_percent <= 15:
#         # PREVENTIVE PROTECTION: Micro charging during MD hours to prevent emergency situations
#         urgency_level = 'preventive_protection'
#         charge_multiplier = 0.3  # Micro charging only
#         tariff_consideration = 0.5  # Balanced approach
#         md_constraint_priority = True
#     elif current_soc_percent <= 25:
#         # LOW SOC RECOVERY: Limited charging with MD awareness
#         urgency_level = 'low_soc_recovery' 
#         charge_multiplier = 0.6
#         tariff_consideration = 0.7  # Strong tariff consideration
#         md_constraint_priority = True
#     elif current_soc_percent <= 60:
#         # NORMAL OPERATION: Tariff-optimized charging
#         urgency_level = 'normal_operation'
#         charge_multiplier = 0.7
#         tariff_consideration = 0.9  # Very strong tariff consideration
#         md_constraint_priority = False
#     elif current_soc_percent <= 95:
#         # MAINTENANCE CHARGING: Conservative approach (updated from 85% to 95%)
#         urgency_level = 'maintenance_charging'
#         charge_multiplier = 0.4
#         tariff_consideration = 1.0  # Full tariff consideration
#         md_constraint_priority = False
#     else:
#         # MAXIMUM SOC REACHED: No charging needed (updated for 95% limit)
#         urgency_level = 'max_soc_reached'
#         charge_multiplier = 0.0  # No charging above 95%
#         tariff_consideration = 1.0  # Full tariff consideration
#         md_constraint_priority = False
#     
#     # ðŸŽ¯ RP4 TARIFF-BASED CHARGING ADJUSTMENTS (2-Period System)
#     # Normalize tariff_period to handle both old 3-period and new 2-period systems
#     if tariff_period.lower() in ['peak']:
#         # Peak Period (Mon-Fri 2PM-10PM) = MD recording window
#         # Minimal charging to preserve battery capacity for discharge
#         rp4_period = 'peak'
#         tariff_multiplier = 0.2  # Very limited charging during MD window
#         period_strategy = 'preserve_for_discharge'
#     else:
#         # Off-Peak (all other times) = Optimal charging periods
#         # This includes nights, weekends, holidays
#         rp4_period = 'off_peak'
#         tariff_multiplier = 1.0  # Full charging capability
#         period_strategy = 'optimal_charging'
#     
#     # ðŸ”§ ENHANCED CHARGING POWER CALCULATION
#     base_charge_power = min(available_excess_power_kw, max_charge_power_kw) * charge_multiplier
#     
#     # Apply RP4 tariff considerations with MD constraint awareness
#     if md_constraint_priority:
#         # For critical/preventive protection: Prioritize MD compliance over tariff optimization
#         tariff_adjusted_multiplier = (1 - tariff_consideration * 0.5) + (tariff_consideration * 0.5 * tariff_multiplier)
#     else:
#         # Normal operation: Full tariff optimization
#         tariff_adjusted_multiplier = (1 - tariff_consideration) + (tariff_consideration * tariff_multiplier)
#     
#     # Final charging power recommendation
#     recommended_charge_power = base_charge_power * tariff_adjusted_multiplier
#     
#     # Apply battery health constraints
#     health_derating = battery_health_params.get('health_derating_factor', 1.0)
#     temperature_derating = battery_health_params.get('temperature_derating_factor', 1.0)
#     
#     final_charge_power = recommended_charge_power * health_derating * temperature_derating
#     
#     # ðŸ“‹ STRATEGY DESCRIPTION for logging and debugging
#     if current_soc_percent <= 15 and rp4_period == 'peak':
#         strategy_description = f"MD-aware {urgency_level}: Limited charging during peak to maintain MD compliance"
#     elif rp4_period == 'peak':
#         strategy_description = f"Peak period {urgency_level}: Minimal charging to preserve discharge capacity"
#     else:
#         strategy_description = f"Off-peak {urgency_level}: Optimized charging during low-cost period"
#     
#     return {
#         'recommended_charge_power_kw': max(0, final_charge_power),
#         'urgency_level': urgency_level,
#         'rp4_period': rp4_period,
#         'period_strategy': period_strategy,
#         'charge_multiplier': charge_multiplier,
#         'tariff_consideration': tariff_consideration,
#         'tariff_multiplier': tariff_multiplier,
#         'tariff_adjusted_multiplier': tariff_adjusted_multiplier,
#         'md_constraint_priority': md_constraint_priority,
#         'health_derating': health_derating,
#         'temperature_derating': temperature_derating,
#         'available_excess_power_kw': available_excess_power_kw,
#         'max_charge_power_kw': max_charge_power_kw,
#         'strategy_description': strategy_description,
#         'charging_recommendation': f"RP4-aware {urgency_level} at {final_charge_power:.1f}kW during {rp4_period}"
#     }
# 
# 
# def _get_tariff_aware_discharge_strategy(tariff_type, current_tariff_period, current_soc_percent, 
#                                        demand_power_kw, monthly_target_kw, battery_health_params):
#     """
#     Simple MD discharge strategy - calculates discharge power to reduce demand below monthly target.
#     
#     Args:
#         tariff_type: Type of tariff ('TOU', 'General', etc.)
#         current_tariff_period: RP4 period ('peak' or 'off_peak')
#         current_soc_percent: Current battery state of charge
#         demand_power_kw: Current power demand
#         monthly_target_kw: Current monthly target for this timestamp
#         battery_health_params: Battery health parameters
#         
#     Returns:
#         Dictionary with discharge strategy recommendations
#     """
#     # Calculate excess above target
#     excess_above_target_kw = max(0, demand_power_kw - monthly_target_kw)
#     
#     # Simple SOC-based discharge limits (updated for 5% minimum safety SOC)
#     if current_soc_percent <= 5:
#         soc_factor = 0.0  # No discharge at critical safety SOC (5% minimum)
#     elif current_soc_percent <= 15:
#         soc_factor = 0.3  # Very limited discharge near minimum SOC
#     elif current_soc_percent <= 25:
#         soc_factor = 0.6  # Limited discharge at low SOC
#     else:
#         soc_factor = 1.0  # Full discharge capability
#     
#     # Simple tariff-based strategy
#     if tariff_type.upper() == 'TOU':
#         if current_tariff_period.lower() == 'peak':
#             tariff_factor = 1.0  # Full discharge during peak for cost savings
#         else:
#             tariff_factor = 0.3  # Limited discharge during off-peak
#     else:
#         tariff_factor = 0.8  # General tariff - consistent discharge
#     
#     # Calculate recommended discharge
#     if excess_above_target_kw > 0:
#         # Target 80% of excess with 10% safety buffer
#         target_discharge = excess_above_target_kw * 0.8
#         recommended_discharge_kw = target_discharge * soc_factor * tariff_factor
#     else:
#         recommended_discharge_kw = 0
#     
#     # Calculate discharge multiplier
#     if demand_power_kw > 0:
#         discharge_multiplier = min(recommended_discharge_kw / demand_power_kw, 1.0)
#     else:
#         discharge_multiplier = 0
#     
#     # Predicted results
#     predicted_net_md = demand_power_kw - recommended_discharge_kw
#     safety_margin_kw = predicted_net_md - monthly_target_kw
#     
#     return {
#         'recommended_discharge_multiplier': discharge_multiplier,
#         'recommended_discharge_kw': recommended_discharge_kw,
#         'excess_above_target_kw': excess_above_target_kw,
#         'predicted_net_md_kw': predicted_net_md,
#         'safety_margin_kw': safety_margin_kw,
#         'strategy_description': f'Simple MD discharge: {recommended_discharge_kw:.1f}kW (Net MD: {predicted_net_md:.1f}kW)',
#         'discharge_strategy': 'simple_md_shaving'
#     }
# 
# 
# def _calculate_c_rate_limited_power_simple(current_soc_percent, max_power_rating_kw, battery_capacity_kwh, c_rate=1.0):
#     """
#     Simple C-rate power limitation for charging/discharging.
#     
#     Args:
#         current_soc_percent: Current state of charge percentage
#         max_power_rating_kw: Battery's rated power
#         battery_capacity_kwh: Battery's energy capacity
#         c_rate: Battery's C-rate (default 1.0C)
#         
#     Returns:
#         Dictionary with power limits
#     """
#     # Calculate C-rate based power limits
#     c_rate_power_limit = battery_capacity_kwh * c_rate
#     
#     # SOC-based derating (power reduces at extreme SOC levels)
#     if current_soc_percent > 90:
#         soc_factor = 0.8  # Reduce power at high SOC
#     elif current_soc_percent < 20:
#         soc_factor = 0.7  # Reduce power at low SOC
#     else:
#         soc_factor = 1.0  # Full power in normal SOC range
#     
#     # Final power limit is minimum of C-rate limit and rated power
#     effective_max_discharge_kw = min(c_rate_power_limit, max_power_rating_kw) * soc_factor
#     effective_max_charge_kw = min(c_rate_power_limit, max_power_rating_kw) * soc_factor * 0.8  # Charging typically slower
#     
#     return {
#         'max_discharge_power_kw': effective_max_discharge_kw,
#         'max_charge_power_kw': effective_max_charge_kw,
#         'c_rate_power_limit_kw': c_rate_power_limit,
#         'soc_derating_factor': soc_factor,
#         'limiting_factor': 'C-rate' if c_rate_power_limit < max_power_rating_kw else 'Power Rating'
#     }
# 
# 
# def _get_tou_charging_urgency(current_timestamp, soc_percent, holidays=None):
#     """
#     Determine TOU charging urgency based on time until MD window and current SOC.
#     
#     TOU charging windows:
#     - Primary: 10 PM - 2 PM next day (overnight charging)
#     - Target: 95% SOC by 2 PM on weekdays for MD readiness
#     
#     Args:
#         current_timestamp: Current datetime
#         soc_percent: Current battery SOC percentage
#         holidays: Set of holiday dates
#     
#     Returns:
#         dict: Charging urgency information
#     """
#     from datetime import datetime, timedelta
#     
#     # Check if it's a charging window (10 PM - 2 PM next day)
#     hour = current_timestamp.hour
#     is_weekday = current_timestamp.weekday() < 5
#     is_holiday = holidays and current_timestamp.date() in holidays
#     
#     # TOU charging window: 10 PM to 2 PM next day
#     is_charging_window = hour >= 22 or hour < 14
#     
#     # Calculate time until next MD window (2 PM)
#     current_date = current_timestamp.date()
#     if hour < 14:
#         # Same day 2 PM
#         next_md_start = datetime.combine(current_date, datetime.min.time().replace(hour=14))
#     else:
#         # Next day 2 PM
#         next_day = current_date + timedelta(days=1)
#         next_md_start = datetime.combine(next_day, datetime.min.time().replace(hour=14))
#     
#     # Only consider weekday MD windows
#     while next_md_start.weekday() >= 5 or (holidays and next_md_start.date() in holidays):
#         next_md_start += timedelta(days=1)
#         next_md_start = next_md_start.replace(hour=14, minute=0, second=0, microsecond=0)
#     
#     time_until_md = next_md_start - current_timestamp
#     hours_until_md = time_until_md.total_seconds() / 3600
#     
#     # Determine charging urgency
#     urgency_level = 'normal'
#     charge_rate_multiplier = 1.0
#     
#     if hours_until_md <= 4:  # Less than 4 hours until MD window
#         if soc_percent < 95:
#             urgency_level = 'critical'
#             charge_rate_multiplier = 1.5  # Aggressive charging
#     elif hours_until_md <= 8:  # 4-8 hours until MD window
#         if soc_percent < 90:
#             urgency_level = 'high'
#             charge_rate_multiplier = 1.2  # Enhanced charging
#     elif hours_until_md <= 16:  # 8-16 hours until MD window
#         if soc_percent < 80:
#             urgency_level = 'normal'
#             charge_rate_multiplier = 1.0  # Standard charging
#     
#     return {
#         'is_charging_window': is_charging_window,
#         'hours_until_md': hours_until_md,
#         'urgency_level': urgency_level,
#         'charge_rate_multiplier': charge_rate_multiplier,
#         'target_soc': 95,
#         'is_weekday': is_weekday and not is_holiday,
#         'next_md_start': next_md_start
#     }
# 
# 
# def _simulate_battery_operation_v2(df, power_col, monthly_targets, battery_sizing, battery_params, interval_hours, selected_tariff=None, holidays=None):
#     """
#     V2-specific battery simulation that ensures Net Demand NEVER goes below monthly targets.
#     
#     Key V2 Innovation: Monthly targets act as FLOOR values for Net Demand.
#     - Net Demand must stay ABOVE or EQUAL to the monthly target at all times
#     - Battery discharge is limited to keep Net Demand >= Monthly Target
#     - Uses dynamic monthly targets instead of static target
#     - TOU ENHANCEMENT: Special charging precondition for TOU tariffs (95% SOC by 2PM)
#     
#     Args:
#         df: Energy data DataFrame with datetime index
#         power_col: Name of power demand column
#         monthly_targets: Series with Period index containing monthly targets
#         battery_sizing: Dictionary with capacity_kwh, power_rating_kw
#         battery_params: Dictionary with efficiency, depth_of_discharge
#         interval_hours: Time interval in hours (e.g., 0.25 for 15-min)
#         selected_tariff: Tariff configuration
#         holidays: Set of holiday dates
#         
#     Returns:
#         Dictionary with simulation results and V2-specific metrics
#     """
#     import numpy as np
#     import pandas as pd
#     
#     # ðŸ”‹ TOU PRECONDITION DETECTION
#     is_tou_tariff = False
#     tou_feedback_messages = []
#     
#     if selected_tariff:
#         tariff_type = selected_tariff.get('Type', '').lower()
#         tariff_name = selected_tariff.get('Tariff', '').lower()
#         is_tou_tariff = tariff_type == 'tou' or 'tou' in tariff_name
#         
#         if is_tou_tariff:
#             tou_feedback_messages.append("ðŸ”‹ TOU Tariff Detected - Implementing 95% SOC readiness requirement")
#             tou_feedback_messages.append("âš¡ Charging Window: 10 PM - 2 PM for MD readiness (2 PM - 10 PM)")
#     
#     # Create simulation dataframe
#     df_sim = df[[power_col]].copy()
#     df_sim['Original_Demand'] = df_sim[power_col]
#     
#     # V2 ENHANCEMENT: Create dynamic monthly target series for each timestamp
#     target_series = _create_v2_dynamic_target_series(df_sim.index, monthly_targets)
#     df_sim['Monthly_Target'] = target_series
#     df_sim['Excess_Demand'] = (df_sim[power_col] - df_sim['Monthly_Target']).clip(lower=0)
#     
#     # Battery state variables
#     battery_capacity = battery_sizing['capacity_kwh']
#     usable_capacity = battery_capacity * (battery_params['depth_of_discharge'] / 100)
#     max_power = battery_sizing['power_rating_kw']
#     efficiency = battery_params['round_trip_efficiency'] / 100
#     
#     # Initialize battery state
#     soc = np.zeros(len(df_sim))  # State of Charge in kWh
#     soc_percent = np.zeros(len(df_sim))  # SOC as percentage
#     battery_power = np.zeros(len(df_sim))  # Positive = discharge, Negative = charge
#     net_demand = df_sim[power_col].copy()
#     
#     # V2 SIMULATION LOOP - Monthly Target Floor Implementation
#     for i in range(len(df_sim)):
#         current_demand = df_sim[power_col].iloc[i]
#         monthly_target = df_sim['Monthly_Target'].iloc[i]
#         excess = max(0, current_demand - monthly_target)
#         current_timestamp = df_sim.index[i]
#         
#         # Determine if discharge is allowed based on tariff type
#         should_discharge = excess > 0
#         
#         if selected_tariff and should_discharge:
#             # Apply TOU logic for discharge decisions
#             tariff_type = selected_tariff.get('Type', '').lower()
#             tariff_name = selected_tariff.get('Tariff', '').lower()
#             is_tou_tariff = tariff_type == 'tou' or 'tou' in tariff_name
#             
#             if is_tou_tariff:
#                 # TOU tariffs: Only discharge during MD windows (2PM-10PM weekdays)
#                 should_discharge = (excess > 0) and is_md_window(current_timestamp, holidays)
#             # For General tariffs, discharge anytime above target (24/7 MD recording)
#         
#         if should_discharge:  # V2 ENHANCED DISCHARGE LOGIC - Monthly Target Floor with C-rate constraints
#             # V2 CRITICAL CONSTRAINT: Calculate maximum discharge that keeps Net Demand >= Monthly Target
#             max_allowable_discharge = current_demand - monthly_target
#             
#             # Get current SOC for C-rate calculations
#             current_soc_kwh = soc[i-1] if i > 0 else usable_capacity * 0.80  # Start at 80% SOC (within 5%-95% range)
#             current_soc_percent = (current_soc_kwh / usable_capacity) * 100
#             
#             # Get battery specifications with C-rate constraints
#             if hasattr(st.session_state, 'tabled_analysis_selected_battery'):
#                 battery_spec = st.session_state.tabled_analysis_selected_battery['spec']
#                 c_rate = battery_spec.get('c_rate', 1.0)
#             else:
#                 c_rate = 1.0  # Default C-rate
#             
#             # Calculate C-rate limited power
#             power_limits = _calculate_c_rate_limited_power_simple(
#                 current_soc_percent, max_power, battery_capacity, c_rate
#             )
#             max_discharge_power_c_rate = power_limits['max_discharge_power_kw']
#             
#             # Calculate required discharge power with ALL constraints
#             required_discharge = min(
#                 max_allowable_discharge,  # MD target constraint
#                 max_power,  # Battery power rating
#                 max_discharge_power_c_rate  # C-rate constraint
#             )
#             
#             # Check if battery has enough energy (with 5% minimum SOC safety protection)
#             available_energy = current_soc_kwh
#             min_soc_energy = usable_capacity * 0.05  # 5% minimum safety SOC
#             max_discharge_energy = max(0, available_energy - min_soc_energy)  # Don't discharge below 5%
#             max_discharge_power = min(max_discharge_energy / interval_hours, required_discharge)
#             
#             actual_discharge = max(0, max_discharge_power)
#             battery_power[i] = actual_discharge
#             soc[i] = current_soc_kwh - actual_discharge * interval_hours
#             
#             # V2 GUARANTEE: Net Demand = Original Demand - Discharge, but NEVER below Monthly Target
#             net_demand_candidate = current_demand - actual_discharge
#             net_demand.iloc[i] = max(net_demand_candidate, monthly_target)
#             
#         else:  # Can charge battery if there's room and low demand
#             if i > 0:
#                 soc[i] = soc[i-1]
#             else:
#                 soc[i] = usable_capacity * 0.8
#             
#             # Enhanced charging logic with TOU precondition support
#             current_time = df_sim.index[i]
#             hour = current_time.hour
#             soc_percentage = (soc[i] / usable_capacity) * 100
#             
#             # Calculate dynamic demand thresholds based on recent patterns
#             lookback_periods = min(96, len(df_sim))  # 24 hours of 15-min data or available
#             start_idx = max(0, i - lookback_periods)
#             recent_demand = df_sim[power_col].iloc[start_idx:i+1]
#             
#             if len(recent_demand) > 0:
#                 avg_demand = recent_demand.mean()
#                 demand_25th = recent_demand.quantile(0.25)
#             else:
#                 avg_demand = df_sim[power_col].mean()
#                 demand_25th = avg_demand * 0.6
#             
#             # ðŸ”‹ TOU PRECONDITION LOGIC
#             should_charge = False
#             charge_rate_factor = 0.3  # Default conservative rate
#             tou_charging_active = False
#             
#             if is_tou_tariff:
#                 # Get TOU charging urgency
#                 tou_info = _get_tou_charging_urgency(current_time, soc_percentage, holidays)
#                 
#                 # TOU SPECIAL CHARGING LOGIC
#                 if tou_info['is_charging_window'] and tou_info['is_weekday']:
#                     tou_charging_active = True
#                     
#                     # TOU charging conditions based on urgency (standardized to 95% max SOC)
#                     if tou_info['urgency_level'] == 'critical':
#                         # CRITICAL: Must charge aggressively - less than 4 hours to MD window
#                         should_charge = (soc_percentage < 95) and (current_demand < avg_demand * 1.2)
#                         charge_rate_factor = min(1.0, 0.8 * tou_info['charge_rate_multiplier'])  # Up to 1.0x (max power)
#                         
#                         if i % 4 == 0:  # Log every 4 intervals (1 hour for 15-min data)
#                             tou_feedback_messages.append(f"ðŸš¨ CRITICAL TOU Charging: {tou_info['hours_until_md']:.1f}h until MD window, SOC: {soc_percentage:.1f}%")
#                             
#                     elif tou_info['urgency_level'] == 'high':
#                         # HIGH: Enhanced charging - 4-8 hours to MD window (standardized to 95% max SOC)
#                         should_charge = (soc_percentage < 95) and (current_demand < avg_demand * 1.0)
#                         charge_rate_factor = 0.6 * tou_info['charge_rate_multiplier']
#                         
#                         if i % 8 == 0:  # Log every 8 intervals
#                             tou_feedback_messages.append(f"âš¡ HIGH TOU Charging: {tou_info['hours_until_md']:.1f}h until MD window, SOC: {soc_percentage:.1f}%")
#                             
#                     else:
#                         # NORMAL: Standard overnight charging (standardized to 95% max SOC)
#                         should_charge = (soc_percentage < 95) and (current_demand < avg_demand * 0.8)
#                         charge_rate_factor = 0.5
#                         
#                         if i % 16 == 0:  # Log every 16 intervals
#                             tou_feedback_messages.append(f"ðŸ”‹ Standard TOU Charging: {tou_info['hours_until_md']:.1f}h until MD window, SOC: {soc_percentage:.1f}%")
#                 
#                 # Outside TOU charging window - use standard tariff-aware logic
#                 if not tou_charging_active:
#                     monthly_target = df_sim['Monthly_Target'].iloc[i]
#                     is_md_period = is_md_window(current_time, holidays)
#                     
#                     # Standard SOC-based charging with tariff awareness (updated for 5% min safety SOC)
#                     if soc_percentage < 10:  # Very low SOC - emergency charging (updated from 30%)
#                         should_charge = current_demand < avg_demand * 0.9
#                         charge_rate_factor = 0.8
#                     elif soc_percentage < 60:  # Low SOC
#                         if not is_md_period:
#                             should_charge = current_demand < avg_demand * 0.8
#                             charge_rate_factor = 0.6
#                         else:
#                             should_charge = current_demand < demand_25th * 1.2
#                             charge_rate_factor = 0.4
#                     elif soc_percentage < 95:  # Normal operation (standardized to 95% max SOC)
#                         if not is_md_period:
#                             should_charge = current_demand < avg_demand * 0.7
#                             charge_rate_factor = 0.5
#                         else:
#                             should_charge = current_demand < demand_25th
#                             charge_rate_factor = 0.3
#             
#             else:
#                 # ðŸ”Œ STANDARD GENERAL TARIFF LOGIC (24/7 MD recording)
#                 monthly_target = df_sim['Monthly_Target'].iloc[i]
#                 is_md_period = is_md_window(current_time, holidays)
#                 
#                 # Very low SOC - charge aggressively regardless of period (updated for 5% min safety SOC)
#                 if soc_percentage < 10:  # Updated from 30% to 10% for emergency charging only
#                     should_charge = current_demand < avg_demand * 0.9  # Lenient threshold
#                     charge_rate_factor = 0.8  # Higher charge rate
#                 # Low SOC - moderate charging with tariff awareness
#                 elif soc_percentage < 60:
#                     if not is_md_period:  # âœ… RP4 Off-peak (all times except 2PM-10PM weekdays)
#                         should_charge = current_demand < avg_demand * 0.8
#                         charge_rate_factor = 0.6
#                     else:  # âœ… RP4 Peak (2PM-10PM weekdays) - MD recording window
#                         should_charge = current_demand < demand_25th * 1.2
#                         charge_rate_factor = 0.4
#                 # Normal SOC - conservative charging with full tariff awareness
#                 elif soc_percentage < 95:  # Standardized 95% target for both TOU and General tariffs
#                     if not is_md_period:  # âœ… RP4 Off-peak periods
#                         should_charge = current_demand < avg_demand * 0.7
#                         charge_rate_factor = 0.5
#                     else:  # âœ… RP4 Peak periods - very selective
#                         should_charge = current_demand < demand_25th
#                         charge_rate_factor = 0.3
#             
#             # Execute charging if conditions are met
#             max_soc_target = 0.95 if is_tou_tariff else 0.95  # Both use 95% now, but TOU is more aggressive
#             
#             if should_charge and soc[i] < usable_capacity * max_soc_target:
#                 # V2 SMART MD CONSTRAINT: Only apply MD target constraint during MD recording periods
#                 is_md_recording_period = is_md_window(current_time, holidays)
#                 
#                 if is_md_recording_period:
#                     # During MD periods: Limit charging to keep Net Demand <= Monthly Target
#                     max_allowable_charging_for_md = max(0, monthly_target - current_demand)
#                 else:
#                     # During OFF-PEAK periods: Allow unrestricted charging (essential for nighttime charging)
#                     max_allowable_charging_for_md = max_power  # No MD constraint during off-peak
#                 
#                 # Get battery specifications with C-rate constraints
#                 if hasattr(st.session_state, 'tabled_analysis_selected_battery'):
#                     battery_spec = st.session_state.tabled_analysis_selected_battery['spec']
#                     c_rate = battery_spec.get('c_rate', 1.0)
#                 else:
#                     c_rate = 1.0  # Default C-rate
#                 
#                 # Calculate C-rate limited power
#                 power_limits = _calculate_c_rate_limited_power_simple(
#                     soc_percentage, max_power, battery_capacity, c_rate
#                 )
#                 max_charge_power_c_rate = power_limits['max_charge_power_kw']
#                 
#                 # Calculate charge power with ALL constraints
#                 remaining_capacity = usable_capacity * 0.95 - soc[i]
#                 max_charge_energy = remaining_capacity / efficiency
#                 
#                 # V2 ENHANCED CHARGING POWER CALCULATION with all constraints
#                 unconstrained_charge_power = min(
#                     max_power * charge_rate_factor,  # Dynamic charging rate
#                     max_charge_energy / interval_hours,  # Energy constraint
#                     remaining_capacity / interval_hours / efficiency,  # Don't exceed 95% SOC
#                     max_charge_power_c_rate  # C-rate constraint
#                 )
#                 
#                 # V2 MD TARGET CONSTRAINT: Ensure Net Demand doesn't exceed monthly target
#                 md_constrained_charge_power = min(
#                     unconstrained_charge_power,
#                     max_allowable_charging_for_md
#                 )
#                 
#                 final_charge_power = max(0, md_constrained_charge_power)
#                 
#                 if final_charge_power > 0:
#                     # Apply charging
#                     battery_power[i] = -final_charge_power  # Negative for charging
#                     soc[i] = soc[i] + final_charge_power * interval_hours * efficiency
#                     
#                     # V2 SMART NET DEMAND CALCULATION: Different logic for MD vs Off-Peak periods
#                     if is_md_recording_period:
#                         # During MD periods: Net Demand = Current Demand + Charging, but NEVER above Monthly Target
#                         net_demand_candidate = current_demand + final_charge_power
#                         net_demand.iloc[i] = min(net_demand_candidate, monthly_target)
#                     else:
#                         # During Off-Peak periods: Net Demand = Current Demand + Charging (no MD constraint)
#                         net_demand.iloc[i] = current_demand + final_charge_power
#                         
#                     # Add debug feedback for significant charging events
#                     if final_charge_power > 50 and i % 8 == 0:  # Log every 8 intervals for large charging
#                         period_type = "MD" if is_md_recording_period else "Off-Peak"
#                         tou_feedback_messages.append(f"ðŸ”‹ Charging {final_charge_power:.1f}kW during {period_type} period, SOC: {soc_percentage:.1f}% â†’ {(soc[i]/usable_capacity)*100:.1f}%")
#                         
#                 else:
#                     # No charging possible
#                     net_demand.iloc[i] = current_demand
#                     
#                     # Debug feedback for why charging didn't occur (only for low SOC)
#                     if soc_percentage < 50 and i % 16 == 0:  # Log every 16 intervals
#                         period_type = "MD" if is_md_recording_period else "Off-Peak" 
#                         if not should_charge:
#                             tou_feedback_messages.append(f"â¸ï¸ No charging: demand too high ({current_demand:.0f}kW > threshold) during {period_type}, SOC: {soc_percentage:.1f}%")
#                         elif max_allowable_charging_for_md <= 0:
#                             tou_feedback_messages.append(f"â¸ï¸ No charging: MD constraint ({current_demand:.0f}kW > {monthly_target:.0f}kW target) during {period_type}, SOC: {soc_percentage:.1f}%")
#             else:
#                 # No charging conditions met
#                 net_demand.iloc[i] = current_demand
#         
#         # Ensure SOC stays within 5%-95% limits for standardized battery protection
#         soc[i] = max(usable_capacity * 0.05, min(soc[i], usable_capacity * 0.95))
#         soc_percent[i] = (soc[i] / usable_capacity) * 100
#     
#     # Add V2 simulation results to dataframe
#     df_sim['Battery_Power_kW'] = battery_power
#     df_sim['Battery_SOC_kWh'] = soc
#     df_sim['Battery_SOC_Percent'] = soc_percent
#     df_sim['Net_Demand_kW'] = net_demand
#     df_sim['Peak_Shaved'] = df_sim['Original_Demand'] - df_sim['Net_Demand_kW']
#     
#     # V2 VALIDATION: Ensure Net Demand never goes below monthly targets
#     violations = df_sim[df_sim['Net_Demand_kW'] < df_sim['Monthly_Target']]
#     if len(violations) > 0:
#         st.warning(f"âš ï¸ V2 Constraint Violation: {len(violations)} intervals where Net Demand < Monthly Target detected!")
#     
#     # Calculate V2 performance metrics
#     total_energy_discharged = sum([p * interval_hours for p in battery_power if p > 0])
#     total_energy_charged = sum([abs(p) * interval_hours for p in battery_power if p < 0])
#     
#     # ðŸ”‹ TOU READINESS VALIDATION
#     tou_readiness_stats = {}
#     
#     if is_tou_tariff:
#         # Check 2 PM readiness on weekdays
#         weekday_2pm_data = df_sim[
#             (df_sim.index.hour == 14) & 
#             (df_sim.index.minute == 0) &
#             (df_sim.index.to_series().apply(lambda ts: ts.weekday() < 5 and (not holidays or ts.date() not in holidays)))
#         ]
#         
#         if len(weekday_2pm_data) > 0:
#             ready_days = len(weekday_2pm_data[weekday_2pm_data['Battery_SOC_Percent'] >= 95])
#             total_weekdays = len(weekday_2pm_data)
#             readiness_rate = (ready_days / total_weekdays * 100) if total_weekdays > 0 else 0
#             
#             avg_soc_at_2pm = weekday_2pm_data['Battery_SOC_Percent'].mean()
#             min_soc_at_2pm = weekday_2pm_data['Battery_SOC_Percent'].min()
#             
#             tou_readiness_stats = {
#                 'ready_days': ready_days,
#                 'total_weekdays': total_weekdays,
#                 'readiness_rate_percent': readiness_rate,
#                 'avg_soc_at_2pm': avg_soc_at_2pm,
#                 'min_soc_at_2pm': min_soc_at_2pm,
#                 'target_soc': 95
#             }
#             
#             # Add success/warning messages
#             if readiness_rate >= 95:
#                 tou_feedback_messages.append(f"âœ… Excellent TOU Readiness: {readiness_rate:.1f}% days ready at 2 PM")
#             elif readiness_rate >= 85:
#                 tou_feedback_messages.append(f"âœ… Good TOU Readiness: {readiness_rate:.1f}% days ready at 2 PM")
#             elif readiness_rate >= 70:
#                 tou_feedback_messages.append(f"âš ï¸ Moderate TOU Readiness: {readiness_rate:.1f}% days ready at 2 PM")
#             else:
#                 tou_feedback_messages.append(f"ðŸš¨ Poor TOU Readiness: {readiness_rate:.1f}% days ready at 2 PM - Consider larger battery")
#                 
#             if min_soc_at_2pm < 80:
#                 tou_feedback_messages.append(f"âš ï¸ Minimum 2 PM SOC: {min_soc_at_2pm:.1f}% - Risk of inadequate MD preparation")
#         else:
#             tou_feedback_messages.append("âš ï¸ No weekday 2 PM data available for readiness analysis")
#     
#     # Store TOU feedback for display
#     if len(tou_feedback_messages) > 0:
#         # Display TOU messages using streamlit if available
#         try:
#             for msg in tou_feedback_messages[-5:]:  # Show last 5 messages to avoid clutter
#                 if "ðŸš¨" in msg or "âš ï¸" in msg:
#                     st.warning(msg)
#                 elif "âœ…" in msg:
#                     st.success(msg)
#                 else:
#                     st.info(msg)
#         except ImportError:
#             pass  # Streamlit not available
#     
#     # V2 Peak reduction using monthly targets (not static) - IMPROVED HIERARCHY
#     df_md_peak_for_reduction = df_sim[df_sim.index.to_series().apply(lambda ts: is_md_window(ts, holidays))]
#     
#     if len(df_md_peak_for_reduction) > 0:
#         # V2 CALCULATION: Peak reduction against monthly targets
#         daily_reduction_analysis = df_md_peak_for_reduction.groupby(df_md_peak_for_reduction.index.date).agg({
#             'Original_Demand': 'max',
#             'Net_Demand_kW': 'max',
#             'Monthly_Target': 'first'  # V2: Get monthly target for each day
#         }).reset_index()
#         daily_reduction_analysis.columns = ['Date', 'Original_Peak_MD', 'Net_Peak_MD', 'Monthly_Target']
#         
#         # V2 Peak reduction: Original - Net (with monthly target context)
#         daily_reduction_analysis['Peak_Reduction'] = daily_reduction_analysis['Original_Peak_MD'] - daily_reduction_analysis['Net_Peak_MD']
#         peak_reduction = daily_reduction_analysis['Peak_Reduction'].max()
#     else:
#         # Fallback calculation
#         peak_reduction = df_sim['Original_Demand'].max() - df_sim['Net_Demand_kW'].max()
#     
#     # Initialize V2 debug information
#     debug_info = {
#         'total_points': len(df_sim),
#         'monthly_targets_used': len(monthly_targets),
#         'constraint_violations': len(violations),
#         'sample_timestamps': df_sim.index[:3].tolist() if len(df_sim) > 0 else [],
#         'v2_methodology': 'Monthly targets as floor constraints with synchronized success rate'
#     }
#     
#     # V2 MD-focused success rate using synchronized calculation function - IMPROVED HIERARCHY
#     df_md_peak = df_sim[df_sim.index.to_series().apply(lambda ts: is_md_window(ts, holidays))]
#     
#     # Add Success_Status column for synchronized calculation
#     df_sim['Success_Status'] = df_sim.apply(lambda row: _get_comprehensive_battery_status(row, holidays), axis=1)
#     
#     if len(df_md_peak) > 0:
#         # Use synchronized success rate calculation
#         success_metrics = _calculate_success_rate_from_shaving_status(df_sim, holidays=holidays)
#         success_rate = success_metrics['success_rate_percent']
#         successful_days = success_metrics['successful_intervals']
#         total_days = success_metrics['total_md_intervals']
#         md_focused_calculation = True
#         
#         # V2 DAILY ANALYSIS: Still needed for peak reduction calculation
#         daily_md_analysis = df_md_peak.groupby(df_md_peak.index.date).agg({
#             'Original_Demand': 'max',
#             'Net_Demand_kW': 'max',
#             'Monthly_Target': 'first'
#         }).reset_index()
#         daily_md_analysis.columns = ['Date', 'Original_Peak_MD', 'Net_Peak_MD', 'Monthly_Target']
#         daily_md_analysis['Success'] = daily_md_analysis['Net_Peak_MD'] <= daily_md_analysis['Monthly_Target'] * 1.05
#         
#         # Store synchronized debug info
#         debug_info['md_calculation_details'] = {
#             'calculation_method': success_metrics['calculation_method'],
#             'md_period_logic': success_metrics['md_period_logic'],
#             'successful_intervals': successful_days,
#             'total_md_intervals': total_days,
#             'success_rate_percent': success_rate,
#             'synchronized': True
#         }
#     else:
#         # Fallback: Use synchronized calculation even without MD peak data
#         success_metrics = _calculate_success_rate_from_shaving_status(df_sim, holidays=holidays)
#         success_rate = success_metrics['success_rate_percent']
#         successful_days = success_metrics['successful_intervals']
#         total_days = success_metrics['total_md_intervals']
#         md_focused_calculation = False
#         
#         debug_info['md_calculation_details'] = {
#             'calculation_method': success_metrics['calculation_method'],
#             'successful_intervals': successful_days,
#             'total_intervals': total_days,
#             'synchronized': True
#         }
#     
#     # V2 RETURN RESULTS with monthly target context and TOU readiness
#     results = {
#         'df_simulation': df_sim,
#         'total_energy_discharged': total_energy_discharged,
#         'total_energy_charged': total_energy_charged,
#         'peak_reduction_kw': peak_reduction,
#         'success_rate_percent': success_rate,
#         'successful_shaves': successful_days,
#         'total_peak_events': total_days,
#         'average_soc': np.mean(soc_percent),
#         'min_soc': np.min(soc_percent),
#         'max_soc': np.max(soc_percent),
#         'md_focused_calculation': md_focused_calculation,
#         'v2_constraint_violations': len(violations),
#         'monthly_targets_count': len(monthly_targets),
#         'debug_info': debug_info
#     }
#     
#     # Add TOU-specific results if TOU tariff is detected
#     if is_tou_tariff:
#         results.update({
#             'is_tou_tariff': True,
#             'tou_readiness_stats': tou_readiness_stats,
#             'tou_feedback_messages': tou_feedback_messages
#         })
#     else:
#         results['is_tou_tariff'] = False
#     
#     return results
# 
# 
# # ===================================================================================================
# # SINGLE SOURCE OF TRUTH: V2 Battery Simulation Function
# # ENHANCED VERSION REMOVED - Using simplified approach for maintainability
# # ===================================================================================================
# 
# 
# # ===================================================================================================
# # V2 ENHANCED SHAVING SUCCESS CLASSIFICATION
# # ===================================================================================================
# 
# def _get_simplified_battery_status(row, holidays=None):
#     """
#     Simplified 4-category battery status classification: Success, Partial, Failed, or Not Applicable.
#     
#     This replaces the overly complex 24-category system with a clean, actionable classification
#     focused on MD shaving effectiveness during billing periods only.
#     
#     Categories:
#     - âœ… Success: Complete MD shaving achieved or no action needed
#     - ðŸŸ¡ Partial: Some shaving achieved but not complete  
#     - ðŸ”´ Failed: Should have shaved but couldn't or failed completely
#     - âšª Not Applicable: Outside MD billing window (off-peak periods for TOU)
#     
#     Args:
#         row: DataFrame row with simulation data
#         holidays: Set of holiday dates to exclude from MD period determination
#         
#     Returns:
#         str: Simplified operational status (Success/Partial/Failed/Not Applicable)
#     """
#     original_demand = row['Original_Demand']
#     net_demand = row['Net_Demand_kW'] 
#     monthly_target = row['Monthly_Target']
#     battery_power = row.get('Battery_Power_kW', 0)  # Positive = discharge, negative = charge
#     soc_percent = row.get('Battery_SOC_Percent', 100)
#     
#     # Check if this is an MD billing period (weekdays 2PM-10PM, excluding holidays)
#     is_md_window = False
#     if row.name.weekday() < 5:  # Weekday check first
#         if not (holidays and row.name.date() in holidays):  # Holiday check
#             if 14 <= row.name.hour < 22:  # Hour check (2PM-10PM)
#                 is_md_window = True
#     
#     # Only classify periods that affect MD billing
#     if not is_md_window:
#         return 'âšª Not Applicable'  # Off-peak periods don't affect MD charges
#     
#     # ==========================================
#     # MD PERIOD CLASSIFICATION (Simplified)
#     # ==========================================
#     
#     # No intervention needed - already below target
#     if original_demand <= monthly_target:
#         return 'âœ… Success'
#     
#     # Critical battery issues that prevent operation
#     if soc_percent < 5:  # Below safety minimum
#         return 'ðŸ”´ Failed'
#     
#     # Battery attempted discharge during MD period
#     if battery_power > 0:
#         excess_before = original_demand - monthly_target
#         excess_after = max(0, net_demand - monthly_target)
#         reduction_achieved = excess_before - excess_after
#         reduction_percentage = (reduction_achieved / excess_before * 100) if excess_before > 0 else 0
#         
#         # Complete success - got demand to target level
#         if net_demand <= monthly_target * 1.05:  # 5% tolerance
#             return 'âœ… Success'
#         
#         # Partial success - some reduction but not complete
#         elif reduction_percentage >= 20:  # At least 20% reduction
#             return 'ðŸŸ¡ Partial'
#         
#         # Minimal or no impact
#         else:
#             return 'ðŸ”´ Failed'
#     
#     else:
#         # Should have discharged during MD period but didn't
#         if soc_percent < 25:  # Low SOC prevented discharge
#             return 'ðŸ”´ Failed'
#         else:  # Battery available but didn't discharge
#             return 'ðŸ”´ Failed'
# 
# 
# # Keep backward compatibility alias
# def _get_comprehensive_battery_status(row, holidays=None):
#     """Backward compatibility alias for the simplified battery status function."""
#     return _get_simplified_battery_status(row, holidays)
# 
# 
# # Alias for backward compatibility
# def _get_enhanced_shaving_success(row, holidays=None):
#     """Backward compatibility alias for the comprehensive battery status function."""
#     return _get_comprehensive_battery_status(row, holidays)
# 
# 
# def _calculate_success_rate_from_shaving_status(df_sim, holidays=None, debug=False):
#     """
#     Calculate success rate from the 6-category Success_Status classification with MD Period as primary gate.
#     
#     This function provides the single source of truth for success rate calculations across the application.
#     It ensures consistency between the detailed Success_Status column and all success rate metrics.
#     
#     MD Period Integration:
#     - Primary Gate: Only MD recording periods (weekdays 2PM-10PM, excluding holidays) are considered
#     - Success Criteria: Only âœ… Complete Success and ðŸŸ¢ No Action Needed count as successful
#     - Off-peak periods and holidays are excluded from success rate calculations
#     
#     Args:
#         df_sim: DataFrame with simulation results containing Success_Status or shaving success data
#         holidays: Set of holiday dates to exclude from MD period determination
#         debug: Boolean to enable debug output showing calculation details
#     
#     Returns:
#         dict: Success rate metrics with detailed breakdown
#     """
#     if df_sim is None or len(df_sim) == 0:
#         return {
#             'success_rate_percent': 0.0,
#             'total_md_intervals': 0,
#             'successful_intervals': 0,
#             'calculation_method': 'Empty dataset',
#             'md_period_logic': 'Weekdays 2PM-10PM (primary gate)'
#         }
#     
#     # Ensure we have Success_Status column or create it
#     if 'Success_Status' not in df_sim.columns:
#         if 'Shaving_Success' in df_sim.columns:
#             # Use existing Shaving_Success column
#             status_column = 'Shaving_Success'
#         else:
#             # Create Success_Status using the enhanced classification
#             df_sim = df_sim.copy()
#             df_sim['Success_Status'] = df_sim.apply(_get_enhanced_shaving_success, axis=1)
#             status_column = 'Success_Status'
#     else:
#         status_column = 'Success_Status'
#     
#     # MD PERIOD PRIMARY GATE: Filter for MD recording periods only
#     def is_md_period(timestamp):
#         """
#         Determine if timestamp falls within MD recording periods.
#         Primary gate for success rate calculation.
#         
#         Improved Hierarchy: Holiday Check â†’ Weekday Check â†’ Hour Check
#         This clearer flow makes the logic more maintainable for both General and TOU tariffs.
#         """
#         # 1. HOLIDAY CHECK (first priority - clearest exclusion)
#         if holidays and timestamp.date() in holidays:
#             return False
#         
#         # 2. WEEKDAY CHECK (second priority - excludes weekends)
#         if timestamp.weekday() >= 5:  # Weekend (Saturday=5, Sunday=6)
#             return False
#         
#         # 3. HOUR CHECK (final constraint - MD recording window)
#         if not (14 <= timestamp.hour < 22):  # Outside 2PM-10PM range
#             return False
#         
#         return True
#     
#     # Apply MD Period primary gate
#     md_period_mask = df_sim.index.to_series().apply(is_md_period)
#     df_md_only = df_sim[md_period_mask]
#     
#     if len(df_md_only) == 0:
#         return {
#             'success_rate_percent': 0.0,
#             'total_md_intervals': 0,
#             'successful_intervals': 0,
#             'calculation_method': 'No MD period data found',
#             'md_period_logic': 'Weekdays 2PM-10PM (primary gate)',
#             'excluded_intervals': len(df_sim),
#             'exclusion_reasons': 'All intervals outside MD periods'
#         }
#     
#     # SUCCESS CRITERIA: Count successful intervals using simplified 4-category system
#     # Only âœ… Success counts as successful in the simplified system
#     successful_statuses = ['âœ… Success']
#     
#     # Count successful intervals
#     successful_intervals = 0
#     for idx, row in df_md_only.iterrows():
#         status = str(row[status_column])
#         if status in successful_statuses:
#             successful_intervals += 1
#     
#     total_md_intervals = len(df_md_only)
#     success_rate_percent = (successful_intervals / total_md_intervals * 100) if total_md_intervals > 0 else 0.0
#     
#     # Status breakdown for debugging
#     status_counts = df_md_only[status_column].value_counts().to_dict()
#     
#     # Calculate breakdown by simplified categories
#     category_breakdown = {
#         'Success': sum(1 for status in df_md_only[status_column] if 'âœ… Success' in str(status)),
#         'Partial': sum(1 for status in df_md_only[status_column] if 'ðŸŸ¡ Partial' in str(status)),
#         'Failed': sum(1 for status in df_md_only[status_column] if 'ðŸ”´ Failed' in str(status)),
#         'Not_Applicable': sum(1 for status in df_md_only[status_column] if 'âšª Not Applicable' in str(status))
#     }
#     
#     result = {
#         'success_rate_percent': success_rate_percent,
#         'total_md_intervals': total_md_intervals,
#         'successful_intervals': successful_intervals,
#         'calculation_method': 'MD Period gated with simplified 4-category system',
#         'md_period_logic': 'Weekdays 2PM-10PM (primary gate)',
#         'successful_statuses': successful_statuses,
#         'status_breakdown': status_counts,
#         'category_breakdown': category_breakdown,
#         'excluded_intervals': len(df_sim) - total_md_intervals,
#         'total_intervals': len(df_sim)
#     }
#     
#     if debug:
#         import streamlit as st
#         st.info(f"""
#         ðŸ” **Success Rate Calculation Debug Info (Simplified 4-Category System):**
#         - **MD Period Gate**: {total_md_intervals} intervals during weekdays 2PM-10PM
#         - **Excluded**: {len(df_sim) - total_md_intervals} intervals outside MD periods
#         - **Successful**: {successful_intervals} intervals (âœ… Success only)
#         - **Success Rate**: {success_rate_percent:.1f}%
#         
#         **Simplified Category Breakdown:**
#         {chr(10).join([f"  - {category}: {count}" for category, count in result['category_breakdown'].items()])}
#         
#         **Detailed Status Breakdown:**
#         {chr(10).join([f"  - {status}: {count}" for status, count in status_counts.items()])}
#         """)
#     
#     return result
# 
# 
# # ===================================================================================================
# # NUMBER FORMATTING UTILITIES
# # ===================================================================================================
# 
# def _format_rm_value(value):
#     """
#     Format RM values according to specified rules:
#     - >= RM1: RM1,000,000.00 (with thousands separators and 2 decimal places)
#     - < RM1: RM0.0000 (with 4 decimal places)
#     """
#     if value >= 1:
#         return f"RM{value:,.2f}"
#     else:
#         return f"RM{value:.4f}"
# 
# def _format_number_value(value):
#     """
#     Format general numbers according to specified rules:
#     - >= 1: 1,000 (with thousands separators, no decimal places for integers)
#     - < 1: 0.00 (with 2 decimal places)
#     """
#     if value >= 1:
#         # Check if it's effectively an integer
#         if abs(value - round(value)) < 0.001:
#             return f"{int(round(value)):,}"
#         else:
#             return f"{value:,.1f}"
#     else:
#         return f"{value:.2f}"
# 
# # ===================================================================================================
# # V2 TABLE VISUALIZATION FUNCTIONS - Enhanced Battery Simulation Tables
# # ===================================================================================================
# 
# def _calculate_md_aware_target_violation(row, selected_tariff=None):
#     """
#     Calculate target violation considering MD recording periods and tariff type.
#     
#     Args:
#         row: DataFrame row containing simulation data
#         selected_tariff: Selected tariff configuration
#         
#     Returns:
#         str: Target violation status considering MD periods
#     """
#     net_demand = row.get('Net_Demand_kW', 0)
#     monthly_target = row.get('Monthly_Target', 0)
#     md_period = row.get('MD_Period', '')
#     
#     # Determine tariff type
#     tariff_type = 'General'  # Default
#     if selected_tariff:
#         tariff_name = selected_tariff.get('Tariff', '').lower()
#         tariff_type_field = selected_tariff.get('Type', '').lower()
#         is_tou_tariff = tariff_type_field == 'tou' or 'tou' in tariff_name
#         if is_tou_tariff:
#             tariff_type = 'TOU'
#     
#     # Calculate violation based on tariff type and MD period
#     if tariff_type == 'TOU':
#         # TOU: Only violations during Peak periods matter (MD recording periods)
#         if 'ðŸ”´ Peak' in md_period:
#             return 'âŒ' if net_demand > monthly_target else 'âœ…'
#         else:
#             return 'âšª Not Applicable'  # Off-peak periods don't affect MD
#     else:
#         # General: All violations matter (24/7 MD recording)
#         return 'âŒ' if net_demand > monthly_target else 'âœ…'
# 
# 
# def _calculate_target_shave_kw_holiday_aware(row, holidays=None):
#     """
#     Calculate target shave amount (kW) considering MD recording periods, tariff type, and holidays.
#     
#     This function determines how much power needs to be shaved during MD recording windows only.
#     MD charges only apply during specific periods, so shaving is only needed during those times.
#     
#     Args:
#         row: DataFrame row containing simulation data
#         holidays: Set of holiday dates (optional)
#         
#     Returns:
#         float: Target shave amount in kW (0.0 if outside MD window or on holidays)
#     """
#     # Get required data from row
#     original_demand = row.get('Original_Demand', 0)
#     monthly_target = row.get('Monthly_Target', 0)
#     
#     # Get timestamp from row index
#     timestamp = row.name
#     
#     # Check if this is a holiday
#     if holidays and timestamp.date() in holidays:
#         return 0.0  # No MD charges on holidays
#     
#     # Check if this is within MD recording window (2PM-10PM weekdays) - IMPROVED HIERARCHY
#     # Holiday check already performed above, now check weekday and hour
#     is_md_period = (timestamp.weekday() < 5 and 14 <= timestamp.hour < 22)
#     
#     if not is_md_period:
#         return 0.0  # No MD charges outside recording window
#     
#     # Calculate shave amount only during MD recording periods
#     return max(0.0, original_demand - monthly_target)
# 
# def _create_enhanced_battery_table(df_sim, selected_tariff=None, holidays=None):
#     """
#     Create enhanced table with health and C-rate information for time-series analysis.
#     
#     Args:
#         df_sim: Simulation dataframe with battery operation data
#         selected_tariff: Selected tariff configuration for MD-aware analysis
#         holidays: Set of holiday dates for MD-aware calculations
#         
#     Returns:
#         pd.DataFrame: Enhanced table with status indicators and detailed battery metrics
#     """
#     enhanced_columns = {
#         'Timestamp': df_sim.index.strftime('%Y-%m-%d %H:%M'),
#         'Original_Demand_kW': df_sim['Original_Demand'].round(1),
#         'Monthly_Target_kW': df_sim['Monthly_Target'].round(1),
#         'Battery_Action': df_sim['Battery_Power_kW'].apply(
#             lambda x: f"Discharge {x:.1f}kW" if x > 0 else f"Charge {abs(x):.1f}kW" if x < 0 else "Standby"
#         ),
#         'Success_Status': df_sim.apply(lambda row: _get_enhanced_shaving_success(row, holidays), axis=1),
#         'Net_Demand_kW': df_sim['Net_Demand_kW'].round(1),
#         'BESS_Balance_kWh': df_sim['Battery_SOC_kWh'].round(1),
#         'SOC_%': df_sim['Battery_SOC_Percent'].round(1),
#         'SOC_Status': df_sim['Battery_SOC_Percent'].apply(
#             lambda x: 'ðŸ”´ Critical' if x < 25 else 'ðŸŸ¡ Low' if x < 40 else 'ðŸŸ¢ Normal' if x < 80 else 'ðŸ”µ High'
#         ),
#         # NEW COLUMN 1: Total Charge / Discharge (kW) - Positive for charging, negative for discharging
#         'Charge (+ve)/Discharge (-ve) kW': df_sim['Battery_Power_kW'].apply(
#             lambda x: f"+{abs(x):.1f}" if x < 0 else f"-{x:.1f}" if x > 0 else "0.0"
#         ),
#         # NEW COLUMN 2: Target Shave (kW) - Amount that needs to be shaved during MD window only
#         'Target_Shave_kW': df_sim.apply(
#             lambda row: _calculate_target_shave_kw_holiday_aware(row, holidays), axis=1
#         ).round(1),
#         # NEW COLUMN 3: Actual Shave (kW) - Renamed from Peak_Shaved_kW
#         'Actual_Shave_kW': df_sim['Peak_Shaved'].round(1),
#         # MD Period classification - IMPROVED HIERARCHY (holidays handled by is_md_window)
#         'MD_Period': df_sim.index.map(lambda x: 'ðŸ”´ Peak' if is_md_window(x, holidays) else 'ðŸŸ¢ Off-Peak'),
#         'Target_Violation': df_sim.apply(lambda row: _calculate_md_aware_target_violation(row, selected_tariff), axis=1)
#     }
#     
#     return pd.DataFrame(enhanced_columns)
# 
# 
# def _create_daily_summary_table(df_sim, selected_tariff=None, interval_hours=None):
#     """
#     Create revised daily summary of battery performance with RP4 tariff-aware peak events analysis.
#     
#     Args:
#         df_sim: Simulation dataframe with battery operation data
#         selected_tariff: Selected tariff configuration for RP4 tariff-aware analysis
#         interval_hours: Time interval in hours (if None, will be detected dynamically)
#         
#     Returns:
#         pd.DataFrame: Daily performance summary with RP4 tariff-aware peak events analysis
#     """
#     if df_sim.empty:
#         return pd.DataFrame()
#     
#     # Get dynamic interval hours if not provided
#     if interval_hours is None:
#         interval_hours = _get_dynamic_interval_hours(df_sim)
#     
#     # Determine tariff type for RP4 tariff-aware analysis
#     is_tou_tariff = False
#     if selected_tariff:
#         tariff_name = selected_tariff.get('Tariff', '').lower()
#         tariff_type_field = selected_tariff.get('Type', '').lower()
#         is_tou_tariff = 'tou' in tariff_name or 'tou' in tariff_type_field or tariff_type_field == 'tou'
#     
#     # Get battery usable capacity for charging cycle calculation
#     battery_usable_capacity_kwh = 100  # Default fallback
#     if hasattr(st.session_state, 'tabled_analysis_selected_battery'):
#         selected_battery = st.session_state.tabled_analysis_selected_battery
#         quantity = getattr(st.session_state, 'tabled_analysis_battery_quantity', 1)
#         battery_spec = selected_battery['spec']
#         total_capacity = battery_spec.get('energy_kWh', 100) * quantity
#         depth_of_discharge = 80  # Default DoD
#         try:
#             # Try to get DoD from battery params if available
#             battery_params = getattr(st.session_state, 'battery_params', {})
#             depth_of_discharge = battery_params.get('depth_of_discharge', 80)
#         except:
#             pass
#         battery_usable_capacity_kwh = total_capacity * (depth_of_discharge / 100)
#     
#     # RP4 Tariff-Aware Peak Events Detection Logic
#     def is_peak_event_rp4(row):
#         """
#         Determine if this interval contains a peak event based on RP4 tariff logic:
#         - TOU Tariff: Peak events only during MD recording periods (2PM-10PM weekdays)
#         - General Tariff: Peak events anytime (24/7 MD recording)
#         """
#         timestamp = row.name
#         original_demand = row['Original_Demand']
#         monthly_target = row['Monthly_Target']
#         
#         # Check if demand exceeds monthly target
#         if original_demand <= monthly_target:
#             return False
#         
#         # Apply RP4 tariff-specific logic - IMPROVED HIERARCHY
#         if is_tou_tariff:
#             # TOU: Only count as peak event during MD recording window (2PM-10PM weekdays, excluding holidays)
#             # Note: This inline logic doesn't have holidays parameter, would need function call for complete accuracy
#             return (timestamp.weekday() < 5 and 14 <= timestamp.hour < 22)
#         else:
#             # General: Any time above target is a peak event (24/7 MD recording)
#             return True
#     
#     # Add peak event classification to dataframe
#     df_sim_analysis = df_sim.copy()
#     df_sim_analysis['Is_Peak_Event'] = df_sim_analysis.apply(is_peak_event_rp4, axis=1)
#     df_sim_analysis['Peak_Event_Excess'] = df_sim_analysis.apply(
#         lambda row: max(0, row['Original_Demand'] - row['Monthly_Target']) if row['Is_Peak_Event'] else 0, axis=1
#     )
#     
#     # Group by date for daily analysis - Get unique dates only
#     daily_summary = []
#     unique_dates = sorted(set(df_sim_analysis.index.date))
#     
#     for date in unique_dates:
#         day_data = df_sim_analysis[df_sim_analysis.index.date == date].copy()
#         
#         if len(day_data) == 0:
#             continue
#             
#         # 1. Date (YYYY-MM-DD)
#         date_str = date.strftime('%Y-%m-%d')
#         
#         # 2. Total Peak Events (Count Peak Events by following tariff aware follow RP4 tariff selection)
#         total_peak_events = int(day_data['Is_Peak_Event'].sum())
#         
#         # 3. General or TOU MD Excess (MD kW) - Maximum MD excess during peak events
#         tariff_label = "TOU" if is_tou_tariff else "General"
#         if total_peak_events > 0:
#             md_excess_kw = day_data[day_data['Is_Peak_Event']]['Peak_Event_Excess'].max()
#         else:
#             md_excess_kw = 0.0
#         
#         # 4. Total Energy Charge (kWh)
#         charging_intervals = day_data[day_data['Battery_Power_kW'] < 0]
#         total_energy_charge_kwh = abs(charging_intervals['Battery_Power_kW']).sum() * interval_hours  # Convert to kWh using dynamic interval
#         
#         # 5. Total Energy Discharge (kWh)
#         discharging_intervals = day_data[day_data['Battery_Power_kW'] > 0]
#         total_energy_discharge_kwh = discharging_intervals['Battery_Power_kW'].sum() * interval_hours  # Convert to kWh using dynamic interval
#         
#         # 6. Target MD Shave (kW) - Maximum target shaving required during peak events
#         if total_peak_events > 0:
#             target_md_shave_kw = day_data[day_data['Is_Peak_Event']]['Peak_Event_Excess'].max()
#         else:
#             target_md_shave_kw = 0.0
#         
#         # 7. Actual MD Shave (kW) - Maximum actual shaving achieved during peak events
#         if total_peak_events > 0:
#             peak_event_data = day_data[day_data['Is_Peak_Event']]
#             actual_md_shave_kw = (peak_event_data['Original_Demand'] - peak_event_data['Net_Demand_kW']).max()
#         else:
#             actual_md_shave_kw = 0.0
#         
#         # 8. Variance MD Shave (kW) (6. - 7.)
#         variance_md_shave_kw = target_md_shave_kw - actual_md_shave_kw
#         
#         # 9. Target_Success - Check if maximum net demand during peak events is within monthly target
#         if total_peak_events > 0:
#             peak_event_data = day_data[day_data['Is_Peak_Event']]
#             max_net_demand_during_peaks = peak_event_data['Net_Demand_kW'].max()
#             monthly_target = day_data['Monthly_Target'].iloc[0]
#             target_success = 'âœ…' if max_net_demand_during_peaks <= monthly_target * 1.05 else 'âŒ'  # 5% tolerance
#         else:
#             target_success = 'âœ…'  # No peak events means success by default
#         
#         # 10. CORRECTED Equivalent Full Cycles (EFC) - Throughput Method (Industry Standard)
#         # Step 1: Calculate total throughput (charge + discharge energy)
#         total_energy_throughput_kwh = total_energy_charge_kwh + total_energy_discharge_kwh
#         
#         # Step 2: Apply throughput method - EFC = Throughput Ã· (2 Ã— Usable Capacity)
#         # This is the industry-standard method used for battery warranties
#         efc_throughput = total_energy_throughput_kwh / (2 * battery_usable_capacity_kwh) if battery_usable_capacity_kwh > 0 else 0
#         
#         # Alternative calculation (Discharge-Only Method) for reference:
#         # efc_discharge_only = total_energy_discharge_kwh / battery_usable_capacity_kwh if battery_usable_capacity_kwh > 0 else 0
#         
#         # Use throughput method as primary (industry default for warranties)
#         equivalent_full_cycles = efc_throughput
#         
#         # Append daily summary with proper formatting
#         daily_summary.append({
#             'Date': date_str,
#             'Total Peak Events': _format_number_value(total_peak_events),
#             f'{tariff_label} MD Excess (kW)': _format_number_value(md_excess_kw),
#             'Total Energy Charge (kWh)': _format_number_value(total_energy_charge_kwh),
#             'Total Energy Discharge (kWh)': _format_number_value(total_energy_discharge_kwh),
#             'Target MD Shave (kW)': _format_number_value(target_md_shave_kw),
#             'Actual MD Shave (kW)': _format_number_value(actual_md_shave_kw),
#             'Variance MD Shave (kW)': _format_number_value(variance_md_shave_kw),
#             'Target_Success': target_success,
#             'Equivalent Full Cycles (EFC)': _format_number_value(equivalent_full_cycles),  # CORRECTED: Now uses proper EFC formula
#             'equivalent_full_cycles_raw': equivalent_full_cycles  # Store raw value for accumulation calculation
#         })
#     
#     # Convert to DataFrame for accumulating cycles calculation
#     df_summary = pd.DataFrame(daily_summary)
#     
#     # 11. NEW COLUMN: Accumulating Charging Cycles - Cumulative sum of daily EFC values
#     if len(df_summary) > 0:
#         # Calculate cumulative sum of raw EFC values
#         cumulative_cycles = df_summary['equivalent_full_cycles_raw'].cumsum()
#         
#         # Add formatted accumulating cycles column
#         df_summary['Accumulating Charging Cycles'] = [_format_number_value(x) for x in cumulative_cycles]
#         
#         # Remove the raw helper column
#         df_summary = df_summary.drop('equivalent_full_cycles_raw', axis=1)
#     
#     return df_summary
# 
# 
# def _create_monthly_summary_table(df_sim, selected_tariff=None, interval_hours=None):
#     """
#     Create monthly summary of battery performance with MD shaving effectiveness.
#     
#     Args:
#         df_sim: Simulation dataframe with battery operation data
#         selected_tariff: Selected tariff configuration for cost calculations
#         interval_hours: Time interval in hours (if None, will be detected dynamically)
#         
#     Returns:
#         pd.DataFrame: Monthly performance summary with cost calculations
#     """
#     if df_sim.empty:
#         return pd.DataFrame()
#     
#     # Get dynamic interval hours if not provided
#     if interval_hours is None:
#         interval_hours = _get_dynamic_interval_hours(df_sim)
#     
#     # Extract month-year from index
#     df_sim['YearMonth'] = df_sim.index.to_series().dt.to_period('M')
#     
#     # Get battery usable capacity for charging cycle calculation
#     battery_usable_capacity_kwh = 100  # Default fallback
#     if hasattr(st.session_state, 'tabled_analysis_selected_battery'):
#         selected_battery = st.session_state.tabled_analysis_selected_battery
#         quantity = getattr(st.session_state, 'tabled_analysis_battery_quantity', 1)
#         battery_spec = selected_battery['spec']
#         total_capacity = battery_spec.get('energy_kWh', 100) * quantity
#         depth_of_discharge = 80  # Default DoD
#         try:
#             battery_params = getattr(st.session_state, 'battery_params', {})
#             depth_of_discharge = battery_params.get('depth_of_discharge', 80)
#         except:
#             depth_of_discharge = 80
#         battery_usable_capacity_kwh = total_capacity * (depth_of_discharge / 100)
#     
#     # Determine tariff type for MD excess calculation
#     is_tou = False
#     md_rate_rm_per_kw = 97.06  # Default TOU rate
#     
#     if selected_tariff:
#         tariff_name = selected_tariff.get('Tariff', '').lower()
#         tariff_type = selected_tariff.get('Type', '').lower()
#         if 'tou' in tariff_name or 'tou' in tariff_type or tariff_type == 'tou':
#             is_tou = True
#         
#         # Get MD rate from tariff
#         rates = selected_tariff.get('Rates', {})
#         if rates:
#             md_rate_rm_per_kw = rates.get('Capacity Rate', 0) + rates.get('Network Rate', 0)
#             if md_rate_rm_per_kw == 0:
#                 md_rate_rm_per_kw = 97.06  # Fallback to default
#     
#     # FIXED: Correctly filter data based on tariff type
#     if is_tou:
#         # TOU: Calculate MD excess from TOU periods only (2-10 PM weekdays)
#         tou_mask = (df_sim.index.weekday < 5) & (df_sim.index.hour >= 14) & (df_sim.index.hour < 22)
#         df_md = df_sim[tou_mask].copy()
#         tariff_label = "TOU"
#     else:
#         # General: Calculate MD excess from all periods (24/7)
#         df_md = df_sim.copy()
#         tariff_label = "General"
#     
#     if df_md.empty:
#         return pd.DataFrame()
#     
#     # Calculate monthly charging cycles using full dataset (not just tariff-filtered)
#     monthly_cycles_data = []
#     for period in df_sim.groupby('YearMonth').groups.keys():
#         month_data = df_sim[df_sim['YearMonth'] == period]
#         
#         # Calculate total energy charge and discharge for the month
#         charging_intervals = month_data[month_data['Battery_Power_kW'] < 0]
#         discharging_intervals = month_data[month_data['Battery_Power_kW'] > 0]
#         
#         total_energy_charge_kwh = abs(charging_intervals['Battery_Power_kW']).sum() * interval_hours
#         total_energy_discharge_kwh = discharging_intervals['Battery_Power_kW'].sum() * interval_hours
#         
#         # CORRECTED EFC calculation - Throughput Method (Industry Standard)
#         # Step 1: Calculate total throughput for this month
#         total_energy_throughput_kwh = total_energy_charge_kwh + total_energy_discharge_kwh
#         
#         # Step 2: Apply throughput method - EFC = Throughput Ã· (2 Ã— Usable Capacity) 
#         # This matches battery manufacturer warranties and industry standards
#         equivalent_full_cycles = total_energy_throughput_kwh / (2 * battery_usable_capacity_kwh) if battery_usable_capacity_kwh > 0 else 0
#         
#         monthly_cycles_data.append({
#             'period': period,
#             'equivalent_full_cycles': equivalent_full_cycles  # CORRECTED: Now uses proper EFC formula
#         })
#     
#     # Convert to DataFrame for easier merging
#     cycles_df = pd.DataFrame(monthly_cycles_data).set_index('period')
#     
#     # Group by month and calculate tariff-specific MD values
#     monthly_data = df_md.groupby('YearMonth').agg({
#         'Original_Demand': 'max',  # Maximum demand in the tariff-specific periods
#         'Net_Demand_kW': 'max',    # Maximum net demand in the tariff-specific periods  
#         'Monthly_Target': 'first',
#         'Battery_Power_kW': lambda x: (x > 0).sum() * interval_hours,  # Total discharge hours using dynamic interval
#         'Battery_SOC_Percent': 'mean'
#     }).round(2)
#     
#     # Calculate MD excess and success shaved based on tariff-specific periods
#     monthly_data['MD_Excess_kW'] = (monthly_data['Original_Demand'] - monthly_data['Monthly_Target']).apply(lambda x: max(0, x))
#     monthly_data['Success_Shaved_kW'] = (monthly_data['Original_Demand'] - monthly_data['Net_Demand_kW']).apply(lambda x: max(0, x))  # Max Original - Max Net per month
#     monthly_data['Cost_Saving_RM'] = monthly_data['Success_Shaved_kW'] * md_rate_rm_per_kw
#     
#     # Merge EFC cycles data (corrected column name)
#     monthly_data = monthly_data.join(cycles_df, how='left')
#     monthly_data['equivalent_full_cycles'] = monthly_data['equivalent_full_cycles'].fillna(0)
#     
#     # Calculate Accumulating Charging Cycles for monthly summary
#     # This represents the cumulative EFC cycles up to the end of each month
#     cumulative_monthly_cycles = monthly_data['equivalent_full_cycles'].cumsum()
#     
#     # Format the results with proper number formatting
#     result = pd.DataFrame({
#         'Month': [str(period) for period in monthly_data.index],
#         f'{tariff_label} MD Excess (kW)': [_format_number_value(x) for x in monthly_data['MD_Excess_kW']],
#         'Success Shaved (kW)': [_format_number_value(x) for x in monthly_data['Success_Shaved_kW']],
#         'Cost Saving (RM)': [_format_rm_value(x) for x in monthly_data['Cost_Saving_RM']],
#         'Total EFC': [_format_number_value(x) for x in monthly_data['equivalent_full_cycles']], 
#         'Accumulating Charging Cycles': [_format_number_value(x) for x in cumulative_monthly_cycles]  # NEW: Added as last column
#     })
#     
#     return result
# 
# 
# def _create_kpi_summary_table(simulation_results, df_sim, interval_hours=None):
#     """
#     Create comprehensive KPI summary table with battery performance metrics.
#     
#     Args:
#         simulation_results: Dictionary containing simulation metrics
#         df_sim: Simulation dataframe with battery operation data
#         interval_hours: Time interval in hours (if None, will be detected dynamically)
#         
#     Returns:
#         pd.DataFrame: Key performance indicators table
#     """
#     # Get dynamic interval hours if not provided
#     if interval_hours is None:
#         interval_hours = _get_dynamic_interval_hours(df_sim)
#         
#     # Get battery capacity from session state or use default
#     battery_capacity_kwh = 100  # Default fallback
#     if hasattr(st.session_state, 'tabled_analysis_selected_battery'):
#         selected_battery = st.session_state.tabled_analysis_selected_battery
#         quantity = getattr(st.session_state, 'tabled_analysis_battery_quantity', 1)
#         battery_capacity_kwh = selected_battery['spec'].get('energy_kWh', 100) * quantity
#     
#     kpis = {
#         'Metric': [
#             'Total Simulation Hours',
#             'Peak Reduction Achieved (kW)',
#             'Success Rate (%)',
#             'Total Energy Discharged (kWh)',
#             'Total Energy Charged (kWh)',
#             'Round-Trip Efficiency (%)',
#             'Average SOC (%)',
#             'Minimum SOC Reached (%)',
#             'Maximum SOC Reached (%)',
#             'Monthly Targets Used',
#             'Target Violations',
#             'Battery Utilization (%)'
#         ],
#         'Value': [
#             f"{_format_number_value(len(df_sim) * interval_hours)} hours",
#             f"{_format_number_value(simulation_results.get('peak_reduction_kw', 0))} kW",
#             f"{_format_number_value(simulation_results.get('success_rate_percent', 0))}%",
#             f"{_format_number_value(simulation_results.get('total_energy_discharged', 0))} kWh",
#             f"{_format_number_value(simulation_results.get('total_energy_charged', 0))} kWh",
#             f"{_format_number_value(simulation_results.get('total_energy_discharged', 0) / max(simulation_results.get('total_energy_charged', 1), 1) * 100)}%",
#             f"{_format_number_value(simulation_results.get('average_soc', 0))}%",
#             f"{_format_number_value(simulation_results.get('min_soc', 0))}%",
#             f"{_format_number_value(simulation_results.get('max_soc', 0))}%",
#             f"{_format_number_value(simulation_results.get('monthly_targets_count', 0))} months",
#             f"{_format_number_value(simulation_results.get('v2_constraint_violations', 0))} intervals",
#             f"{_format_number_value(simulation_results.get('total_energy_discharged', 0) / max(len(df_sim) * interval_hours * battery_capacity_kwh, 1) * 100)}%"
#         ]
#     }
#     
#     return pd.DataFrame(kpis)
# 
# 
# def _display_battery_simulation_tables(df_sim, simulation_results, selected_tariff=None, holidays=None):
#     """
#     Display comprehensive battery simulation tables with tabbed interface.
#     
#     Args:
#         df_sim: Simulation dataframe with battery operation data
#         simulation_results: Dictionary containing simulation metrics
#         selected_tariff: Selected tariff configuration for cost calculations
#         holidays: Set of holiday dates for MD-aware calculations
#     """
#     st.markdown("##### 1ï¸âƒ£.1 ðŸ“‹ Battery Simulation Data Tables")
#     
#     # Tab-based layout for different table views
#     tab1, tab2, tab3, tab4, tab5 = st.tabs([
#         "ðŸ“Š Time Series Data (Chart Filtered)", 
#         "ðŸ“… Daily Summary",
#         "ðŸ“† Monthly Summary", 
#         "ðŸŽ¯ KPI Summary",
#         "ðŸ” Filtered View"
#     ])
#     
#     with tab1:
#         st.markdown("**Complete Time-Series Battery Operation Data**")
#         
#         # Check if data is filtered by TWO-LEVEL cascading filters
#         chart_filter_active = hasattr(st.session_state, 'chart_success_filter') and st.session_state.chart_success_filter != "All Days"
#         level2_filter_active = (chart_filter_active and 
#                                'specific_day_filter' in st.session_state and 
#                                st.session_state.get('specific_day_filter', '').strip() and 
#                                not st.session_state.get('specific_day_filter', '').startswith("All "))
#         
#         if chart_filter_active:
#             # Get filter info from session state
#             selected_filter = st.session_state.chart_success_filter
#             total_days = len(set(df_sim.index.date)) if len(df_sim) > 0 else 0
#             
#             if level2_filter_active:
#                 specific_day = st.session_state.get('specific_day_filter', '')
#                 st.info(f"ðŸŽ¯ **Two-Level Cascading Filter Applied**: \n- Level 1: '{selected_filter}' \n- Level 2: Specific Day ({specific_day})")
#                 st.info(f"ðŸ“Š **Filtered Results**: {len(df_sim):,} records from {total_days} day(s)")
#             else:
#                 st.info(f"ðŸŽ¯ **Level 1 Filter Applied**: Showing data filtered by '{selected_filter}' from chart filter")
#                 st.info(f"ðŸ“Š **Filtered Results**: {len(df_sim):,} records from {total_days} days")
#         else:
#             st.info(f"ðŸ“Š **All Results**: Showing {len(df_sim):,} records (no chart filter applied)")
#         
#         # Create table data from the filtered df_sim
#         table_data = _create_enhanced_battery_table(df_sim, selected_tariff, holidays)
#         
#         # Display data
#         st.dataframe(table_data, use_container_width=True, height=400)
#         
#         # Download option with cascading filter info in filename
#         csv = table_data.to_csv(index=False)
#         
#         if level2_filter_active:
#             # Two-level filter active
#             level1_name = st.session_state.chart_success_filter.replace(' ', '_').lower()
#             specific_day = st.session_state.get('specific_day_filter', '').replace('-', '')
#             filter_suffix = f"_L1-{level1_name}_L2-{specific_day}"
#         elif chart_filter_active:
#             # Only Level 1 filter active
#             filter_suffix = f"_filtered_{st.session_state.chart_success_filter.replace(' ', '_').lower()}"
#         else:
#             # No filters active
#             filter_suffix = "_all"
#             
#         filename = f"battery_timeseries{filter_suffix}_{len(table_data)}records.csv"
#         st.download_button("ðŸ“¥ Download Time Series Data", csv, filename, "text/csv", key="download_ts")
#     
#     with tab2:
#         st.markdown("**Daily Performance Summary with RP4 Tariff-Aware Peak Events**")
#         
#         # UPDATED: Pass selected_tariff and interval_hours to daily summary function
#         interval_hours = _get_dynamic_interval_hours(df_sim)
#         daily_data = _create_daily_summary_table(df_sim, selected_tariff, interval_hours)
#         
#         if len(daily_data) > 0:
#             st.dataframe(daily_data, use_container_width=True)
#             
#             # Add summary metrics with proper formatting
#             col1, col2, col3, col4 = st.columns(4)
#             
#             # Extract numeric values from formatted data for calculations
#             peak_events_values = daily_data['Total Peak Events'].apply(lambda x: float(x.replace(',', '')) if isinstance(x, str) else x)
#             efc_values = daily_data['Equivalent Full Cycles (EFC)'].apply(lambda x: float(x.replace(',', '')) if isinstance(x, str) else x)
#             
#             total_peak_events = peak_events_values.sum()
#             successful_days = len(daily_data[daily_data['Target_Success'] == 'âœ…'])
#             total_days = len(daily_data)
#             success_rate = (successful_days / total_days * 100) if total_days > 0 else 0
#             total_efc = efc_values.sum()
#             
#             col1.metric("Total Peak Events", _format_number_value(total_peak_events))
#             col2.metric("Success Rate", f"{_format_number_value(success_rate)}%", f"{successful_days}/{total_days} days")
#             col3.metric("Total EFC", _format_number_value(total_efc))
#             col4.metric("Avg EFC/Day", _format_number_value(total_efc/total_days) if total_days > 0 else "0.00")
#             
#             # Add explanation
#             tariff_type = "TOU" if (selected_tariff and ('tou' in selected_tariff.get('Tariff', '').lower() or selected_tariff.get('Type', '').lower() == 'tou')) else "General"
#             
#             # Get battery info for explanation
#             battery_info = "100 kWh (80% DoD = 80 kWh usable)"  # Default
#             if hasattr(st.session_state, 'tabled_analysis_selected_battery'):
#                 selected_battery = st.session_state.tabled_analysis_selected_battery
#                 quantity = getattr(st.session_state, 'tabled_analysis_battery_quantity', 1)
#                 battery_spec = selected_battery['spec']
#                 total_capacity = battery_spec.get('energy_kWh', 100) * quantity
#                 try:
#                     battery_params = getattr(st.session_state, 'battery_params', {})
#                     dod = battery_params.get('depth_of_discharge', 80)
#                 except:
#                     dod = 80
#                 usable_capacity = total_capacity * (dod / 100)
#                 battery_info = f"{total_capacity} kWh ({dod}% DoD = {usable_capacity:.1f} kWh usable)"
#             
#             # Download option
#             csv = daily_data.to_csv(index=False)
#             st.download_button("ðŸ“¥ Download Daily Summary", csv, "battery_daily_summary.csv", "text/csv", key="download_daily_summary")
#             
#             st.info(f"""
#             **ðŸ“Š RP4 Tariff-Aware Analysis ({tariff_type} Tariff):**
#             
#             **Peak Event Detection Logic:**
#             - **{tariff_type} Tariff**: {"Peak events only during MD recording periods (2PM-10PM weekdays)" if tariff_type == "TOU" else "Peak events anytime above monthly target (24/7 MD recording)"}
#             - **MD Excess**: Maximum demand above monthly target during peak events only
#             - **Target Success**: âœ… if maximum net demand during peak events â‰¤ monthly target (Â±5% tolerance)
#             
#             **Energy & EFC (Equivalent Full Cycles) Calculations:**
#             - **Battery Configuration**: {battery_info}
#             - **Energy Conversion**: Dynamic interval detection for accurate kWh conversion
#             - **EFC Formula**: (Total Charge kWh + Total Discharge kWh) Ã· (2 Ã— Usable Battery Capacity) - Industry Standard Throughput Method
#             - **Fractional EFC**: Values can be less than 1.0 (e.g., 0.42 = 42% of a full cycle per day)
#             
#             **Daily Analysis Scope:**
#             - Charge/Discharge energies sum all intervals for the entire day (24/7)
#             - Peak events filtered by tariff-specific MD recording periods only
#             - Target/Actual shaving calculated only during peak events
#             """)
#         else:
#             st.info("No daily summary data available.")
#     
#     with tab3:
#         st.markdown("**Monthly Performance Summary**")
#         interval_hours = _get_dynamic_interval_hours(df_sim)
#         monthly_data = _create_monthly_summary_table(df_sim, selected_tariff, interval_hours)
#         
#         if len(monthly_data) > 0:
#             st.dataframe(monthly_data, use_container_width=True)
#             
#             # Download option
#             csv = monthly_data.to_csv(index=False)
#             st.download_button("ðŸ“¥ Download Monthly Summary", csv, "battery_monthly_summary.csv", "text/csv", key="download_monthly")
#             
#             # Display summary metrics including charging cycles
#             if selected_tariff and 'Cost Saving (RM)' in monthly_data.columns:
#                 # Extract numeric values from formatted data for calculations
#                 cost_saving_values = monthly_data['Cost Saving (RM)'].apply(lambda x: float(x.replace('RM', '').replace(',', '')) if isinstance(x, str) else x)
#                 
#                 # Handle both old and new column names for charging cycles
#                 if 'Accumulating Charging Cycles' in monthly_data.columns:
#                     # Use the new accumulating column - take the final (maximum) value since it's cumulative
#                     accumulating_cycle_values = monthly_data['Accumulating Charging Cycles'].apply(lambda x: float(x.replace(',', '')) if isinstance(x, str) else x)
#                     total_charging_cycles = accumulating_cycle_values.max() if len(accumulating_cycle_values) > 0 else 0
#                     # For monthly average, use Total EFC if available, otherwise calculate from Total Charging Cycles / months
#                     if 'Total EFC' in monthly_data.columns:
#                         efc_values = monthly_data['Total EFC'].apply(lambda x: float(x.replace(',', '')) if isinstance(x, str) else x)
#                         avg_monthly_cycles = efc_values.mean()
#                     else:
#                         avg_monthly_cycles = total_charging_cycles / len(monthly_data) if len(monthly_data) > 0 else 0
#                 elif 'Total Charging Cycles' in monthly_data.columns:
#                     # Backwards compatibility with old column name
#                     charging_cycle_values = monthly_data['Total Charging Cycles'].apply(lambda x: float(x.replace(',', '')) if isinstance(x, str) else x)
#                     total_charging_cycles = charging_cycle_values.sum()
#                     avg_monthly_cycles = charging_cycle_values.mean()
#                 elif 'Total EFC' in monthly_data.columns:
#                     # Use Total EFC as fallback
#                     efc_values = monthly_data['Total EFC'].apply(lambda x: float(x.replace(',', '')) if isinstance(x, str) else x)
#                     total_charging_cycles = efc_values.sum()
#                     avg_monthly_cycles = efc_values.mean()
#                 else:
#                     # No charging cycle data available
#                     total_charging_cycles = 0
#                     avg_monthly_cycles = 0
#                 
#                 success_shaved_values = monthly_data['Success Shaved (kW)'].apply(lambda x: float(x.replace(',', '')) if isinstance(x, str) else x)
#                 md_excess_values = monthly_data.iloc[:, 1].apply(lambda x: float(x.replace(',', '')) if isinstance(x, str) else x)  # Second column is MD Excess
#                 
#                 total_cost_saving = cost_saving_values.sum()
#                 avg_monthly_saving = cost_saving_values.mean()
#                 total_success_shaved = success_shaved_values.sum()
#                 total_md_excess = md_excess_values.sum()
#                 
#                 col1, col2, col3, col4 = st.columns(4)
#                 with col1:
#                     st.metric("Total Cost Saving", _format_rm_value(total_cost_saving))
#                 with col2:
#                     st.metric("Average Monthly Saving", _format_rm_value(avg_monthly_saving))
#                 with col3:
#                     # Update metric label based on available data
#                     if 'Accumulating Charging Cycles' in monthly_data.columns:
#                         st.metric("Total Accumulating Cycles", _format_number_value(total_charging_cycles))
#                     else:
#                         st.metric("Total Charging Cycles", _format_number_value(total_charging_cycles))
#                 with col4:
#                     st.metric("Analysis Period", f"{len(monthly_data)} months")
#                     
#                 # Additional metrics row
#                 col1, col2, col3 = st.columns(3)
#                 with col1:
#                     st.metric("Avg Cycles/Month", _format_number_value(avg_monthly_cycles))
#                 with col2:
#                     st.metric("Total Success Shaved", f"{_format_number_value(total_success_shaved)} kW")
#                 with col3:
#                     tariff_type = "TOU" if 'TOU' in monthly_data.columns[1] else "General"
#                     st.metric(f"Total {tariff_type} MD Excess", f"{_format_number_value(total_md_excess)} kW")
#         else:
#             st.info("No monthly data available for analysis.")
#     
#     with tab4:
#         st.markdown("**Key Performance Indicators**")
#         interval_hours = _get_dynamic_interval_hours(df_sim)
#         kpi_data = _create_kpi_summary_table(simulation_results, df_sim, interval_hours)
#         st.dataframe(kpi_data, use_container_width=True, hide_index=True)
#     
#     with tab5:
#         st.markdown("**Custom Filtered View**")
#         
#         # Advanced filters
#         col1, col2 = st.columns(2)
#         with col1:
#             if len(df_sim) > 0:
#                 date_range = st.date_input("Select date range", 
#                                          [df_sim.index.min().date(), df_sim.index.max().date()],
#                                          key="filter_date_range")
#         with col2:
#             soc_range = st.slider("SOC Range (%)", 0, 100, (0, 100), key="filter_soc_range")
#         
#         # Apply advanced filters
#         if len(df_sim) > 0 and len(date_range) == 2:
#             mask = (df_sim.index.date >= date_range[0]) & (df_sim.index.date <= date_range[1])
#             mask &= (df_sim['Battery_SOC_Percent'] >= soc_range[0]) & (df_sim['Battery_SOC_Percent'] <= soc_range[1])
#             
#             filtered_advanced = _create_enhanced_battery_table(df_sim[mask], selected_tariff, holidays)
#             st.dataframe(filtered_advanced, use_container_width=True, height=400)
#         else:
#     
#             st.info("Please select a valid date range to view filtered data.")
# 

# =============================================================================
# V2 BATTERY SIMULATION FUNCTIONS
# =============================================================================

def _create_v2_dynamic_target_series(simulation_index, monthly_targets):
    """
    Create a dynamic target series that matches the simulation dataframe index
    with stepped monthly targets from V2's monthly_targets.
    
    Args:
        simulation_index: DatetimeIndex from the simulation dataframe
        monthly_targets: V2's monthly targets (Series with Period index)
        
    Returns:
        Series with same index as simulation_index, containing monthly target values
    """
    target_series = pd.Series(index=simulation_index, dtype=float)
    
    for timestamp in simulation_index:
        # FIXED: Ensure timestamp is a pandas Timestamp object
        if not isinstance(timestamp, pd.Timestamp):
            try:
                timestamp = pd.to_datetime(timestamp)
            except Exception as e:
                try:
                    import streamlit as st
                    st.warning(f"Could not convert timestamp {timestamp} to datetime: {e}")
                except ImportError:
                    print(f"Could not convert timestamp {timestamp} to datetime: {e}")
                continue
        
        # Get the month period for this timestamp
        try:
            month_period = timestamp.to_period('M')
        except Exception as e:
            try:
                import streamlit as st
                st.warning(f"Could not convert timestamp {timestamp} to period: {e}")
            except ImportError:
                print(f"Could not convert timestamp {timestamp} to period: {e}")
            continue
        
        # Find the corresponding monthly target - FIXED: Ensure scalar float value
        if month_period in monthly_targets.index:
            target_value = monthly_targets.loc[month_period]
            target_series.loc[timestamp] = float(target_value)
        else:
            # Fallback: use the closest available monthly target
            available_months = list(monthly_targets.index)
            if available_months:
                # Find the closest month
                closest_month = min(available_months, 
                                  key=lambda m: abs((month_period - m).n))
                target_value = monthly_targets.loc[closest_month]
                target_series.loc[timestamp] = float(target_value)
            else:
                # Ultimate fallback
                target_series.loc[timestamp] = 1000.0  # Safe default
    
    return target_series


def _calculate_c_rate_limited_power_simple(current_soc_percent, max_power_rating_kw, battery_capacity_kwh, c_rate=1.0):
    """
    Simple C-rate power limitation for charging/discharging.
    
    Args:
        current_soc_percent: Current state of charge percentage
        max_power_rating_kw: Battery's rated power
        battery_capacity_kwh: Battery's energy capacity
        c_rate: Battery's C-rate (default 1.0C)
        
    Returns:
        Dictionary with power limits
    """
    # Calculate C-rate based power limits
    c_rate_power_limit = battery_capacity_kwh * c_rate
    
    # SOC-based derating (power reduces at extreme SOC levels)
    if current_soc_percent > 90:
        soc_factor = 0.8  # Reduce power at high SOC
    elif current_soc_percent < 20:
        soc_factor = 0.7  # Reduce power at low SOC
    else:
        soc_factor = 1.0  # Full power in normal SOC range
    
    # Final power limit is minimum of C-rate limit and rated power
    effective_max_discharge_kw = min(c_rate_power_limit, max_power_rating_kw) * soc_factor
    effective_max_charge_kw = min(c_rate_power_limit, max_power_rating_kw) * soc_factor * 0.8  # Charging typically slower
    
    return {
        'max_discharge_power_kw': effective_max_discharge_kw,
        'max_charge_power_kw': effective_max_charge_kw,
        'c_rate_power_limit_kw': c_rate_power_limit,
        'soc_derating_factor': soc_factor,
        'limiting_factor': 'C-rate' if c_rate_power_limit < max_power_rating_kw else 'Power Rating'
    }


def _get_tou_charging_urgency(current_timestamp, soc_percent, holidays=None):
    """
    Determine TOU charging urgency based on time until MD window and current SOC.
    
    TOU charging windows:
    - Primary: 10 PM - 2 PM next day (overnight charging)
    - Target: 95% SOC by 2 PM on weekdays for MD readiness
    
    Args:
        current_timestamp: Current datetime
        soc_percent: Current battery SOC percentage
        holidays: Set of holiday dates
    
    Returns:
        dict: Charging urgency information
    """
    from datetime import datetime, timedelta
    
    # Check if it's a charging window (10 PM - 2 PM next day)
    hour = current_timestamp.hour
    is_weekday = current_timestamp.weekday() < 5
    is_holiday = holidays and current_timestamp.date() in holidays
    
    # TOU charging window: 10 PM to 2 PM next day
    is_charging_window = hour >= 22 or hour < 14
    
    # Calculate time until next MD window (2 PM)
    current_date = current_timestamp.date()
    if hour < 14:
        # Same day 2 PM
        next_md_start = datetime.combine(current_date, datetime.min.time().replace(hour=14))
    else:
        # Next day 2 PM
        next_day = current_date + timedelta(days=1)
        next_md_start = datetime.combine(next_day, datetime.min.time().replace(hour=14))
    
    # Only consider weekday MD windows
    while next_md_start.weekday() >= 5 or (holidays and next_md_start.date() in holidays):
        next_md_start += timedelta(days=1)
        next_md_start = next_md_start.replace(hour=14, minute=0, second=0, microsecond=0)
    
    time_until_md = next_md_start - current_timestamp
    hours_until_md = time_until_md.total_seconds() / 3600
    
    # Determine charging urgency
    urgency_level = 'normal'
    charge_rate_multiplier = 1.0
    
    if hours_until_md <= 4:  # Less than 4 hours until MD window
        if soc_percent < 95:
            urgency_level = 'critical'
            charge_rate_multiplier = 1.5  # Aggressive charging
    elif hours_until_md <= 8:  # 4-8 hours until MD window
        if soc_percent < 90:
            urgency_level = 'high'
            charge_rate_multiplier = 1.2  # Enhanced charging
    elif hours_until_md <= 16:  # 8-16 hours until MD window
        if soc_percent < 80:
            urgency_level = 'normal'
            charge_rate_multiplier = 1.0  # Standard charging
    
    return {
        'urgency_level': urgency_level,
        'charge_rate_multiplier': charge_rate_multiplier,
        'hours_until_md': hours_until_md,
        'is_charging_window': is_charging_window,
        'is_weekday': is_weekday and not is_holiday,
        'next_md_window': next_md_start
    }


def is_md_window(timestamp, holidays=None):
    """
    Determine if timestamp is in MD recording window based on RP4 tariff rules.
    
    Args:
        timestamp: datetime object
        holidays: set of holiday dates
        
    Returns:
        bool: True if in MD recording period
    """
    # MD recording: 2 PM - 10 PM on weekdays (non-holidays)
    if holidays and timestamp.date() in holidays:
        return False
    
    if timestamp.weekday() >= 5:  # Weekend
        return False
    
    hour = timestamp.hour
    return 14 <= hour < 22  # 2 PM to 10 PM


def _get_enhanced_shaving_success(row, holidays=None):
    """
    Enhanced shaving success classification using comprehensive battery status evaluation.
    Uses simplified 4-category system for better user understanding.
    
    Args:
        row: DataFrame row with simulation data
        holidays: Set of holiday dates
        
    Returns:
        str: Success classification with emoji and description
    """
    try:
        timestamp = row.name
        is_md = is_md_window(timestamp, holidays)
        
        # Get key metrics
        original_demand = row.get('Original_Demand', 0)
        net_demand = row.get('Net_Demand_kW', original_demand)
        monthly_target = row.get('Monthly_Target', 0)
        battery_power = row.get('Battery_Power_kW', 0)
        soc_percent = row.get('Battery_SOC_Percent', 50)
        
        # Calculate demand reduction
        demand_reduction = original_demand - net_demand
        excess_above_target = max(0, original_demand - monthly_target)
        
        # During MD periods
        if is_md:
            if net_demand <= monthly_target * 1.05:  # Within 5% tolerance
                if soc_percent > 20:
                    return "âœ… Success - Target Met"
                else:
                    return "ðŸŸ¡ Partial - Target Met (Low SOC)"
            elif demand_reduction > 0:  # Some battery help
                if demand_reduction >= excess_above_target * 0.5:  # Reduced 50%+ of excess
                    return "ðŸŸ¡ Partial - Significant Reduction"
                else:
                    return "ðŸŸ¡ Partial - Limited Reduction"
            else:
                return "ðŸ”´ Failed - No Battery Response"
        
        # Outside MD periods
        else:
            if battery_power < 0:  # Charging
                return "âœ… Success - Charging"
            elif battery_power == 0:  # Idle
                return "âœ… Success - Idle"
            else:  # Discharging outside MD (unusual)
                return "ðŸŸ¡ Partial - Non-MD Discharge"
                
    except Exception as e:
        return "â“ Unknown"


def _simulate_battery_operation_v2(df, power_col, monthly_targets, battery_sizing, battery_params, interval_hours, selected_tariff=None, holidays=None):
    """
    V2-specific battery simulation with monthly target floor constraints.
    """
    import numpy as np
    
    # Create simulation dataframe
    df_sim = df[[power_col]].copy()
    df_sim['Original_Demand'] = df_sim[power_col]
    
    # V2 ENHANCEMENT: Create dynamic monthly target series
    target_series = _create_v2_dynamic_target_series(df_sim.index, monthly_targets)
    df_sim['Monthly_Target'] = target_series
    df_sim['Excess_Demand'] = (df_sim[power_col] - df_sim['Monthly_Target']).clip(lower=0)
    
    # Battery parameters - FIXED: Ensure all values are scalar floats
    battery_capacity = float(battery_sizing['capacity_kwh'])
    usable_capacity = float(battery_capacity * (battery_params['depth_of_discharge'] / 100))
    max_power = float(battery_sizing['power_rating_kw'])
    efficiency = float(battery_params['round_trip_efficiency'] / 100)
    
    # Initialize arrays
    soc = np.zeros(len(df_sim))
    soc_percent = np.zeros(len(df_sim))
    battery_power = np.zeros(len(df_sim))
    net_demand = df_sim[power_col].copy()
    
    # Main simulation loop
    for i in range(len(df_sim)):
        # FIXED: Convert all pandas Series values to scalar floats
        current_demand = float(df_sim[power_col].iloc[i])
        monthly_target = float(df_sim['Monthly_Target'].iloc[i])
        excess = max(0, current_demand - monthly_target)
        current_timestamp = df_sim.index[i]
        
        # Get current SOC - FIXED: Ensure scalar values
        current_soc_kwh = float(soc[i-1]) if i > 0 else float(usable_capacity * 0.80)
        current_soc_percent = float((current_soc_kwh / usable_capacity) * 100)
        
        # Discharge logic
        if excess > 0 and is_md_window(current_timestamp, holidays):
            # Calculate discharge power (limited by monthly target floor)
            max_allowable_discharge = current_demand - monthly_target
            
            # C-rate and SOC constraints
            power_limits = _calculate_c_rate_limited_power_simple(
                current_soc_percent, max_power, battery_capacity, 1.0
            )
            max_discharge_power = power_limits['max_discharge_power_kw']
            
            # Apply all constraints - FIXED: Ensure all values are scalar
            required_discharge = min(
                float(max_allowable_discharge),
                float(max_power),
                float(max_discharge_power)
            )
            
            # Check energy availability (5% minimum SOC)
            min_soc_energy = float(usable_capacity * 0.05)
            max_discharge_energy = max(0, float(current_soc_kwh - min_soc_energy))
            max_discharge_from_energy = float(max_discharge_energy / interval_hours)
            
            actual_discharge = min(float(required_discharge), float(max_discharge_from_energy))
            actual_discharge = max(0, float(actual_discharge))
            
            battery_power[i] = actual_discharge
            soc[i] = current_soc_kwh - actual_discharge * interval_hours
            net_demand.iloc[i] = max(current_demand - actual_discharge, monthly_target)
            
        else:
            # Charging logic (simplified)
            soc[i] = current_soc_kwh
            
            # Basic charging if demand is low and SOC < 95%
            if current_soc_percent < 95 and current_demand < monthly_target * 0.8:
                # FIXED: Ensure all calculations use scalar values
                remaining_capacity = float(usable_capacity * 0.95 - current_soc_kwh)
                charge_power = min(
                    float(max_power * 0.3), 
                    float(remaining_capacity / interval_hours)
                )
                
                if charge_power > 0:
                    battery_power[i] = -float(charge_power)
                    soc[i] = float(current_soc_kwh + charge_power * interval_hours * efficiency)
                    net_demand.iloc[i] = current_demand + charge_power
                else:
                    net_demand.iloc[i] = current_demand
            else:
                net_demand.iloc[i] = current_demand
        
        # Ensure SOC limits - FIXED: All operations use scalar values
        soc[i] = max(float(usable_capacity * 0.05), min(float(soc[i]), float(usable_capacity * 0.95)))
        soc_percent[i] = float((soc[i] / usable_capacity) * 100)
    
    # Add results to dataframe
    df_sim['Battery_Power_kW'] = battery_power
    df_sim['Battery_SOC_kWh'] = soc
    df_sim['Battery_SOC_Percent'] = soc_percent
    df_sim['Net_Demand_kW'] = net_demand
    
    # Add shaving success classification for chart compatibility
    df_sim['Shaving_Success'] = df_sim.apply(lambda row: _get_enhanced_shaving_success(row, holidays), axis=1)
    
    # Calculate metrics - FIXED: Ensure scalar calculations
    total_discharge = float(sum([p * interval_hours for p in battery_power if p > 0]))
    total_charge = float(sum([abs(p) * interval_hours for p in battery_power if p < 0]))
    
    return {
        'df_sim': df_sim,
        'total_discharge_kwh': total_discharge,
        'total_charge_kwh': total_charge,
        'peak_reduction_kw': float(df_sim['Original_Demand'].max() - df_sim['Net_Demand_kW'].max()),
        'avg_soc_percent': float(df_sim['Battery_SOC_Percent'].mean())
    }


def _display_v2_battery_simulation_chart(df_sim, monthly_targets=None, sizing=None, selected_tariff=None, holidays=None):
    """
    V2-specific battery operation simulation chart with DYNAMIC monthly targets.
    
    Key V2 Enhancement: Replaces static target line with stepped monthly target line.
    
    Args:
        df_sim: Simulation dataframe with battery operation data
        monthly_targets: V2's dynamic monthly targets (Series with Period index)
        sizing: Battery sizing dictionary from V2 analysis
        selected_tariff: Tariff configuration for MD period detection
        holidays: Set of holiday dates
    """
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    
    # Handle None parameters with safe defaults
    if monthly_targets is None:
        st.error("âŒ V2 Chart Error: monthly_targets is required for dynamic target visualization")
        return
        
    if sizing is None:
        sizing = {'power_rating_kw': 100, 'capacity_kwh': 100}
    
    # ===== V2 TWO-LEVEL CASCADING FILTERING =====
    st.markdown("##### ðŸŽ¯ V2 Two-Level Cascading Filters")
    
    # Success/Failure dropdown filter instead of timestamp filter
    if len(df_sim) > 0:
        # Calculate shaving success for each point if not already available
        if 'Shaving_Success' not in df_sim.columns:
            # Use the comprehensive battery status if Success_Status exists
            if 'Success_Status' in df_sim.columns:
                df_sim['Shaving_Success'] = df_sim['Success_Status']
            else:
                df_sim['Shaving_Success'] = df_sim.apply(lambda row: _get_enhanced_shaving_success(row, holidays), axis=1)
        
        # ===== LEVEL 1: DAY TYPE FILTER =====
        col1, col2 = st.columns([4, 1])
        with col1:
            filter_options = [
                "All Days",
                "All Success Days", 
                "All Partial Days",
                "All Failed Days"
            ]
            
            selected_filter = st.selectbox(
                "ðŸŽ¯ Level 1: Filter by Day Type:",
                options=filter_options,
                index=0,
                key="chart_success_filter",
                help="First level: Filter chart data to show complete days that contain specific event types"
            )
            
        with col2:
            if st.button("ðŸ”„ Reset All Filters", key="reset_chart_success_filter"):
                st.session_state.chart_success_filter = "All Days"
                if 'specific_day_filter' in st.session_state:
                    del st.session_state.specific_day_filter
                st.rerun()
        
        # ===== LEVEL 2: SPECIFIC DAY FILTER =====
        level2_days = []
        
        # Get available days based on Level 1 filter
        if selected_filter == "All Success Days":
            success_patterns = 'âœ… Success'
            success_days = df_sim[df_sim['Shaving_Success'].str.contains(success_patterns, na=False)].index.date
            level2_days = sorted(set(success_days))
        elif selected_filter == "All Partial Days":
            partial_patterns = 'ðŸŸ¡ Partial'
            partial_days = df_sim[df_sim['Shaving_Success'].str.contains(partial_patterns, na=False)].index.date
            level2_days = sorted(set(partial_days))
        elif selected_filter == "All Failed Days":
            failed_patterns = 'ðŸ”´ Failed'
            failed_days = df_sim[df_sim['Shaving_Success'].str.contains(failed_patterns, na=False)].index.date
            level2_days = sorted(set(failed_days))
        else:
            all_days = sorted(set(df_sim.index.date))
            level2_days = all_days
        
        # Always show Level 2 filter interface
        st.markdown("**Level 2: Select Specific Day for Detailed Analysis**")
        col3, col4 = st.columns([5, 1])
        
        with col3:
            # Create options for specific day selection
            if selected_filter == "All Days":
                day_options = ["All Days"]
            else:
                day_options = ["All " + selected_filter.split()[-2] + " " + selected_filter.split()[-1]]
            
            # Add individual days if available
            if level2_days:
                day_options.extend([str(day) for day in level2_days])
            
            selected_specific_day = st.selectbox(
                "ðŸŽ¯ Select Specific Day:",
                options=day_options,
                index=0,
                key="specific_day_filter",
                help="Second level: Choose a specific date for detailed analysis"
            )
        
        with col4:
            if st.button("ðŸ”„ Reset Day", key="reset_specific_day_filter"):
                if 'specific_day_filter' in st.session_state:
                    del st.session_state.specific_day_filter
                st.rerun()
                
        # ===== APPLY FILTERS TO DATA =====
        df_filtered = df_sim.copy()
        
        # Apply Level 1 filter
        if selected_filter == "All Success Days":
            success_patterns = 'âœ… Success'
            success_days = set(df_sim[df_sim['Shaving_Success'].str.contains(success_patterns, na=False)].index.date)
            df_filtered = df_sim[pd.Series(df_sim.index.date).isin(success_days).values]
        elif selected_filter == "All Partial Days":
            partial_patterns = 'ðŸŸ¡ Partial'
            partial_days = set(df_sim[df_sim['Shaving_Success'].str.contains(partial_patterns, na=False)].index.date)
            df_filtered = df_sim[pd.Series(df_sim.index.date).isin(partial_days).values]
        elif selected_filter == "All Failed Days":
            failed_patterns = 'ðŸ”´ Failed'
            failed_days = set(df_sim[df_sim['Shaving_Success'].str.contains(failed_patterns, na=False)].index.date)
            df_filtered = df_sim[pd.Series(df_sim.index.date).isin(failed_days).values]
        
        # Apply Level 2 filter (specific day selection)
        if selected_specific_day not in ["All Days", "All Success Days", "All Partial Days", "All Failed Days"]:
            try:
                from datetime import datetime
                selected_date = datetime.strptime(selected_specific_day, "%Y-%m-%d").date()
                df_filtered = df_filtered[df_filtered.index.date == selected_date]
            except:
                st.error(f"Invalid date format: {selected_specific_day}")
                return
        
        if len(df_filtered) == 0:
            st.warning(f"No data matches the selected filters: {selected_filter} + {selected_specific_day}")
            return
    else:
        st.error("âŒ No simulation data available")
        return
    
    # Resolve Net Demand column name flexibly
    net_candidates = ['Net_Demand_kW', 'Net_Demand_KW', 'Net_Demand']
    net_col = next((c for c in net_candidates if c in df_filtered.columns), None)
    
    # Validate required columns exist
    required_base = ['Original_Demand', 'Battery_Power_kW', 'Battery_SOC_Percent']
    missing_columns = [col for col in required_base if col not in df_filtered.columns]
    if net_col is None:
        missing_columns.append('Net_Demand_kW')
    
    if missing_columns:
        st.error(f"âŒ Missing required columns in V2 simulation data: {missing_columns}")
        st.info("Available columns: " + ", ".join(df_filtered.columns.tolist()))
        return
    
    # Create V2 dynamic target series (stepped monthly targets) - filtered to match chart data
    target_series = _create_v2_dynamic_target_series(df_filtered.index, monthly_targets)
    
    # Display filtered event range info
    if selected_filter != "All Days" and len(df_filtered) > 0:
        filter_start = df_filtered.index.min()
        filter_end = df_filtered.index.max()
        st.info(f"ðŸ“… **Filtered Event Range**: {filter_start.strftime('%Y-%m-%d %H:%M')} to {filter_end.strftime('%Y-%m-%d %H:%M')}")
    
    # Panel 1: V2 Enhanced MD Shaving Effectiveness with Dynamic Monthly Targets
    st.markdown("##### 1ï¸âƒ£ V2 MD Shaving Effectiveness: Demand vs Battery vs Dynamic Monthly Targets")
    
    # Display filtering status info (updated for always-visible Level 2)
    level2_active = ('specific_day_filter' in st.session_state and 
                    st.session_state.get('specific_day_filter', '').strip() and 
                    not st.session_state.get('specific_day_filter', '').startswith("All "))
    
    if level2_active:
        specific_day = st.session_state.get('specific_day_filter', '')
        st.info(f"ðŸ†• **V2 Enhancement with Two-Level Filtering**: Target line changes monthly based on V2 configuration, showing **{selected_filter}** filtered to **{specific_day}**")
    elif selected_filter != "All Days":
        st.info(f"ðŸ†• **V2 Enhancement with Level 1 Filtering**: Target line changes monthly based on V2 configuration, showing only **{selected_filter.lower()}**")
    else:
        st.info("ðŸ†• **V2 Enhancement**: Target line changes monthly based on your V2 target configuration")
    
    fig = go.Figure()
    
    # Add demand lines
    fig.add_trace(
        go.Scatter(x=df_filtered.index, y=df_filtered[net_col], 
                  name='Net Demand (with Battery)', line=dict(color='#00BFFF', width=2),
                  hovertemplate='Net: %{y:.1f} kW<br>%{x}<extra></extra>')
    )
    
    # V2 ENHANCEMENT: Add stepped monthly target line instead of static line
    fig.add_trace(
        go.Scatter(x=df_filtered.index, y=target_series, 
                  name='Monthly Target (V2 Dynamic)', 
                  line=dict(color='green', dash='dash', width=3),
                  hovertemplate='Monthly Target: %{y:.1f} kW<br>%{x}<extra></extra>')
    )
    
    # Replace area fills with bar charts for battery discharge/charge
    discharge_series = df_filtered['Battery_Power_kW'].where(df_filtered['Battery_Power_kW'] > 0, other=0)
    charge_series = df_filtered['Battery_Power_kW'].where(df_filtered['Battery_Power_kW'] < 0, other=0)
    
    # Discharge bars
    fig.add_trace(go.Bar(
        x=df_filtered.index,
        y=discharge_series,
        name='Battery Discharge (kW)',
        marker=dict(color='orange'),
        opacity=0.6,
        hovertemplate='Discharge: %{y:.1f} kW<br>%{x}<extra></extra>',
        yaxis='y2'
    ))
    
    # Charge bars (negative values)
    fig.add_trace(go.Bar(
        x=df_filtered.index,
        y=charge_series,
        name='Battery Charge (kW)',
        marker=dict(color='green'),
        opacity=0.6,
        hovertemplate='Charge: %{y:.1f} kW<br>%{x}<extra></extra>',
        yaxis='y2'
    ))
    
    # V2 ENHANCEMENT: Add dynamic conditional coloring using monthly targets instead of static average
    # This replaces the V1 averaging approach with dynamic monthly target-based coloring
    fig = _create_v2_conditional_demand_line_with_dynamic_targets(
        fig, df_filtered, 'Original_Demand', target_series, selected_tariff, holidays, "Original Demand"
    )
    
    # Compute symmetric range for y2 to show positive/negative bars
    try:
        max_abs_power = float(df_filtered['Battery_Power_kW'].abs().max())
    except Exception:
        max_abs_power = float(sizing.get('power_rating_kw', 100))
    y2_limit = max(max_abs_power * 1.1, sizing.get('power_rating_kw', 100) * 0.5)
    
    fig.update_layout(
        title='ðŸŽ¯ V2 MD Shaving Effectiveness: Demand vs Battery vs Dynamic Monthly Targets',
        xaxis_title='Time',
        yaxis_title='Power Demand (kW)',
        yaxis2=dict(
            title='Battery Power (kW) [+ discharge | - charge]',
            overlaying='y',
            side='right',
            range=[-y2_limit, y2_limit],
            zeroline=True,
            zerolinecolor='gray'
        ),
        height=500,
        hovermode='x unified',
        legend=dict(
            orientation="h",
            yanchor="top", 
            y=-0.15,
            xanchor="center", 
            x=0.5
        ),
        margin=dict(b=100),
        barmode='overlay',
        template="none",
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)'
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # V2 ENHANCEMENT INFO: Add explanation about dynamic color coding
    st.info("""
    ðŸ†• **V2 Color Coding Enhancement**: The colored line segments now use **dynamic monthly targets** instead of a static average target.
    - **Blue segments**: Below monthly target (acceptable levels)
    - **Green segments**: Above monthly target during off-peak periods (energy cost only)
    - **Red segments**: Above monthly target during peak periods (energy + MD cost impact)
    
    This provides more accurate visual feedback about when intervention is needed based on realistic monthly billing patterns.
    """)
    
    # ===== V2 SUMMARY METRICS =====
    # Get dynamic interval hours for energy calculations
    interval_hours = _get_dynamic_interval_hours(df_filtered)
    
    # Calculate basic metrics
    total_energy_discharged = df_filtered['Battery_Power_kW'].where(df_filtered['Battery_Power_kW'] > 0, 0).sum() * interval_hours
    total_energy_charged = abs(df_filtered['Battery_Power_kW'].where(df_filtered['Battery_Power_kW'] < 0, 0).sum()) * interval_hours
    success_rate = len([s for s in df_filtered['Shaving_Success'] if 'âœ…' in s]) / len(df_filtered) * 100
    
    # Display key metrics
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Energy Discharged", f"{total_energy_discharged:.1f} kWh")
    col2.metric("Energy Charged", f"{total_energy_charged:.1f} kWh")
    col3.metric("Success Rate", f"{success_rate:.1f}%")
    col4.metric("Avg SOC", f"{df_filtered['Battery_SOC_Percent'].mean():.1f}%")
    
    # Panel 2: Combined SOC and Battery Power Chart (same as V1)
    st.markdown("##### 2ï¸âƒ£ Combined SOC and Battery Power Chart")
    
    fig2 = make_subplots(specs=[[{"secondary_y": True}]])
    
    # SOC line (left y-axis)
    fig2.add_trace(
        go.Scatter(x=df_filtered.index, y=df_filtered['Battery_SOC_Percent'],
                  name='SOC (%)', line=dict(color='purple', width=2),
                  hovertemplate='SOC: %{y:.1f}%<br>%{x}<extra></extra>'),
        secondary_y=False
    )
    
    # Battery power line (right y-axis) 
    fig2.add_trace(
        go.Scatter(x=df_filtered.index, y=df_filtered['Battery_Power_kW'],
                  name='Battery Power', line=dict(color='orange', width=2),
                  hovertemplate='Power: %{y:.1f} kW<br>%{x}<extra></extra>'),
        secondary_y=True
    )
    
    # Add horizontal line for minimum SOC warning (updated to 10% based on 5% safety limit)
    fig2.add_hline(y=10, line_dash="dot", line_color="red", 
                   annotation_text="Low SOC Warning (10% - 5% Safety Limit)", secondary_y=False)
    
    # Update axes
    fig2.update_xaxes(title_text="Time")
    fig2.update_yaxes(title_text="State of Charge (%)", secondary_y=False, range=[0, 100])
    fig2.update_yaxes(title_text="Battery Discharge Power (kW)", secondary_y=True)
    
    fig2.update_layout(
        title='âš¡ SOC vs Battery Power: Timing Analysis',
        height=400,
        hovermode='x unified',
        template="none",
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)'
    )
    
    st.plotly_chart(fig2, use_container_width=True)
    
    # Panel 3: Battery Power Utilization Heatmap (same as V1)
    st.markdown("##### 3ï¸âƒ£ Battery Power Utilization Heatmap")
    
    # Prepare data for heatmap
    df_heatmap = df_filtered.copy()
    df_heatmap['Date'] = df_heatmap.index.date
    df_heatmap['Hour'] = df_heatmap.index.hour
    df_heatmap['Battery_Utilization_%'] = (df_heatmap['Battery_Power_kW'] / sizing['power_rating_kw'] * 100).clip(0, 100)
    
    # Create pivot table for heatmap
    heatmap_data = df_heatmap.pivot_table(
        values='Battery_Utilization_%', 
        index='Hour', 
        columns='Date', 
        aggfunc='mean',
        fill_value=0
    )
    
    # Create heatmap
    fig3 = go.Figure(data=go.Heatmap(
        z=heatmap_data.values,
        x=[str(d) for d in heatmap_data.columns],
        y=heatmap_data.index,
        colorscale='Viridis',
        hoverongaps=False,
        hovertemplate='Date: %{x}<br>Hour: %{y}<br>Utilization: %{z:.1f}%<extra></extra>',
        colorbar=dict(title="Battery Utilization (%)")
    ))
    
    fig3.update_layout(
        title='ðŸ”¥ Battery Power Utilization Heatmap (% of Rated Power)',
        xaxis_title='Date',
        yaxis_title='Hour of Day',
        height=400,
        template="none",
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)'
    )
    
    st.plotly_chart(fig3, use_container_width=True)
    
    # V2 Key insights with monthly target context
    st.markdown("##### ðŸ” V2 Key Insights from Enhanced Monthly Target Analysis")
    
    insights = []
    
    # Use V2 energy efficiency calculation
    energy_efficiency = (total_energy_discharged / max(total_energy_charged, 1) * 100)
        
    if energy_efficiency < 80:
        insights.append("âš ï¸ **V2 MD Energy Shortfall**: Battery capacity may be insufficient for complete monthly target-based MD peak shaving")
    elif energy_efficiency >= 95:
        insights.append("âœ… **Excellent V2 MD Coverage**: Battery effectively handles all monthly target energy requirements")
    
    # Check V2 success rate
    if success_rate > 90:
        insights.append("âœ… **High V2 Success Rate**: Battery effectively manages most peak events against dynamic monthly targets")
    elif success_rate < 60:
        insights.append("âŒ **Low V2 Success Rate**: Consider increasing battery power rating or capacity for better monthly target management")
    
    # Check battery utilization if heatmap data is available
    if len(df_heatmap) > 0:
        avg_utilization = df_heatmap['Battery_Utilization_%'].mean()
        if avg_utilization < 30:
            insights.append("ðŸ“Š **Under-utilized**: Battery power rating may be oversized for V2 monthly targets")
        elif avg_utilization > 80:
            insights.append("ðŸ”¥ **High Utilization**: Battery operating near maximum capacity for V2 monthly targets")
    
    # Check for low SOC events (updated to 10% warning threshold based on 5% safety limit)
    low_soc_events = len(df_filtered[df_filtered['Battery_SOC_Percent'] < 10])
    if low_soc_events > 0:
        insights.append(f"ðŸ”‹ **Low SOC Warning**: {low_soc_events} intervals with SOC below 10% during V2 operation (5% safety limit)")
    
    # Add insight about V2 methodology
    if len(monthly_targets) > 0:
        insights.append(f"ðŸ“Š **V2 Innovation**: Analysis uses {len(monthly_targets)} dynamic monthly targets vs traditional static targets for superior accuracy")
        insights.append(f"ðŸŽ¨ **V2 Color Enhancement**: Line color coding now reflects dynamic monthly targets instead of static averaging - providing month-specific intervention guidance")
    
    if not insights:
        insights.append("âœ… **Optimal V2 Performance**: Battery system operating within acceptable parameters with monthly targets")
    
    for insight in insights:
        st.info(insight)             